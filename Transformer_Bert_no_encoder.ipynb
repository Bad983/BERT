{"cells":[{"cell_type":"code","source":["!pip install -q -U 'tensorflow-text==2.8.*'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NE4enZGpvMRX","executionInfo":{"status":"ok","timestamp":1671267045016,"user_tz":-60,"elapsed":73676,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"73eeba06-f675-4573-885a-9f88a89696cb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 4.9 MB 37.9 MB/s \n","\u001b[K     |████████████████████████████████| 498.0 MB 13 kB/s \n","\u001b[K     |████████████████████████████████| 462 kB 44.7 MB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 73.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.4 MB 65.9 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install -q tf-models-official"],"metadata":{"id":"FPtWz_qHuofc","executionInfo":{"status":"ok","timestamp":1671267120734,"user_tz":-60,"elapsed":75740,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"78793b4d-ff94-4c85-bbad-57102d09d325"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 2.3 MB 34.0 MB/s \n","\u001b[K     |████████████████████████████████| 662 kB 71.3 MB/s \n","\u001b[K     |████████████████████████████████| 118 kB 66.0 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 63.1 MB/s \n","\u001b[K     |████████████████████████████████| 238 kB 74.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 62.0 MB/s \n","\u001b[K     |████████████████████████████████| 588.3 MB 21 kB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 62.3 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 70.6 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n","\u001b[K     |████████████████████████████████| 439 kB 55.5 MB/s \n","\u001b[K     |████████████████████████████████| 1.7 MB 70.1 MB/s \n","\u001b[K     |████████████████████████████████| 6.0 MB 75.2 MB/s \n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"hJy-juNOpUOY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671267149522,"user_tz":-60,"elapsed":28828,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"88ad8ac2-bf4c-4371-a89a-75c471853956"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"id":"UaAiWsEuC_4K","executionInfo":{"status":"ok","timestamp":1671267156442,"user_tz":-60,"elapsed":6939,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"outputs":[],"source":["import os\n","import re\n","import time\n","import unicodedata\n","import datetime\n","import pathlib\n","from pathlib import Path\n","\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","from keras import layers\n","\n","import tensorflow_hub as hub\n","import tensorflow_models as tfm\n","\n","import tensorflow_text as text\n","from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"]},{"cell_type":"code","source":["tf.get_logger().setLevel('ERROR')\n","tf.config.run_functions_eagerly(True)"],"metadata":{"id":"uKEqRlKowOQS","executionInfo":{"status":"ok","timestamp":1671267156443,"user_tz":-60,"elapsed":24,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Parametri BERT"],"metadata":{"id":"BehZY4rETECN"}},{"cell_type":"code","source":["bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'  \n","tfhub_handle_encoder =  'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n","tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n","gs_folder_bert = 'gs://cloud-tpu-checkpoints/bert/v3/uncased_L-12_H-768_A-12'\n","# bert_vocab = os.path.join(gs_folder_bert, 'vocab.txt')\n","\n","print('BERT model selected                : ', tfhub_handle_encoder)\n","print('Preprocessing model auto-selected  : ', tfhub_handle_preprocess)\n","# print('BERT vocab                         : ', bert_vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fodDcY6sm392","executionInfo":{"status":"ok","timestamp":1671267156444,"user_tz":-60,"elapsed":24,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"02307e61-89b7-45c4-b982-c37f5a13bf91"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT model selected                :  https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Preprocessing model auto-selected  :  https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"]}]},{"cell_type":"markdown","source":["### Variabili Globali"],"metadata":{"id":"HRe16D-rUBLA"}},{"cell_type":"code","source":["# PARAMETRI GLOBALI\n","root_folder = 'drive/MyDrive/BERT/'\n","\n","# DATI\n","data_folder_name = 'data'\n","train_filename = 'ita.txt'\n","data_filename = 'train_data.csv'\n","\n","DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n","train_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n","data_filenamepath = os.path.abspath(os.path.join(DATA_PATH, data_filename))\n","\n","\n","# PATH LOG Tensorboard\n","PATH_LOG = 'logs/fit/transformer_bert_v2'\n","PATH_LOG = os.path.abspath(os.path.join(root_folder, PATH_LOG))\n","log_dir =  os.path.abspath(os.path.join(PATH_LOG, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))) \n","\n","# PATH WEIGHTS Tensorboard\n","PATH_WEIGHTS = 'weights/transformer_bert_v2'\n","PATH_WEIGHTS = os.path.abspath(os.path.join(root_folder, PATH_WEIGHTS))\n","checkpoint_path = os.path.abspath(os.path.join(PATH_WEIGHTS, 'cp.ckpt'))\n","\n","# VOCABOLARIO\n","vocab_folder = 'vocab'\n","en_vocab_finalname = 'en_vocab_custom.txt'\n","it_vocab_finalname = 'it_vocab_custom.txt'\n","\n","VOCAB_PATH = os.path.abspath(os.path.join(root_folder, vocab_folder))\n","en_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, en_vocab_finalname))\n","it_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, it_vocab_finalname))"],"metadata":{"id":"ewLgCIuEpczO","executionInfo":{"status":"ok","timestamp":1671267156445,"user_tz":-60,"elapsed":20,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# parametri per il modello\n","INPUT_COLUMN = 'input'\n","TARGET_COLUMN = 'target'\n","\n","# parametri per il modello\n","NUM_SAMPLES = 300000 \n","TRAIN = 16000\n","VALIDATION = 16000\n","N_VALIDATION = 5\n","TEST = 100\n","\n","MAX_VOCAB_SIZE = 20000 \n","EMBEDDING_DIM = 64 \n","HIDDEN_DIM = 1024 # numero di celle nei layer ricorrenti nascosti\n","\n","BATCH_SIZE = 32\n","BUFFER_SIZE = 2000\n","MAX_SEQ_LENGTH = 64\n","\n","NUM_LAYERS = 1 # Numero di layer di Encoder e Decoder del Transformer\n","NUM_HEADS = 8 # Numero di meccanismi di multi-head attention\n","FF_DIM = 16 # Numero di celle dei Layer Feed Forward\n","DROPUOT = 0.5\n","\n","# Ottimizzatore Adam\n","LEARNING_RATE_ADAM = 1e-4\n","BETA_1 = 0.66\n","BETA_2 = 0.999\n","EPOCHS_ADAM = 20\n","\n","# IMPOSTO IL DEBUG A TRUE \n","debug = True\n","training = True"],"metadata":{"id":"8CN-4Uzoqbjl","executionInfo":{"status":"ok","timestamp":1671267156446,"user_tz":-60,"elapsed":18,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## DATASET"],"metadata":{"id":"5DPeN9Vanbvv"}},{"cell_type":"markdown","source":["### Caricamento Dati"],"metadata":{"id":"LU7AorKXT8K7"}},{"cell_type":"code","source":["exist_data_file = Path(data_filenamepath)\n","\n","if not exist_data_file.exists():\n","  # Caricamento dataset: frasi in inglese, frasi in italiano\n","  df = pd.read_csv(\n","      train_filenamepath,\n","      sep=\"\\t\",\n","      header=None,\n","      names=[INPUT_COLUMN, TARGET_COLUMN],\n","      usecols=[0,1],\n","      nrows=NUM_SAMPLES\n","  )\n","\n","  df = df[-(TRAIN+VALIDATION+TEST):].reset_index(drop=True)\n","\n","  # Mischio il dataset in modo che sia più uniforme tra train e test\n","  df = df.iloc[np.random.permutation(df.index)].reset_index(drop=True)\n","\n","  print(df.iloc[-4:], '\\n')\n","\n","  df.to_csv(data_filenamepath, header=True, index=False, sep='|', columns=[INPUT_COLUMN, TARGET_COLUMN])"],"metadata":{"id":"cl--E966sf1S","executionInfo":{"status":"ok","timestamp":1671267156942,"user_tz":-60,"elapsed":513,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\n","    data_filenamepath,\n","    sep='|',\n","    header=0\n",")\n","\n","print(df.iloc[-4:], '\\n')\n","\n","# Preprocessing dei dati di Input\n","input_data = df[INPUT_COLUMN].tolist()\n","\n","# Preprocessing dei dati Target con aggiunta del token di fine frase\n","target_data = df[TARGET_COLUMN].tolist()\n","\n","train_input_data = input_data[:TRAIN]\n","train_target_data = target_data[:TRAIN]\n","\n","validation_input_data = input_data[TRAIN:TRAIN+VALIDATION]\n","validation_target_data = target_data[TRAIN:TRAIN+VALIDATION]\n","\n","test_input_data = input_data[TRAIN+VALIDATION:]\n","test_target_data = target_data[TRAIN+VALIDATION:]\n","\n","print('-----------TRAIN SET--------------')\n","print(train_input_data[-4:])\n","print(train_target_data[-4:])\n","print('-----------VALIDATION SET---------------')\n","print(validation_input_data[-4:])\n","print(validation_target_data[-4:])\n","print('-----------TEST SET---------------')\n","print(test_input_data[-4:])\n","print(test_target_data[-4:])"],"metadata":{"id":"-K_qU8ouq5lO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671267159292,"user_tz":-60,"elapsed":2359,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"8b4f0c17-36dd-47d3-a1e7-98d6b31043b0"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["                                      input  \\\n","32096    The clock has already struck noon.   \n","32097  Do you still eat at that restaurant?   \n","32098     This never happened to me before.   \n","32099   What does the Bible say about this?   \n","\n","                                         target  \n","32096    L'orologio ha già segnato mezzogiorno.  \n","32097         Mangia ancora in quel ristorante?  \n","32098  Questo non mi è mai successo in passato.  \n","32099        Che cosa dice la Bibbia su questo?   \n","\n","-----------TRAIN SET--------------\n","[\"There isn't anything else I can do.\", \"That's the chair that I really like.\", 'I think you forgot something, Tom.', \"I don't know how to spell the word.\"]\n","[\"Non c'è altro che riesco a fare.\", 'È la sedia che mi piace veramente.', 'Penso che tu abbia scordato qualcosa, Tom.', 'Io non so come si scrive la parola.']\n","-----------VALIDATION SET---------------\n","[\"I don't know which button to push.\", 'I tried calling you at your office.', 'She glanced shyly at the young man.', 'Who will you vote for for president?']\n","['Non so quale pulsante premere.', 'Ho provato a chiamarla in ufficio.', 'Lei guardò timidamente il giovane.', 'Chi voterete come presidente?']\n","-----------TEST SET---------------\n","['The clock has already struck noon.', 'Do you still eat at that restaurant?', 'This never happened to me before.', 'What does the Bible say about this?']\n","[\"L'orologio ha già segnato mezzogiorno.\", 'Mangia ancora in quel ristorante?', 'Questo non mi è mai successo in passato.', 'Che cosa dice la Bibbia su questo?']\n"]}]},{"cell_type":"markdown","source":["### Analisi Dati"],"metadata":{"id":"q1u_rcHxUaqV"}},{"cell_type":"code","source":["print(f'Esempi nel Dataset di Train                            : {len(train_input_data)}')\n","print(f'Frase più corta in inglese nel Dataset di Train        : {min(train_input_data, key = len)}')\n","print(f'Frase più corta in italiano nel Dataset di Train       : {min(train_target_data, key = len)}')\n","print(f'Frase più lunga in inglese nel Dataset di Train        : {max(train_input_data, key = len)}')\n","print(f'Frase più lunga in italiano nel Dataset di Train       : {max(train_target_data, key = len)}')\n","print('---------------------------------------------------------------------------------------')\n","print(f'Esempi nel Dataset di Validation                       : {len(validation_input_data)}')\n","print(f'Frase più corta in inglese nel Dataset di Validation   : {min(validation_input_data, key = len)}')\n","print(f'Frase più corta in italiano nel Dataset di Validation  : {min(validation_target_data, key = len)}')\n","print(f'Frase più lunga in inglese nel Dataset di Validation   : {max(validation_input_data, key = len)}')\n","print(f'Frase più lunga in italiano nel Dataset di Validation  : {max(validation_target_data, key = len)}')\n","print('---------------------------------------------------------------------------------------')\n","print(f'Esempi nel Dataset di Test                             : {len(test_input_data)}')\n","print(f'Frase più corta in inglese nel Dataset di Test         : {min(test_input_data, key = len)}')\n","print(f'Frase più corta in italiano nel Dataset di Test        : {min(test_target_data, key = len)}')\n","print(f'Frase più lunga in inglese nel Dataset di Test         : {max(test_input_data, key = len)}')\n","print(f'Frase più lunga in italiano nel Dataset di Test        : {max(test_target_data, key = len)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rssHK6CUcRL","executionInfo":{"status":"ok","timestamp":1671267159295,"user_tz":-60,"elapsed":52,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"e5313280-87e4-479e-eb1e-c40ccef9ed27"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Esempi nel Dataset di Train                            : 16000\n","Frase più corta in inglese nel Dataset di Train        : How are you? \"I can't complain.\"\n","Frase più corta in italiano nel Dataset di Train       : Ti aspetterò.\n","Frase più lunga in inglese nel Dataset di Train        : Did Tom find what he was looking for?\n","Frase più lunga in italiano nel Dataset di Train       : Per favore, non fare bollire le uova fino a farle diventare così dure.\n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Validation                       : 16000\n","Frase più corta in inglese nel Dataset di Validation   : Please go there now. \"Go where?\"\n","Frase più corta in italiano nel Dataset di Validation  : Si accomodi.\n","Frase più lunga in inglese nel Dataset di Validation   : All their secrets have been revealed.\n","Frase più lunga in italiano nel Dataset di Validation  : È passato un po' di tempo dall'ultima volta che ci siamo incontrati.\n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Test                             : 100\n","Frase più corta in inglese nel Dataset di Test         : She has a very enviable position.\n","Frase più corta in italiano nel Dataset di Test        : Tu non devi saperlo.\n","Frase più lunga in inglese nel Dataset di Test         : Carrots and turnips are edible roots.\n","Frase più lunga in italiano nel Dataset di Test        : Sono contento che ci siamo lasciati alle nostre spalle tutto questo.\n"]}]},{"cell_type":"markdown","source":["## Tokenizer\n","\n","Carico il modello di tokenizer di BERT e creo un Tokenizer per il set di dati a disposizione"],"metadata":{"id":"njyY9RWlFMWu"}},{"cell_type":"markdown","source":["### Tokenizer Bert"],"metadata":{"id":"0KUcCnjXVjt3"}},{"cell_type":"code","source":["# Tokenizer BERT\n","tokenizer_encoder = hub.KerasLayer(tfhub_handle_preprocess, name='Bert_Preprocessing')"],"metadata":{"id":"-4B-HWWcmsmz","executionInfo":{"status":"ok","timestamp":1671267167021,"user_tz":-60,"elapsed":7757,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["### Tokenizer Custom"],"metadata":{"id":"mICEGEzJVnvx"}},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices((input_data, target_data))\n","dataset = dataset.shuffle(len(input_data)).batch(BATCH_SIZE, drop_remainder=True)\n","\n","train_en = dataset.map(lambda en, it: en)\n","train_it = dataset.map(lambda en, it: it)\n","\n","bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","bert_vocab_args = dict(\n","    # The target vocabulary size\n","    vocab_size = MAX_VOCAB_SIZE,\n","    # Reserved tokens that must be included in the vocabulary\n","    reserved_tokens=reserved_tokens,\n","    # Arguments for `text.BertTokenizer`\n","    bert_tokenizer_params=bert_tokenizer_params,\n","    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","    learn_params={},\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abBEnJJGV0AD","executionInfo":{"status":"ok","timestamp":1671267167445,"user_tz":-60,"elapsed":478,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"d98d19bd-5810-4f82-d89c-122ceb96401a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def write_vocab_file(filepath, vocab):\n","  with open(filepath, 'w') as f:\n","    for token in vocab:\n","      print(token, file=f)"],"metadata":{"id":"fPqihfIGVz9o","executionInfo":{"status":"ok","timestamp":1671267167446,"user_tz":-60,"elapsed":15,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(en_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  en_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_en.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(en_vocab_filenamepath, en_vocab)"],"metadata":{"id":"dGsP1V4nVz6S","executionInfo":{"status":"ok","timestamp":1671267167447,"user_tz":-60,"elapsed":15,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(it_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  it_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_it.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(it_vocab_filenamepath, it_vocab)"],"metadata":{"id":"GTMPQWlmVz1W","executionInfo":{"status":"ok","timestamp":1671267167447,"user_tz":-60,"elapsed":15,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["en_tokenizer = text.BertTokenizer(en_vocab_filenamepath, **bert_tokenizer_params)\n","it_tokenizer = text.BertTokenizer(it_vocab_filenamepath, **bert_tokenizer_params)"],"metadata":{"id":"l4rnN0BsVzxq","executionInfo":{"status":"ok","timestamp":1671267169713,"user_tz":-60,"elapsed":2280,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["START = tf.argmax(tf.constant(reserved_tokens) == \"[START]\")\n","END = tf.argmax(tf.constant(reserved_tokens) == \"[END]\")\n","\n","def add_start_end(ragged):\n","  count = ragged.bounding_shape()[0]\n","  starts = tf.fill([count,1], START)\n","  ends = tf.fill([count,1], END)\n","  x = tf.concat([starts, ragged, ends], axis=1)\n","  # x = keras.preprocessing.sequence.pad_sequences(x.numpy(), maxlen=MAX_SEQ_LENGTH, padding='post')\n","  return x\n","\n","def cleanup_text(reserved_tokens, token_txt):\n","  # Drop the reserved tokens, except for \"[UNK]\".\n","  bad_tokens = [re.escape(tok) for tok in reserved_tokens if tok != \"[UNK]\"]\n","  bad_token_re = \"|\".join(bad_tokens)\n","\n","  bad_cells = tf.strings.regex_full_match(token_txt, bad_token_re)\n","  result = tf.ragged.boolean_mask(token_txt, ~bad_cells)\n","\n","  # Join them into strings.\n","  result = tf.strings.reduce_join(result, separator=' ', axis=-1)\n","\n","  return result"],"metadata":{"id":"BeaD2-uLWT50","executionInfo":{"status":"ok","timestamp":1671267169714,"user_tz":-60,"elapsed":65,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["#### Classe Tokenizer Custom"],"metadata":{"id":"jgPVS9ZEWWVI"}},{"cell_type":"code","source":["class CustomTokenizer(tf.Module):\n","  def __init__(self, reserved_tokens, vocab_path):\n","    self.tokenizer = text.BertTokenizer(vocab_path, lower_case=True)\n","    self._reserved_tokens = reserved_tokens\n","    self._vocab_path = tf.saved_model.Asset(vocab_path)\n","\n","    vocab = pathlib.Path(vocab_path).read_text().splitlines()\n","    self.vocab = tf.Variable(vocab)\n","\n","    ## Create the signatures for export:   \n","\n","    # Include a tokenize signature for a batch of strings. \n","    self.tokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None], dtype=tf.string))\n","    \n","    # Include `detokenize` and `lookup` signatures for:\n","    #   * `Tensors` with shapes [tokens] and [batch, tokens]\n","    #   * `RaggedTensors` with shape [batch, tokens]\n","    self.detokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int64))\n","    self.detokenize.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int64))\n","\n","    self.lookup.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int64))\n","    self.lookup.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int64))\n","\n","    # These `get_*` methods take no arguments\n","    self.get_vocab_size.get_concrete_function()\n","    self.get_vocab_path.get_concrete_function()\n","    self.get_reserved_tokens.get_concrete_function()\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    enc = self.tokenizer.tokenize(strings)\n","    # Merge the `word` and `word-piece` axes.\n","    enc = enc.merge_dims(-2,-1)\n","    enc = add_start_end(enc)\n","    return enc\n","\n","  @tf.function\n","  def detokenize(self, tokenized):\n","    words = self.tokenizer.detokenize(tokenized)\n","    return cleanup_text(self._reserved_tokens, words)\n","\n","  @tf.function\n","  def lookup(self, token_ids):\n","    return tf.gather(self.vocab, token_ids)\n","\n","  @tf.function\n","  def get_vocab_size(self):\n","    return tf.shape(self.vocab)[0]\n","\n","  @tf.function\n","  def get_vocab_path(self):\n","    return self._vocab_path\n","\n","  @tf.function\n","  def get_reserved_tokens(self):\n","    return tf.constant(self._reserved_tokens)"],"metadata":{"id":"iaAW-xm5WT1_","executionInfo":{"status":"ok","timestamp":1671267169715,"user_tz":-60,"elapsed":63,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["tokenizers = tf.Module()\n","tokenizers.en = CustomTokenizer(reserved_tokens, en_vocab_filenamepath)\n","tokenizers.it = CustomTokenizer(reserved_tokens, it_vocab_filenamepath)"],"metadata":{"id":"svlLobM4WTzC","executionInfo":{"status":"ok","timestamp":1671267177668,"user_tz":-60,"elapsed":8014,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["### Analisi Dati Tokenizzati"],"metadata":{"id":"pKZxiQ5_Whmw"}},{"cell_type":"code","source":["print(f'Vocabolario Italiano : {tokenizers.it.get_vocab_size()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jrg6TwQzW5LN","executionInfo":{"status":"ok","timestamp":1671267177669,"user_tz":-60,"elapsed":127,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"f0dc08b8-860f-4855-d538-e4851d6a6db9"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabolario Italiano : 2706\n"]}]},{"cell_type":"code","source":["print(input_data[-2:])\n","print(tokenizer_encoder(input_data[-2:])['input_word_ids'][:, :16])\n","print('------------------------------------------------------------------')\n","print(target_data[-2:])\n","print(tokenizers.it.tokenize(target_data[-2:]))\n","print(keras.preprocessing.sequence.pad_sequences(tokenizers.it.tokenize(target_data[-2:]).numpy(), maxlen=MAX_SEQ_LENGTH, padding='post')[:, :16])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKEFeDdGFIGS","executionInfo":{"status":"ok","timestamp":1671267178182,"user_tz":-60,"elapsed":634,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"1c60a4a2-7542-4ef8-9c54-31ac785515e2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["['This never happened to me before.', 'What does the Bible say about this?']\n","tf.Tensor(\n","[[ 101 2023 2196 3047 2000 2033 2077 1012  102    0    0    0    0    0\n","     0    0]\n"," [ 101 2054 2515 1996 6331 2360 2055 2023 1029  102    0    0    0    0\n","     0    0]], shape=(2, 16), dtype=int32)\n","------------------------------------------------------------------\n","['Questo non mi è mai successo in passato.', 'Che cosa dice la Bibbia su questo?']\n","<tf.RaggedTensor [[2, 76, 53, 68, 28, 97, 231, 61, 462, 11, 3],\n"," [2, 55, 79, 254, 57, 25, 161, 1952, 236, 76, 23, 3]]>\n","[[   2   76   53   68   28   97  231   61  462   11    3    0    0    0\n","     0    0]\n"," [   2   55   79  254   57   25  161 1952  236   76   23    3    0    0\n","     0    0]]\n"]}]},{"cell_type":"code","source":["print([min(train_input_data, key = len)])\n","print(tokenizer_encoder([min(train_input_data, key = len)])['input_word_ids'][:, :16])\n","print('------------------------------------------------------------------')\n","print([min(train_target_data, key = len)])\n","print(tokenizers.en.tokenize([min(train_target_data, key = len)]))\n","print(keras.preprocessing.sequence.pad_sequences(tokenizers.en.tokenize([min(train_target_data, key = len)]).numpy(), maxlen=MAX_SEQ_LENGTH, padding='post')[:, :16])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O85BUq2INK5j","executionInfo":{"status":"ok","timestamp":1671267178756,"user_tz":-60,"elapsed":592,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"63d75645-5c11-4e56-96a7-42d04153322f"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["['How are you? \"I can\\'t complain.\"']\n","tf.Tensor(\n","[[  101  2129  2024  2017  1029  1000  1045  2064  1005  1056 17612  1012\n","   1000   102     0     0]], shape=(1, 16), dtype=int32)\n","------------------------------------------------------------------\n","['Ti aspetterò.']\n","<tf.RaggedTensor [[2, 43, 512, 108, 1984, 755, 441, 11, 3]]>\n","[[   2   43  512  108 1984  755  441   11    3    0    0    0    0    0\n","     0    0]]\n"]}]},{"cell_type":"code","source":["print([min(train_input_data, key = len)])\n","print(tokenizer_encoder([max(train_input_data, key = len)])['input_word_ids'][:, :16])\n","print('------------------------------------------------------------------')\n","print([max(train_target_data, key = len)])\n","print(tokenizers.en.tokenize([max(train_target_data, key = len)]))\n","print(keras.preprocessing.sequence.pad_sequences(tokenizers.en.tokenize([max(train_target_data, key = len)]).numpy(), maxlen=MAX_SEQ_LENGTH, padding='post')[:, :40])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JzJl4YGBPR3Z","executionInfo":{"status":"ok","timestamp":1671267179214,"user_tz":-60,"elapsed":506,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"d7d1faa5-ccea-48df-f822-63a84315c0cd"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["['How are you? \"I can\\'t complain.\"']\n","tf.Tensor(\n","[[ 101 2106 3419 2424 2054 2002 2001 2559 2005 1029  102    0    0    0\n","     0    0]], shape=(1, 16), dtype=int32)\n","------------------------------------------------------------------\n","['Per favore, non fare bollire le uova fino a farle diventare così dure.']\n","<tf.RaggedTensor [[2, 39, 238, 845, 232, 9, 146, 289, 656, 232, 25, 1976, 571, 1106, 35,\n","  232, 44, 441, 2106, 359, 29, 779, 441, 24, 656, 471, 27, 616, 665, 629,\n","  26, 441, 82, 512, 27, 644, 11, 3]]>\n","[[   2   39  238  845  232    9  146  289  656  232   25 1976  571 1106\n","    35  232   44  441 2106  359   29  779  441   24  656  471   27  616\n","   665  629   26  441   82  512   27  644   11    3    0    0]]\n"]}]},{"cell_type":"markdown","source":["## Creazione dataset\n","Utilizzo della libreria tf.data per la gestione del dataset da utilizzare.\n","Verranno creati batch di esempi che verranno utilizzati durante l'addestramento."],"metadata":{"id":"5QIDajkEsVU1"}},{"cell_type":"code","source":["def prepare_batch(en, it):\n","  zero = tf.zeros([BATCH_SIZE, MAX_SEQ_LENGTH], tf.int64)\n","\n","  # Tokenizzo l'input per l'Encoder\n","  encoder = tokenizer_encoder(en)          \n","\n","  # Tokenizzo l'input per il Decder e creo la variabile Target\n","  it = tokenizers.it.tokenize(it)\n","  decoder = it[:, :-1].to_tensor()  # Drop the [END] tokens\n","  target = it[:, 1:].to_tensor()   # Drop the [START] tokens\n","  \n","  decoder = tf.concat([decoder, zero], 1)\n","  decoder = decoder[:, :(MAX_SEQ_LENGTH)]\n","\n","  target = tf.concat([target, zero], 1)\n","  target = target[:, :(MAX_SEQ_LENGTH)]\n","\n","  return (encoder, decoder), target"],"metadata":{"id":"ccH3jHoABPzV","executionInfo":{"status":"ok","timestamp":1671267179215,"user_tz":-60,"elapsed":11,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def make_batches(ds):\n","  return (\n","      ds\n","      .shuffle(BUFFER_SIZE)\n","      .batch(BATCH_SIZE)\n","      .map(prepare_batch, tf.data.AUTOTUNE)\n","      .prefetch(buffer_size=tf.data.AUTOTUNE))"],"metadata":{"id":"l_dswlCiBTdR","executionInfo":{"status":"ok","timestamp":1671267179217,"user_tz":-60,"elapsed":12,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# Suddivido il dataset di validation in n parti per effettuare una validation incrociata\n","num_record_validation = len(validation_input_data) / N_VALIDATION\n","val_input_data = []\n","val_target_data = []\n","\n","for i in range(N_VALIDATION):\n","  df_input = validation_input_data[int((i*num_record_validation)):int(((i+1)*num_record_validation))]\n","  df_target = validation_target_data[int((i*num_record_validation)):int(((i+1)*num_record_validation))]\n","\n","  val_input_data.append(df_input)\n","  val_target_data.append(df_target)"],"metadata":{"id":"mKGHZ4Ae4K_V","executionInfo":{"status":"ok","timestamp":1671267179218,"user_tz":-60,"elapsed":12,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Definizione del dataset\n","# [from_tensor_slices] permette di recuperare batch\n","# di esempi dai dataset di riferimento\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_input_data, train_target_data))\n","validation_dataset = [tf.data.Dataset.from_tensor_slices((val_input, val_target)) for val_input, val_target in zip(val_input_data, val_target_data)]\n","\n","# impostazione del recupero di esempi presi in maniera\n","# casuale in gruppi di [BATCH_SIZE] tra quelli disponibili\n","train_dataset = make_batches(train_dataset)\n","validation_dataset = [make_batches(val_dataset) for val_dataset in validation_dataset]"],"metadata":{"id":"tktJ5YuIsYe3","executionInfo":{"status":"ok","timestamp":1671267184276,"user_tz":-60,"elapsed":5069,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Recupero un batch di esempi per la verifica delle classi custom che andrò a creare\n","for (enc_input, dec_input), target in train_dataset.take(1):\n","  print('----------------------- ENCODER  -------------------------------')\n","  print(f'Shape                    : {enc_input[\"input_word_ids\"].shape}')\n","  print(f'Word Ids                 : {enc_input[\"input_word_ids\"][0, :MAX_SEQ_LENGTH]}')\n","  print(f'Input Mask               : {enc_input[\"input_mask\"][0, :MAX_SEQ_LENGTH]}')\n","  print(f'Type Ids                 : {enc_input[\"input_type_ids\"][0, :MAX_SEQ_LENGTH]}')  \n","  print('--------------------- DECODER ----------------------------------')\n","  print(f'Shape it input           : {dec_input.shape}')\n","  print(f'Example it input         : {dec_input[0]}')  \n","  print('--------------------- TARGET -----------------------------------')\n","  print(f'Shape it input           : {target.shape}')\n","  print(f'Example it target        : {target[0]}')  "],"metadata":{"id":"VH_aKPlV_AWA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671267184857,"user_tz":-60,"elapsed":637,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"dc472af1-9387-4da7-81db-45f36ab3879d"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------- ENCODER  -------------------------------\n","Shape                    : (32, 128)\n","Word Ids                 : [  101  3419  2196 17612  2015  2055  2505  1012   102     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0]\n","Input Mask               : [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","Type Ids                 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","--------------------- DECODER ----------------------------------\n","Shape it input           : (32, 64)\n","Example it input         : [  2  52  53  75  57 796 520  97  54 141  11   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0]\n","--------------------- TARGET -----------------------------------\n","Shape it input           : (32, 64)\n","Example it target        : [ 52  53  75  57 796 520  97  54 141  11   3   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0]\n"]}]},{"cell_type":"markdown","source":["## Encoder BERT\n","\n","Predispondo la classe necessaria per la costruzione di BERT\n"],"metadata":{"id":"8dtVuZGJpvXl"}},{"cell_type":"code","source":["class EncoderBert(layers.Layer):\n","  def __init__(self, bert_encoder, embedding_dim, max_len):\n","    super(EncoderBert, self).__init__()\n","    self.encoder = hub.KerasLayer(bert_encoder, name='BERT_encoder')\n","    self.conv_1 = tf.keras.layers.Conv1D(embedding_dim * 4, 1, activation='relu') \n","    self.conv_2 = tf.keras.layers.Conv1D(embedding_dim, 1, activation='relu') \n","    self.lambda_layer = tf.keras.layers.Lambda(lambda x: x[:,:max_len])\n","    self.max_len = max_len\n","\n","  def call(self, x, debug=False):\n","    # x = self.preprocess(input_sequnces)\n","\n","    if debug:\n","      print(f'****************** DEBUG ENCODER BERT ******************')\n","      print(f\"First example\")\n","      print(f'Keys                         : {list(x.keys())}')\n","      print(f'Shape                        : {x[\"input_word_ids\"].shape}')\n","      print(f'Word Ids                     : {x[\"input_word_ids\"][0, :self.max_len]}')\n","      print(f'Input Mask                   : {x[\"input_mask\"][0, :self.max_len]}')\n","      print(f'Type Ids                     : {x[\"input_type_ids\"][0, :self.max_len]}')\n","      \n","    x = self.encoder(x)['sequence_output'] \n","    # encoder_outputs stato intermedio di BERT prima che esegua la traduzione recuperare la metà della lunghezza\n","    # x = self.encoder(x)['encoder_outputs'] \n","    # x = x[int(len(x) / 2) - 1]\n","\n","    if debug:\n","      print()\n","      print(f'Encoder Outputs BERT Shape   : {x.shape}')\n","      print(f'Encoder Outputs BERT Values  : {x[0, :1, :self.max_len]}')\n","\n","    x = self.conv_1(x)\n","    if debug:\n","      print()\n","      print(f'Sequence Conv1 Shape         : {x.shape}')\n","\n","    x = self.conv_2(x)\n","    if debug:\n","      print(f'Sequence Conv2 Shape         : {x.shape}')\n","\n","    x = self.lambda_layer(x)\n","    if debug:\n","      print(f'Sequence Lambda Layer        : {x.shape}')\n","      print()\n","      print(f'Sequence Outputs Values      : {x[0, 0, :self.max_len]}')      \n","      print('*********************************************************') \n","\n","    return x"],"metadata":{"id":"m7v9Y-Lep4CD","executionInfo":{"status":"ok","timestamp":1671267184858,"user_tz":-60,"elapsed":19,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["encoder_bert = EncoderBert(tfhub_handle_encoder, \n","                           EMBEDDING_DIM, \n","                           MAX_SEQ_LENGTH)\n","\n","bert_outputs = encoder_bert(enc_input, debug) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"morr6J7rp-SP","executionInfo":{"status":"ok","timestamp":1671267228348,"user_tz":-60,"elapsed":43508,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"f0e563ca-0a0b-4351-d41f-b71aaf00f099"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_type_ids', 'input_mask', 'input_word_ids']\n","Shape                        : (32, 128)\n","Word Ids                     : [  101  3419  2196 17612  2015  2055  2505  1012   102     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","Type Ids                     : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[ 1.56636700e-01  3.01962942e-02 -1.64500028e-01 -2.63035059e-01\n","  -4.78764653e-01 -2.40052372e-01  1.69600457e-01  7.52705574e-01\n","  -1.78646073e-02 -1.57580733e-01 -1.41511485e-01 -2.39212066e-02\n","   3.23209912e-04  2.16630563e-01  2.82148093e-01  1.65516078e-01\n","  -5.99246807e-02  5.19932449e-01 -3.44489738e-02  3.24362516e-02\n","   1.21833794e-01  7.87354484e-02  8.48811865e-02  1.58281192e-01\n","  -1.47440732e-01  5.36418296e-02  1.91255569e-01 -2.73302138e-01\n","  -1.23670638e-01  2.11973459e-01  1.17391095e-01  4.78979766e-01\n","  -1.94344342e-01  1.35788321e-03  1.50243431e-01 -2.24409401e-01\n","   3.73543471e-01  6.25041500e-02  1.59478724e-01  1.69534422e-03\n","  -3.27148050e-01 -1.69914082e-01 -7.98294023e-02 -2.15564758e-01\n","  -1.93422079e-01 -6.63074374e-01 -3.28575969e+00 -4.40201700e-01\n","   1.01711303e-01 -2.14232117e-01  1.26845390e-01 -4.12845910e-02\n","   2.59186327e-01  4.47164297e-01  1.93186209e-01  3.81701171e-01\n","  -3.62534970e-01 -1.46820724e-01  1.13279127e-01  2.21713021e-01\n","   3.20376396e-01  1.42848700e-01 -1.31182969e-01  5.56073189e-01]]\n","\n","Sequence Conv1 Shape         : (32, 128, 256)\n","Sequence Conv2 Shape         : (32, 128, 64)\n","Sequence Lambda Layer        : (32, 64, 64)\n","\n","Sequence Outputs Values      : [1.621322   0.         0.11909437 0.         0.04455167 0.\n"," 0.27756375 0.77650744 0.0911901  0.79649234 0.         0.\n"," 0.         0.         0.93610424 0.03302285 0.54903203 0.\n"," 1.4030467  1.4426937  0.10696208 0.34030133 0.         0.\n"," 0.05273087 0.16210292 0.9676655  0.28402236 0.         0.\n"," 0.4897042  0.         0.         0.         0.15872946 0.27321714\n"," 0.         0.91499376 0.         0.62635744 0.         0.\n"," 0.         0.         0.25548837 0.4995278  0.9337094  0.\n"," 0.10615837 0.         0.         0.         0.42721328 0.\n"," 0.         0.         0.5775816  0.         0.         0.\n"," 0.03600785 0.         0.         0.        ]\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["## Decoder\n","\n","Predispondo la classe necessaria per la costruzione di un Layer di Decoder"],"metadata":{"id":"ReEQ5rX7aGtl"}},{"cell_type":"markdown","source":["### TOKEN AND POSITION EMBEDDING\n","\n","Implementazione del blocco Embedding per l'utilizzo di vettori posizionali insieme ai vettori di token di parole tramite estensione della classe Layer di Keras. "],"metadata":{"id":"gAu1IXlRZzlq"}},{"cell_type":"code","source":["class TokenAndPositionEmbedding(layers.Layer):\n","  def __init__(self, maxlen, vocab_size, embed_dim):\n","    super(TokenAndPositionEmbedding, self).__init__()\n","    self.maxlen = maxlen\n","    self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n","    self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","  def call(self, x, debug=False):\n","    x = keras.preprocessing.sequence.pad_sequences(x, maxlen=self.maxlen, padding='post')\n","    maxlen = tf.shape(x)[-1]\n","\n","    if debug:\n","      print('********** DEBUG TOKEN AND POSITION EMBEDDING ***********')\n","      print(f'Sequence Max len                          : {maxlen}')\n","      print(f'Sequence Shape                            : {tf.shape(x)}')\n","\n","    positions = tf.range(start=0, limit=maxlen, delta=1)\n","    positions = self.pos_emb(positions)\n","    x = self.token_emb(x)\n","    output = x + positions\n","\n","    if debug:\n","      print(f'Shape TokenAndPositionEmbedding           : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"o9-RSKTqsmUC","executionInfo":{"status":"ok","timestamp":1671267228350,"user_tz":-60,"elapsed":79,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["token_position_it = TokenAndPositionEmbedding(MAX_SEQ_LENGTH, tokenizers.it.get_vocab_size(), EMBEDDING_DIM)\n","\n","inputs_decoder = token_position_it(dec_input, debug)"],"metadata":{"id":"rr_EWQUX8EWP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671267228351,"user_tz":-60,"elapsed":78,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"4d76589c-f11f-45db-d99b-b1922b07b182"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 64\n","Sequence Shape                            : [32 64]\n","Shape TokenAndPositionEmbedding           : (32, 64, 64)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["### LAYER DECODER\n","\n","Implementazione di un blocco di DecoderTransformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"XdLv-6nidKGK"}},{"cell_type":"markdown","source":["#### Layer Decoder"],"metadata":{"id":"dMTKLwd3dRw5"}},{"cell_type":"code","source":["class Decoder(layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DEC'):\n","    super(Decoder, self).__init__()\n","    self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.att2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = keras.Sequential(\n","      [layers.Dense(ff_dim, activation='relu'), layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = layers.LayerNormalization()\n","    self.layernorm2 = layers.LayerNormalization()\n","    self.layernorm3 = layers.LayerNormalization()\n","    self.dropout1 = layers.Dropout(rate)\n","    self.dropout2 = layers.Dropout(rate)\n","    self.dropout3 = layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, inputs, bert_outputs, training=False, debug=False):\n","    attn_output1 = self.att1(query=inputs,\n","                             value=inputs, \n","                             key=inputs, \n","                             use_causal_mask=True)\n","    \n","    attn_output1 = self.dropout1(attn_output1)\n","    out1 = self.layernorm1(inputs + attn_output1)\n","\n","    attn_output2 = self.att2(key=bert_outputs, \n","                             value=bert_outputs, \n","                             query=out1)\n","    \n","    attn_output2 = self.dropout2(attn_output2, training=training)\n","    out2 = self.layernorm2(out1 + attn_output2)\n","\n","    ffn_output = self.ffn(out2)\n","    ffn_output = self.dropout3(ffn_output, training=training)\n","\n","    output = self.layernorm3(out2 + ffn_output)\n","\n","    if debug:\n","      print('******************* DEBUG DECODER ***********************')\n","      print(f'Input Shape                       : {inputs.shape}')\n","      print(f'Shape Outputs Decoder             : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"SO5rYsFpfFS_","executionInfo":{"status":"ok","timestamp":1671267228352,"user_tz":-60,"elapsed":63,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_decoder = decoder(inputs=inputs_decoder, \n","                          bert_outputs=bert_outputs,  \n","                          training=training,\n","                          debug=debug)"],"metadata":{"id":"yysVdkHH8EPH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671267231573,"user_tz":-60,"elapsed":3283,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"f34d262a-c421-4601-cd71-8de1d55041e6"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 64, 64)\n","Shape Outputs Decoder             : (32, 64, 64)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["## TRANSFORMER\n","\n","Implementazione del blocco Transformer tramite estensione della classe Layer di Keras."],"metadata":{"id":"ne4zTOG_NKfV"}},{"cell_type":"code","execution_count":36,"metadata":{"pycharm":{"name":"#%%\n"},"id":"lw2xMCAMC_4M","executionInfo":{"status":"ok","timestamp":1671267231575,"user_tz":-60,"elapsed":24,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"outputs":[],"source":["class TransformerBlock(keras.Model):\n","  def __init__(self, \n","               num_layers, \n","               embed_dim, \n","               num_heads, \n","               ff_dim, \n","               max_len,\n","               vocab_size,\n","               tfhub_handle_encoder,\n","               rate=0.5):\n","    \n","    super(TransformerBlock, self).__init__()\n","\n","    self.num_layers = num_layers\n","\n","    self.token_pos_dec = TokenAndPositionEmbedding(max_len, vocab_size, embed_dim)\n","\n","    self.encoder = EncoderBert(tfhub_handle_encoder, embed_dim, max_len)\n","    self.decoder = [Decoder(max_len, embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n","\n","    self.dropout = layers.Dropout(rate)\n","    self.final_layer = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, training=False, debug=False):\n","    inputs_encoder, inputs_decoder  = inputs\n","\n","    encoder_output = self.encoder(inputs_encoder, debug) \n","\n","    inputs_decoder = self.token_pos_dec(inputs_decoder, debug)\n","\n","    if debug:\n","      print(f'---------------- DEBUG TRANSFORMER BLOCK ----------------')\n","      print(f'inputs_encoder       : {inputs_encoder[\"input_word_ids\"].shape}')\n","      print(f'inputs_decoder       : {inputs_decoder.shape}')      \n","\n","    transformer_output = inputs_decoder\n","      \n","    for i in range(self.num_layers):\n","      transformer_output = self.decoder[i](inputs=transformer_output, \n","                                           bert_outputs=encoder_output, \n","                                           training=training,\n","                                           debug=debug)\n","\n","    transformer_output = self.dropout(transformer_output)\n","    logits = self.final_layer(transformer_output)\n","\n","    if debug:\n","      print(f'Output Shape       : {logits.shape}')\n","      print(f'Output Transformer : {logits[0, :1, :12]}')    \n","      print(f'---------------------------------------------------------')\n","\n","    return logits"]},{"cell_type":"code","source":["transformer = TransformerBlock(NUM_LAYERS, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.it.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               DROPUOT)\n","\n","transformer_output = transformer((enc_input, dec_input), \n","                                 training=training,\n","                                 debug=debug)"],"metadata":{"id":"pr--G0ZZVAMi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671267251908,"user_tz":-60,"elapsed":20354,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"1875f40c-32db-4a59-bfef-90938a953aa2"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_type_ids', 'input_mask', 'input_word_ids']\n","Shape                        : (32, 128)\n","Word Ids                     : [  101  3419  2196 17612  2015  2055  2505  1012   102     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","Type Ids                     : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[ 1.56636700e-01  3.01962942e-02 -1.64500028e-01 -2.63035059e-01\n","  -4.78764653e-01 -2.40052372e-01  1.69600457e-01  7.52705574e-01\n","  -1.78646073e-02 -1.57580733e-01 -1.41511485e-01 -2.39212066e-02\n","   3.23209912e-04  2.16630563e-01  2.82148093e-01  1.65516078e-01\n","  -5.99246807e-02  5.19932449e-01 -3.44489738e-02  3.24362516e-02\n","   1.21833794e-01  7.87354484e-02  8.48811865e-02  1.58281192e-01\n","  -1.47440732e-01  5.36418296e-02  1.91255569e-01 -2.73302138e-01\n","  -1.23670638e-01  2.11973459e-01  1.17391095e-01  4.78979766e-01\n","  -1.94344342e-01  1.35788321e-03  1.50243431e-01 -2.24409401e-01\n","   3.73543471e-01  6.25041500e-02  1.59478724e-01  1.69534422e-03\n","  -3.27148050e-01 -1.69914082e-01 -7.98294023e-02 -2.15564758e-01\n","  -1.93422079e-01 -6.63074374e-01 -3.28575969e+00 -4.40201700e-01\n","   1.01711303e-01 -2.14232117e-01  1.26845390e-01 -4.12845910e-02\n","   2.59186327e-01  4.47164297e-01  1.93186209e-01  3.81701171e-01\n","  -3.62534970e-01 -1.46820724e-01  1.13279127e-01  2.21713021e-01\n","   3.20376396e-01  1.42848700e-01 -1.31182969e-01  5.56073189e-01]]\n","\n","Sequence Conv1 Shape         : (32, 128, 256)\n","Sequence Conv2 Shape         : (32, 128, 64)\n","Sequence Lambda Layer        : (32, 64, 64)\n","\n","Sequence Outputs Values      : [0.15328133 1.447158   0.48964447 0.         0.         0.\n"," 0.18216497 0.         0.37030697 0.         0.         0.\n"," 0.11641465 0.         0.         0.         0.11459622 0.\n"," 0.         0.12850861 0.         0.         0.10274117 0.70783913\n"," 0.5326653  0.         0.43947563 0.         0.         0.\n"," 0.         0.7117469  0.         0.         0.         0.09589265\n"," 0.21650028 0.8947789  0.         0.5469902  0.         0.45389092\n"," 0.         0.         0.48353723 0.36515838 0.3021909  0.\n"," 0.         0.         0.         0.09130949 0.44151303 0.393246\n"," 1.060056   0.84497535 0.         0.         0.24102154 0.8912035\n"," 0.16639967 0.         0.         0.3301409 ]\n","*********************************************************\n","********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 64\n","Sequence Shape                            : [32 64]\n","Shape TokenAndPositionEmbedding           : (32, 64, 64)\n","*********************************************************\n","---------------- DEBUG TRANSFORMER BLOCK ----------------\n","inputs_encoder       : (32, 128)\n","inputs_decoder       : (32, 64, 64)\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 64, 64)\n","Shape Outputs Decoder             : (32, 64, 64)\n","*********************************************************\n","Output Shape       : (32, 64, 2706)\n","Output Transformer : [[-0.20225531  0.16793665  0.11145713  0.35344678  0.04242659 -0.12163515\n","  -0.08456438 -0.06443792  0.1421227  -0.17656861  0.1275523  -0.05325285]]\n","---------------------------------------------------------\n"]}]},{"cell_type":"code","source":["transformer.summary()"],"metadata":{"id":"_kwqvJSu8liP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671267251910,"user_tz":-60,"elapsed":55,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"8f703655-25ad-4eaf-9602-958ea28dcc69"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer_block\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," token_and_position_embeddin  multiple                 177280    \n"," g_1 (TokenAndPositionEmbedd                                     \n"," ing)                                                            \n","                                                                 \n"," encoder_bert_1 (EncoderBert  multiple                 109695553 \n"," )                                                               \n","                                                                 \n"," DEC (Decoder)               multiple                  267856    \n","                                                                 \n"," dropout_8 (Dropout)         multiple                  0         \n","                                                                 \n"," dense_4 (Dense)             multiple                  175890    \n","                                                                 \n","=================================================================\n","Total params: 110,316,579\n","Trainable params: 834,338\n","Non-trainable params: 109,482,241\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["### Addestramento modello con ottimizzatore ADAM"],"metadata":{"id":"IFmcHTSDTvYk"}},{"cell_type":"markdown","source":["### Compilazione"],"metadata":{"id":"tiuqPlHo0Z0n"}},{"cell_type":"code","source":["transformer.compile(\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_ADAM, \n","                                       beta_1=BETA_1, \n","                                       beta_2=BETA_2),\n","    metrics=[keras.metrics.SparseCategoricalAccuracy()])"],"metadata":{"id":"bOyqCyjIr-L2","executionInfo":{"status":"ok","timestamp":1671267251913,"user_tz":-60,"elapsed":34,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 save_best_only=True)\n","\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"],"metadata":{"id":"3hurmpSjJ_dT","executionInfo":{"status":"ok","timestamp":1671267251914,"user_tz":-60,"elapsed":34,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["### Addestramento"],"metadata":{"id":"Day7C7Qh0b4G"}},{"cell_type":"code","source":["start = datetime.datetime.now()\n","\n","initial_epoch = 0\n","epochs = 1\n","\n","for val_dataset in validation_dataset:\n","  history = transformer.fit(train_dataset,\n","                             initial_epoch=initial_epoch,\n","                             epochs=epochs,\n","                             shuffle=True,\n","                             validation_data=val_dataset,\n","                             callbacks=[tensorboard_callback, \n","                                       cp_callback])\n","  \n","  initial_epoch = epochs\n","  epochs = epochs + 1\n","\n","  print(initial_epoch)\n","  print(epochs)\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"etOGtBcer9yi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b6205c4-b677-47f2-f22c-4c923d2395e5","executionInfo":{"status":"ok","timestamp":1671269964004,"user_tz":-60,"elapsed":2698740,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["500/500 [==============================] - 512s 1s/step - loss: 4.2261 - sparse_categorical_accuracy: 0.8031 - val_loss: 1.5212 - val_sparse_categorical_accuracy: 0.8411\n","1\n","2\n","Epoch 2/2\n","500/500 [==============================] - 508s 1s/step - loss: 1.2084 - sparse_categorical_accuracy: 0.8555 - val_loss: 0.9183 - val_sparse_categorical_accuracy: 0.8722\n","2\n","3\n","Epoch 3/3\n","500/500 [==============================] - 506s 1s/step - loss: 0.9270 - sparse_categorical_accuracy: 0.8731 - val_loss: 0.8239 - val_sparse_categorical_accuracy: 0.8798\n","3\n","4\n","Epoch 4/4\n","500/500 [==============================] - 506s 1s/step - loss: 0.8427 - sparse_categorical_accuracy: 0.8794 - val_loss: 0.7756 - val_sparse_categorical_accuracy: 0.8837\n","4\n","5\n","Epoch 5/5\n","500/500 [==============================] - 499s 998ms/step - loss: 0.7933 - sparse_categorical_accuracy: 0.8832 - val_loss: 0.7369 - val_sparse_categorical_accuracy: 0.8873\n","5\n","6\n","Tempo necessario per l'addestramento: 0:44:58.252168\n"]}]},{"cell_type":"markdown","source":["### Valutazione dell'addestramento\n","Avendo in output il log ed i risultati dell'addestramento, possiamo visualizzare\n","queste informazioni relativamente alle metriche di interesse."],"metadata":{"id":"L0w4wF79UhAp"}},{"cell_type":"code","source":["# visualizzazione andamento addestramento\n","# su un grafico composto da due sub-plot\n","# uno per il loss, l'altro per l'accuracy\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n","\n","# Errore durante l'addestramento\n","ax1.plot(history.history['loss'], label='Loss')\n","ax1.plot(history.history['val_loss'], label='Validation Loss')\n","ax1.set_title('Training Loss')\n","ax1.legend()\n","\n","# Accuratezza durante l'addestramento\n","ax2.plot(history.history['sparse_categorical_accuracy'], label='Accuracy')\n","ax2.plot(history.history['val_sparse_categorical_accuracy'], label='Validation Accuracy')\n","ax2.set_title('Training Accuracy')\n","ax2.legend()\n","\n","plt.show()"],"metadata":{"id":"RpXR2p5VAdoG","colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"status":"ok","timestamp":1671269964008,"user_tz":-60,"elapsed":34,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"ba92911c-77d1-4f07-fa1b-2741a61bb4f8"},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x360 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### Addestramento 2"],"metadata":{"id":"FOXy7yFkxt4q"}},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"bxKgmkMrxsZr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671113212778,"user_tz":-60,"elapsed":1827,"user":{"displayName":"Daniele Badiali","userId":"15682358814001311695"}},"outputId":"a448d5cd-e3ab-4a64-dcb3-ec10d0f27866"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7feee87372e0>"]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","history = transformer.fit(train_dataset,\n","                          initial_epoch=16,\n","                          epochs=EPOCHS_ADAM+10,\n","                          shuffle=True,\n","                          validation_data=validation_dataset,\n","                          callbacks=[tensorboard_callback, \n","                                     cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KHTgL6iyyBU2","outputId":"91e098cc-3275-48e4-e4f7-6e6a467b6bfd","executionInfo":{"status":"ok","timestamp":1671121816990,"user_tz":-60,"elapsed":8602355,"user":{"displayName":"Daniele Badiali","userId":"15682358814001311695"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 17/30\n","563/563 [==============================] - 620s 1s/step - loss: 0.8929 - sparse_categorical_accuracy: 0.8717 - val_loss: 0.7899 - val_sparse_categorical_accuracy: 0.8802\n","Epoch 18/30\n","563/563 [==============================] - 611s 1s/step - loss: 0.7898 - sparse_categorical_accuracy: 0.8803 - val_loss: 0.7265 - val_sparse_categorical_accuracy: 0.8851\n","Epoch 19/30\n","563/563 [==============================] - 609s 1s/step - loss: 0.7325 - sparse_categorical_accuracy: 0.8843 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.8883\n","Epoch 20/30\n","563/563 [==============================] - 593s 1s/step - loss: 0.6923 - sparse_categorical_accuracy: 0.8871 - val_loss: 0.6496 - val_sparse_categorical_accuracy: 0.8906\n","Epoch 21/30\n","563/563 [==============================] - 593s 1s/step - loss: 0.6601 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.6223 - val_sparse_categorical_accuracy: 0.8930\n","Epoch 22/30\n","563/563 [==============================] - 591s 1s/step - loss: 0.6328 - sparse_categorical_accuracy: 0.8916 - val_loss: 0.6006 - val_sparse_categorical_accuracy: 0.8949\n","Epoch 23/30\n","563/563 [==============================] - 608s 1s/step - loss: 0.6093 - sparse_categorical_accuracy: 0.8938 - val_loss: 0.5782 - val_sparse_categorical_accuracy: 0.8969\n","Epoch 24/30\n","563/563 [==============================] - 592s 1s/step - loss: 0.5890 - sparse_categorical_accuracy: 0.8955 - val_loss: 0.5577 - val_sparse_categorical_accuracy: 0.8987\n","Epoch 25/30\n","563/563 [==============================] - 592s 1s/step - loss: 0.5703 - sparse_categorical_accuracy: 0.8971 - val_loss: 0.5412 - val_sparse_categorical_accuracy: 0.9001\n","Epoch 26/30\n","563/563 [==============================] - 611s 1s/step - loss: 0.5528 - sparse_categorical_accuracy: 0.8988 - val_loss: 0.5263 - val_sparse_categorical_accuracy: 0.9017\n","Epoch 27/30\n","563/563 [==============================] - 593s 1s/step - loss: 0.5377 - sparse_categorical_accuracy: 0.9003 - val_loss: 0.5122 - val_sparse_categorical_accuracy: 0.9031\n","Epoch 28/30\n","563/563 [==============================] - 592s 1s/step - loss: 0.5223 - sparse_categorical_accuracy: 0.9018 - val_loss: 0.4977 - val_sparse_categorical_accuracy: 0.9047\n","Epoch 29/30\n","563/563 [==============================] - 599s 1s/step - loss: 0.5091 - sparse_categorical_accuracy: 0.9033 - val_loss: 0.4858 - val_sparse_categorical_accuracy: 0.9064\n","Epoch 30/30\n","563/563 [==============================] - 608s 1s/step - loss: 0.4957 - sparse_categorical_accuracy: 0.9047 - val_loss: 0.4746 - val_sparse_categorical_accuracy: 0.9075\n","Tempo necessario per l'addestramento: 2:23:22.123092\n"]}]},{"cell_type":"markdown","source":["### Test del modello\n","La seguente cella permette di caricare l'ultimo checkpoint dell'addestramento\n","precedentemente salvato."],"metadata":{"id":"ReOkcBp2WHWW"}},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"5PIf_6-RSBb1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Translate:\n","  def __init__(self, transformer_block, tokenizers, tokenizer_bert):\n","    self.transformer = transformer_block\n","    self.tokenizers = tokenizers\n","    self.tokenizer_bert = tokenizer_bert\n","\n","  def predict(self, input_text, max_length):\n","    if input_text is None:\n","      input_text = input_data[np.random.choice(len(input_data))]\n","      print(input_text)\n","\n","    inputs_bert = self.tokenizer_bert(input_text)\n","\n","    start_end = self.tokenizers.it.tokenize([''])[0]\n","    start = start_end[0][tf.newaxis]\n","    end = (start_end[1][tf.newaxis]).numpy()[0]\n","\n","    output_array = tf.TensorArray(dtype=tf.int64, size=max_length, dynamic_size=True)\n","    output_array = output_array.write(0, start)     \n","\n","    out_words = []\n","\n","    for i in tf.range(max_length):\n","      # decodifica e recupero probabilità di output\n","      output = tf.transpose(output_array.stack())\n","      \n","      transformer_output = transformer([inputs_bert, output], \n","                                        training=False,\n","                                        debug=False)\n","\n","      predictions = transformer_output[:, -1:, :]\n","\n","      # selezione della parola più probabile\n","      predict = tf.argmax(predictions, -1)\n","      pred_values = (K.argmax(transformer_output, axis=-1)).numpy()\n","    \n","      # inserimento della parola nella sequenza di output\n","      output_array = output_array.write(i+1, [pred_values[0][i]])\n","\n","      if pred_values[0][i] == end:\n","        break\n","\n","    output = tf.transpose(output_array.stack())\n","    text = tokenizers.it.detokenize(output)[0]  \n","\n","    tokens = tokenizers.it.lookup(output)[0]\n","\n","    return text, tokens"],"metadata":{"id":"L2PEoJVb1V8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_sequences = [test_input_data[41], test_input_data[30], test_input_data[10], \n","                  test_input_data[57], test_input_data[82], test_input_data[15], \n","                  test_input_data[4], test_input_data[42]]\n","\n","translate = Translate(transformer_block=transformer,\n","                      tokenizers=tokenizers,\n","                      tokenizer_bert=tokenizer_encoder)\n","\n","for test_sequence in test_sequences:\n","  text, token = translate.predict(tf.constant([test_sequence]), MAX_SEQ_LENGTH)\n","\n","  print(f'{\"Input:\":15s}: {test_sequence}')\n","  print(f'{\"Prediction\":15s}: {text.numpy().decode(\"utf-8\")}')  \n","  # print(f'tokens : {token}')\n","  # print(target_data[41])\n","  # break\n","  print('---------------------------------------------')\n","\n","print(test_target_data[41])\n","print(test_target_data[30])\n","print(test_target_data[10])\n","print(test_target_data[57])\n","print(test_target_data[82])\n","print(test_target_data[15])\n","print(test_target_data[4])\n","print(test_target_data[42])"],"metadata":{"id":"udIjI2jZWR6g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671121825147,"user_tz":-60,"elapsed":7809,"user":{"displayName":"Daniele Badiali","userId":"15682358814001311695"}},"outputId":"8be5f347-3cc0-4175-9cf6-2c7f9ff04b27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input:         : I know you used to live in Boston.\n","Prediction     : so che ha detto che ha detto a boston .\n","---------------------------------------------\n","Input:         : Do you still talk to Tom in French?\n","Prediction     : lei ha ancora in francese con tom ?\n","---------------------------------------------\n","Input:         : They are leaving for Tokyo tomorrow.\n","Prediction     : noi abbiamo avvita per tre anni fa .\n","---------------------------------------------\n","Input:         : That might work, but it's too risky.\n","Prediction     : lo sa che sia troppo , pero e successo .\n","---------------------------------------------\n","Input:         : Tom said Mary should do that, too.\n","Prediction     : tom ha detto che mary , pero mary fosse cosi , vero .\n","---------------------------------------------\n","Input:         : I've already told Tom what you did.\n","Prediction     : ho detto che tom ha detto che tom e successo .\n","---------------------------------------------\n","Input:         : Wake me up early tomorrow morning.\n","Prediction     : mi piace la sua madre domani pomeriggio .\n","---------------------------------------------\n","Input:         : Have any of you ever talked to Tom?\n","Prediction     : voi avete mai visto tom con tom ?\n","---------------------------------------------\n","Lo so che una volta vivevate a Boston.\n","Parla ancora con Tom in francese?\n","Loro partono per Tokyo domani.\n","Potrebbe funzionare, però è troppo rischioso.\n","Anche Tom ha detto che Mary dovrebbe farlo.\n","Ho già detto a Tom quello che avete fatto.\n","Svegliami presto domani mattina.\n","Qualcuno di voi ha mai parlato con Tom?\n"]}]},{"cell_type":"markdown","source":["### Tensorboard"],"metadata":{"id":"YJf4hjv4PMAJ"}},{"cell_type":"code","source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"metadata":{"id":"vcwHe7VJWt-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_dir"],"metadata":{"id":"7AB28JmGPQgi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir drive/MyDrive/BERT/logs/fit/20221026-134720"],"metadata":{"id":"2ZkkDKVwPT2O"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":["FOXy7yFkxt4q","YJf4hjv4PMAJ"]},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}