{"cells":[{"cell_type":"code","source":["!pip install -q -U 'tensorflow-text==2.8.*'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NE4enZGpvMRX","executionInfo":{"status":"ok","timestamp":1670280015728,"user_tz":-60,"elapsed":67693,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"47e01be5-f3d3-4ed3-b8a1-f74b880a9dd9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 4.9 MB 5.2 MB/s \n","\u001b[K     |████████████████████████████████| 498.0 MB 13 kB/s \n","\u001b[K     |████████████████████████████████| 462 kB 66.2 MB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 60.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.4 MB 59.6 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install -q tf-models-official"],"metadata":{"id":"FPtWz_qHuofc","executionInfo":{"status":"ok","timestamp":1670280087913,"user_tz":-60,"elapsed":72196,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"844c3636-746a-4595-a313-920b2bd42562"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 2.3 MB 4.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 54.1 MB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 66.1 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 55.9 MB/s \n","\u001b[K     |████████████████████████████████| 588.3 MB 20 kB/s \n","\u001b[K     |████████████████████████████████| 238 kB 35.5 MB/s \n","\u001b[K     |████████████████████████████████| 38.2 MB 60.5 MB/s \n","\u001b[K     |████████████████████████████████| 118 kB 73.5 MB/s \n","\u001b[K     |████████████████████████████████| 662 kB 75.0 MB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 70.1 MB/s \n","\u001b[K     |████████████████████████████████| 439 kB 81.7 MB/s \n","\u001b[K     |████████████████████████████████| 6.0 MB 78.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.7 MB 76.8 MB/s \n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"hJy-juNOpUOY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670280113213,"user_tz":-60,"elapsed":25314,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"5547bc57-c52c-4223-bc0c-7b614a4e9f16"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"id":"UaAiWsEuC_4K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670280122905,"user_tz":-60,"elapsed":9704,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"98fda0bd-3948-4735-c24d-056f97a7a8cc"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.8.0 and strictly below 2.11.0 (nightly versions are not supported). \n"," The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n","Some things might work, some things might not.\n","If you were to encounter a bug, do not file an issue.\n","If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n","You can find the compatibility matrix in TensorFlow Addon's readme:\n","https://github.com/tensorflow/addons\n","  warnings.warn(\n"]}],"source":["import os\n","import re\n","import time\n","import unicodedata\n","import datetime\n","import pathlib\n","\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","from keras import layers\n","\n","import tensorflow_hub as hub\n","import tensorflow_models as tfm\n","\n","import tensorflow_text as text\n","from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"]},{"cell_type":"code","source":["tf.get_logger().setLevel('ERROR')\n","tf.config.run_functions_eagerly(True)"],"metadata":{"id":"uKEqRlKowOQS","executionInfo":{"status":"ok","timestamp":1670280122907,"user_tz":-60,"elapsed":23,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Variabili Globali"],"metadata":{"id":"HRe16D-rUBLA"}},{"cell_type":"code","source":["# PARAMETRI GLOBALI\n","root_folder = 'drive/MyDrive/BERT/'\n","\n","# DATI\n","data_folder_name = 'data'\n","train_filename = 'ita.txt'\n","\n","DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n","train_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n","\n","# PATH LOG Tensorboard\n","PATH_LOG = 'logs/fit/transformer_no_bert_v3'\n","PATH_LOG = os.path.abspath(os.path.join(root_folder, PATH_LOG))\n","log_dir =  os.path.abspath(os.path.join(PATH_LOG, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))) \n","\n","# PATH WEIGHTS Tensorboard\n","PATH_WEIGHTS = 'weights/transformer_nobert_v3'\n","PATH_WEIGHTS = os.path.abspath(os.path.join(root_folder, PATH_WEIGHTS))\n","checkpoint_path = os.path.abspath(os.path.join(PATH_WEIGHTS, 'cp.ckpt'))\n","weights = os.path.abspath(os.path.join(PATH_WEIGHTS, 'weights_30_epochs.h5'))\n","model_weights = os.path.abspath(os.path.join(PATH_WEIGHTS, 'model_weights_30_epochs.h5'))\n","\n","# MODELLO TOKENIZER\n","model_name = 'tokenizer_en_it_model'\n","tokenizer_folder_name = 'tokenizer'\n","\n","TOKEN_PATH = os.path.abspath(os.path.join(root_folder, tokenizer_folder_name))\n","tokenizer_filenamepath = os.path.abspath(os.path.join(TOKEN_PATH, model_name))"],"metadata":{"id":"ewLgCIuEpczO","executionInfo":{"status":"ok","timestamp":1670280122908,"user_tz":-60,"elapsed":18,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# parametri per il modello\n","INPUT_COLUMN = 'input'\n","TARGET_COLUMN = 'target'\n","TARGET_FOR_INPUT = 'target_for_input'\n","NUM_SAMPLES = 20800 # portato da 10.000 a 100.000\n","TRAIN = 16000\n","\n","MAX_VOCAB_SIZE = 20000 # portato da 20.0000 a 200.000\n","EMBEDDING_DIM = 16  # --> 256  Densa non lineare relu --> 64  Densa non lineare relu (oppure Conv1D kernel=1)\n","HIDDEN_DIM = 1024 # numero di celle nei layer ricorrenti nascosti\n","\n","BATCH_SIZE = 32\n","BUFFER_SIZE = 2000\n","EPOCHS = 50\n","MAX_SEQ_LENGTH = 8 # --> portare a 10 con layer 'lambda'[:,:10]\n","\n","NUM_LAYERS = 1 # Numero di layer di Encoder e Decoder del Transformer\n","NUM_HEADS = 4 # Numero di meccanismi di multi-head attention\n","FF_DIM = 8 # Numero di celle dei Layer Feed Forward\n","DROPUOT = 0.5\n","\n","LEARNING_RATE=0.001\n","\n","# IMPOSTO IL DEBUG A TRUE \n","debug = True\n","training = True"],"metadata":{"id":"8CN-4Uzoqbjl","executionInfo":{"status":"ok","timestamp":1670280122909,"user_tz":-60,"elapsed":18,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### Caricamento Dati"],"metadata":{"id":"LU7AorKXT8K7"}},{"cell_type":"code","source":["# Caricamento dataset: frasi in inglese, frasi in italiano\n","df = pd.read_csv(\n","    train_filenamepath,\n","    sep=\"\\t\",\n","    header=None,\n","    names=[INPUT_COLUMN, TARGET_COLUMN],\n","    usecols=[0,1],\n","    nrows=NUM_SAMPLES\n",")\n","\n","print(df.iloc[10012:10016], '\\n')\n","\n","# Preprocessing dei dati di Input\n","input_data = df[INPUT_COLUMN].tolist()\n","\n","# Preprocessing dei dati Target con aggiunta del token di fine frase\n","target_data = df[TARGET_COLUMN].tolist()\n","\n","train_input_data = input_data[:TRAIN]\n","train_target_data = target_data[:TRAIN]\n","\n","test_input_data = input_data[TRAIN:]\n","test_target_data = target_data[TRAIN:]\n","\n","print('-----------TRAIN SET--------------')\n","print(train_input_data[-4:])\n","print(train_target_data[-4:])\n","print('-----------TEST SET---------------')\n","print(test_input_data[-4:])\n","print(test_target_data[-4:])\n"],"metadata":{"id":"-K_qU8ouq5lO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670280123590,"user_tz":-60,"elapsed":697,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"61b5dae7-255a-44fe-dd9a-91a462ea88f3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["               input             target\n","10012  They're free.       Sono libere.\n","10013  They're free.  Loro sono libere.\n","10014  They're gone.       Sono andati.\n","10015  They're gone.  Loro sono andati. \n","\n","-----------TRAIN SET--------------\n","['Tom told them.', 'Tom told them.', 'Tom trusts me.', 'Tom trusts us.']\n","[\"Tom l'ha detto a loro.\", 'Tom lo disse a loro.', 'Tom si fida di me.', 'Tom si fida di noi.']\n","-----------TEST SET---------------\n","['Just let me go.', 'Just move back.', 'Just move back.', 'Just move back.']\n","['Lasciatemi andare e basta.', 'Indietreggia e basta.', 'Indietreggi e basta.', 'Indietreggiate e basta.']\n"]}]},{"cell_type":"markdown","source":["### Tokenizer\n","\n","Carico il modello di tokenizer creato utilizzzando il set di dati a disposizione"],"metadata":{"id":"njyY9RWlFMWu"}},{"cell_type":"code","source":["tokenizers = tf.saved_model.load(tokenizer_filenamepath)"],"metadata":{"id":"-4B-HWWcmsmz","executionInfo":{"status":"ok","timestamp":1670280131223,"user_tz":-60,"elapsed":7640,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["print(input_data[-2:])\n","print(tokenizers.en.tokenize(input_data[-2:]))\n","print(keras.preprocessing.sequence.pad_sequences(tokenizers.en.tokenize(input_data[-2:]).numpy(), maxlen=MAX_SEQ_LENGTH, padding='post'))\n","print(tokenizers.en.detokenize(tokenizers.en.tokenize(input_data[-2:])))\n","print('------------------------------------------------------------------')\n","print(target_data[-2:])\n","print(tokenizers.it.tokenize(target_data[-2:]))\n","print(keras.preprocessing.sequence.pad_sequences(tokenizers.it.tokenize(target_data[-2:]).numpy(), maxlen=MAX_SEQ_LENGTH, padding='post'))\n","print(tokenizers.it.detokenize(tokenizers.it.tokenize(target_data[-2:])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKEFeDdGFIGS","executionInfo":{"status":"ok","timestamp":1670280132994,"user_tz":-60,"elapsed":1796,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"b27e6c27-54d2-416a-fe1b-730537360a67"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["['Just move back.', 'Just move back.']\n","<tf.RaggedTensor [[2, 138, 718, 162, 11, 3],\n"," [2, 138, 718, 162, 11, 3]]>\n","[[  2 138 718 162  11   3   0   0]\n"," [  2 138 718 162  11   3   0   0]]\n","tf.Tensor([b'just move back .' b'just move back .'], shape=(2,), dtype=string)\n","------------------------------------------------------------------\n","['Indietreggi e basta.', 'Indietreggiate e basta.']\n","<tf.RaggedTensor [[2, 67, 6903, 6363, 2286, 30, 647, 11, 3],\n"," [2, 67, 6903, 6363, 4956, 30, 647, 11, 3]]>\n","[[  67 6903 6363 2286   30  647   11    3]\n"," [  67 6903 6363 4956   30  647   11    3]]\n","tf.Tensor([b'indietreggi e basta .' b'indietreggiate e basta .'], shape=(2,), dtype=string)\n"]}]},{"cell_type":"markdown","source":["### Creazione dataset\n","Utilizzo della libreria tf.data per la gestione del dataset da utilizzare.\n","Verranno creati batch di esempi che verranno utilizzati durante l'addestramento."],"metadata":{"id":"5QIDajkEsVU1"}},{"cell_type":"code","source":["def prepare_batch(en, it):\n","  zero = tf.zeros([BATCH_SIZE, MAX_SEQ_LENGTH], tf.int64)\n","  en = tokenizers.en.tokenize(en) # Output is ragged.\n","  en = tf.concat([en, zero], 1)\n","  en = en[:, :MAX_SEQ_LENGTH]     # Trim to MAX_TOKENS.\n","  en = en.to_tensor()             # Convert to 0-padded dense Tensor\n","\n","  it = tokenizers.it.tokenize(it)\n","  it_inputs = it[:, :-1].to_tensor()  # Drop the [END] tokens\n","  it_labels = it[:, 1:].to_tensor()   # Drop the [START] tokens\n","  \n","  it_inputs = tf.concat([it_inputs, zero], 1)\n","  it_inputs = it_inputs[:, :(MAX_SEQ_LENGTH)]\n","\n","  it_labels = tf.concat([it_labels, zero], 1)\n","  it_labels = it_labels[:, :(MAX_SEQ_LENGTH)]\n","\n","  return (en, it_inputs), it_labels"],"metadata":{"id":"ccH3jHoABPzV","executionInfo":{"status":"ok","timestamp":1670280132995,"user_tz":-60,"elapsed":17,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def make_batches(ds):\n","  return (\n","      ds\n","      .shuffle(BUFFER_SIZE)\n","      .batch(BATCH_SIZE)\n","      .map(prepare_batch, tf.data.AUTOTUNE)\n","      .prefetch(buffer_size=tf.data.AUTOTUNE))"],"metadata":{"id":"l_dswlCiBTdR","executionInfo":{"status":"ok","timestamp":1670280132996,"user_tz":-60,"elapsed":16,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Definizione del dataset\n","# [from_tensor_slices] permette di recuperare batch\n","# di esempi dai dataset di riferimento\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_input_data, train_target_data))\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_input_data, test_target_data))\n","\n","# impostazione del recupero di esempi presi in maniera\n","# casuale in gruppi di [BATCH_SIZE] tra quelli disponibili\n","train_dataset = make_batches(train_dataset)\n","test_dataset = make_batches(test_dataset)"],"metadata":{"id":"tktJ5YuIsYe3","executionInfo":{"status":"ok","timestamp":1670280134479,"user_tz":-60,"elapsed":1497,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c2ae92a8-2130-4ed9-c39f-673623abccca"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Recupero un batch di esempi per la verifica delle classi custom che andrò a creare\n","for (en_input, it_input), it_target in train_dataset.take(1):\n","  print(f'Shape en input           : {en_input.shape}')\n","  print(f'Example en input         : {en_input[0]}')  \n","  print('-------------------------------------------------------')\n","  print(f'Shape it input           : {it_input.shape}')\n","  print(f'Example it input         : {it_input[0]}')  \n","  print(f'Shape it input           : {it_target.shape}')\n","  print(f'Example it target        : {it_target[0]}')  "],"metadata":{"id":"VH_aKPlV_AWA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670280135761,"user_tz":-60,"elapsed":1303,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"1913120a-1f52-4f92-cb77-eb150d0068e2"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape en input           : (32, 8)\n","Example en input         : [   2   34    8   38 1432   11    3    0]\n","-------------------------------------------------------\n","Shape it input           : (32, 8)\n","Example it input         : [   2   64 3201   11    0    0    0    0]\n","Shape it input           : (32, 8)\n","Example it target        : [  64 3201   11    3    0    0    0    0]\n"]}]},{"cell_type":"markdown","source":["### Token and Position Embedding\n","\n","Implementazione del blocco Embedding per l'utilizzo di vettori posizionali insieme ai vettori di token di parole tramite estensione della classe Layer di Keras"],"metadata":{"id":"gAu1IXlRZzlq"}},{"cell_type":"code","source":["class TokenAndPositionEmbedding(layers.Layer):\n","  def __init__(self, maxlen, vocab_size, embed_dim):\n","    super(TokenAndPositionEmbedding, self).__init__()\n","    self.maxlen = maxlen\n","    self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n","    self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","  def call(self, x, debug=False):\n","    x = keras.preprocessing.sequence.pad_sequences(x, maxlen=self.maxlen, padding='post')\n","    maxlen = tf.shape(x)[-1]\n","\n","    if debug:\n","      print('********** DEBUG TOKEN AND POSITION EMBEDDING ***********')\n","      print(f'Sequence Max len                          : {maxlen}')\n","      print(f'Sequence Shape                            : {tf.shape(x)}')\n","\n","    positions = tf.range(start=0, limit=maxlen, delta=1)\n","    positions = self.pos_emb(positions)\n","    x = self.token_emb(x)\n","    output = x + positions\n","\n","    if debug:\n","      print(f'Shape TokenAndPositionEmbedding           : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"o9-RSKTqsmUC","executionInfo":{"status":"ok","timestamp":1670280135762,"user_tz":-60,"elapsed":12,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["token_position_en = TokenAndPositionEmbedding(MAX_SEQ_LENGTH, tokenizers.en.get_vocab_size(), EMBEDDING_DIM)\n","token_position_it = TokenAndPositionEmbedding(MAX_SEQ_LENGTH, tokenizers.it.get_vocab_size(), EMBEDDING_DIM)\n","\n","inputs_encoder = token_position_en(en_input, debug)\n","inputs_decoder = token_position_it(it_input, debug)"],"metadata":{"id":"rr_EWQUX8EWP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670280136194,"user_tz":-60,"elapsed":441,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"3bc17369-4a65-4cce-aa71-99d29b4585bb"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 8\n","Sequence Shape                            : [32  8]\n","Shape TokenAndPositionEmbedding           : (32, 8, 16)\n","*********************************************************\n","********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 8\n","Sequence Shape                            : [32  8]\n","Shape TokenAndPositionEmbedding           : (32, 8, 16)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["### Encoder\n","\n","Implmentazione di un blocco di EncoderTransformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"_iq7Y-d4eRd8"}},{"cell_type":"code","source":["class Encoder(layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='ENC'):\n","    super(Encoder, self).__init__()\n","    self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = keras.Sequential(\n","      [layers.Dense(ff_dim, activation='relu'), layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = layers.LayerNormalization()\n","    self.layernorm2 = layers.LayerNormalization()\n","    self.dropout1 = layers.Dropout(rate)\n","    self.dropout2 = layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, inputs, training=False, debug=False):\n","    attn_output = self.att(query=inputs,\n","                           value=inputs, \n","                           key=inputs)\n","    \n","    attn_output = self.dropout1(attn_output)\n","    out1 = self.layernorm1(inputs + attn_output)\n","\n","    ffn_output = self.ffn(out1)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","\n","    output = self.layernorm2(out1 + ffn_output)\n","\n","    if debug:\n","      print('********************* DEBUG ENCODER *********************')\n","      print(f'Shape Input Layer Encoder       : {inputs.shape}')\n","      print(f'Shape Output Layer Encoder      : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"joTBTlWF8ETD","executionInfo":{"status":"ok","timestamp":1670280136196,"user_tz":-60,"elapsed":8,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["encoder = Encoder(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_encoder = encoder(inputs=inputs_encoder,\n","                          training=training, \n","                          debug=debug)"],"metadata":{"id":"JaIzBxFCfKe9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670280141568,"user_tz":-60,"elapsed":5378,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"9e123dad-a949-4874-9fc6-7201dce2c8d8"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG ENCODER *********************\n","Shape Input Layer Encoder       : (32, 8, 16)\n","Shape Output Layer Encoder      : (32, 8, 16)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["### Decoder\n","\n","Implementazione di un blocco di DecoderTransformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"grNE3Ww9e6Av"}},{"cell_type":"code","source":["class Decoder(layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DEC'):\n","    super(Decoder, self).__init__()\n","    self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.att2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = keras.Sequential(\n","      [layers.Dense(ff_dim, activation='relu'), layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = layers.LayerNormalization()\n","    self.layernorm2 = layers.LayerNormalization()\n","    self.layernorm3 = layers.LayerNormalization()\n","    self.dropout1 = layers.Dropout(rate)\n","    self.dropout2 = layers.Dropout(rate)\n","    self.dropout3 = layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, inputs, encoder_output, training=False, debug=False):\n","    attn_output1 = self.att1(query=inputs,\n","                             value=inputs, \n","                             key=inputs, \n","                             use_causal_mask=True)\n","    \n","    attn_output1 = self.dropout1(attn_output1)\n","    out1 = self.layernorm1(inputs + attn_output1)\n","\n","    attn_output2 = self.att2(key=encoder_output, \n","                             value=encoder_output, \n","                             query=out1)\n","    \n","    attn_output2 = self.dropout2(attn_output2, training=training)\n","    out2 = self.layernorm2(out1 + attn_output2)\n","\n","    ffn_output = self.ffn(out2)\n","    ffn_output = self.dropout3(ffn_output, training=training)\n","\n","    output = self.layernorm3(out2 + ffn_output)\n","\n","    if debug:\n","      print('******************* DEBUG DECODER ***********************')\n","      print(f'Input Shape                       : {inputs.shape}')\n","      print(f'Shape Outputs Decoder             : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"SO5rYsFpfFS_","executionInfo":{"status":"ok","timestamp":1670280141569,"user_tz":-60,"elapsed":35,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_decoder = decoder(inputs=inputs_decoder, \n","                          encoder_output=outputs_encoder,  \n","                          training=training,\n","                          debug=debug)"],"metadata":{"id":"yysVdkHH8EPH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670280141569,"user_tz":-60,"elapsed":32,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"5a8aa124-8565-464d-c9ec-dacdd4d764d0"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 8, 16)\n","Shape Outputs Decoder             : (32, 8, 16)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["### Transformer\n","\n","Implementazione del blocco Transformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"ne4zTOG_NKfV"}},{"cell_type":"code","execution_count":21,"metadata":{"pycharm":{"name":"#%%\n"},"id":"lw2xMCAMC_4M","executionInfo":{"status":"ok","timestamp":1670280141570,"user_tz":-60,"elapsed":30,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"outputs":[],"source":["class TransformerBlock(keras.Model):\n","  def __init__(self, \n","               num_layers, \n","               embed_dim, \n","               num_heads, \n","               ff_dim, \n","               max_len,\n","               input_vocab_size,\n","               target_vocab_size,\n","               rate=0.5):\n","    \n","    super(TransformerBlock, self).__init__()\n","\n","    self.num_layers = num_layers\n","\n","    self.token_pos_enc = TokenAndPositionEmbedding(max_len, input_vocab_size, embed_dim)\n","    self.token_pos_dec = TokenAndPositionEmbedding(max_len, target_vocab_size, embed_dim)\n","\n","    self.encoder = [Encoder(max_len, embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n","    self.decoder = [Decoder(max_len, embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n","\n","    self.dropout = layers.Dropout(rate)\n","    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","\n","  def call(self, inputs, training=False, debug=False):\n","    inputs_encoder, inputs_decoder  = inputs\n","\n","    inputs_encoder = self.token_pos_enc(inputs_encoder, debug)\n","    inputs_decoder = self.token_pos_dec(inputs_decoder, debug)\n","\n","    if debug:\n","      print(f'---------------- DEBUG TRANSFORMER BLOCK ----------------')\n","      print(f'inputs_encoder       : {inputs_encoder.shape}')\n","      print(f'inputs_decoder       : {inputs_decoder.shape}')      \n","\n","    encoder_output = inputs_encoder\n","    transformer_output = inputs_decoder\n","\n","    for i in range(self.num_layers):\n","      encoder_output = self.encoder[i](inputs=encoder_output, \n","                                       training=training, \n","                                       debug=debug) \n","      \n","    for i in range(self.num_layers):\n","      transformer_output = self.decoder[i](inputs=transformer_output, \n","                                           encoder_output=encoder_output, \n","                                           training=training,\n","                                           debug=debug)\n","\n","    transformer_output = self.dropout(transformer_output)\n","    logits = self.final_layer(transformer_output)\n","\n","    if debug:\n","      print(f'Output Shape       : {logits.shape}')\n","      print(f'Output Transformer : {logits[0, :1, :12]}')    \n","      print(f'---------------------------------------------------------')\n","\n","    return logits"]},{"cell_type":"code","source":["transformer = TransformerBlock(NUM_LAYERS, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.en.get_vocab_size(),\n","                               tokenizers.it.get_vocab_size(),\n","                               DROPUOT)\n","\n","transformer_output = transformer((en_input, it_input), \n","                                 training=training,\n","                                 debug=debug)"],"metadata":{"id":"pr--G0ZZVAMi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670280142054,"user_tz":-60,"elapsed":512,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"2778f946-38c0-473e-8ed0-f2ea6a425bdf"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 8\n","Sequence Shape                            : [32  8]\n","Shape TokenAndPositionEmbedding           : (32, 8, 16)\n","*********************************************************\n","********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 8\n","Sequence Shape                            : [32  8]\n","Shape TokenAndPositionEmbedding           : (32, 8, 16)\n","*********************************************************\n","---------------- DEBUG TRANSFORMER BLOCK ----------------\n","inputs_encoder       : (32, 8, 16)\n","inputs_decoder       : (32, 8, 16)\n","********************* DEBUG ENCODER *********************\n","Shape Input Layer Encoder       : (32, 8, 16)\n","Shape Output Layer Encoder      : (32, 8, 16)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 8, 16)\n","Shape Outputs Decoder             : (32, 8, 16)\n","*********************************************************\n","Output Shape       : (32, 8, 9278)\n","Output Transformer : [[ 0.07671316 -0.03446942  0.01302731 -0.09790986 -0.08604611  0.00131473\n","  -0.03344016 -0.00437246 -0.0423195   0.04541791 -0.04605994 -0.07912897]]\n","---------------------------------------------------------\n"]}]},{"cell_type":"code","source":["transformer.summary()"],"metadata":{"id":"_kwqvJSu8liP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670280142054,"user_tz":-60,"elapsed":26,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"3a8122c6-3ccb-418b-88d3-cc47be35502a"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer_block\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," token_and_position_embeddin  multiple                 98544     \n"," g_2 (TokenAndPositionEmbedd                                     \n"," ing)                                                            \n","                                                                 \n"," token_and_position_embeddin  multiple                 148576    \n"," g_3 (TokenAndPositionEmbedd                                     \n"," ing)                                                            \n","                                                                 \n"," ENC (Encoder)               multiple                  4648      \n","                                                                 \n"," DEC (Decoder)               multiple                  8984      \n","                                                                 \n"," dropout_13 (Dropout)        multiple                  0         \n","                                                                 \n"," dense_8 (Dense)             multiple                  157726    \n","                                                                 \n","=================================================================\n","Total params: 418,478\n","Trainable params: 418,478\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["### Addestramento"],"metadata":{"id":"IFmcHTSDTvYk"}},{"cell_type":"code","source":["transformer.compile(\n","    loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n","    # metrics=['accuracy']) # CategoricalAccuracy\n","    metrics=[keras.metrics.SparseCategoricalAccuracy()])"],"metadata":{"id":"bOyqCyjIr-L2","executionInfo":{"status":"ok","timestamp":1670280142055,"user_tz":-60,"elapsed":10,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 save_best_only=True)\n","\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"],"metadata":{"id":"3hurmpSjJ_dT","executionInfo":{"status":"ok","timestamp":1670280142056,"user_tz":-60,"elapsed":10,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","history = transformer.fit(train_dataset,\n","                          epochs=EPOCHS,\n","                          shuffle=True,\n","                          validation_data=test_dataset,\n","                          callbacks=[tensorboard_callback, \n","                                     cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"etOGtBcer9yi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"07a0b8cf-2f64-4a8e-c761-3970befbff0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","500/500 [==============================] - 168s 336ms/step - loss: 4.8671 - sparse_categorical_accuracy: 0.3834 - val_loss: 3.2157 - val_sparse_categorical_accuracy: 0.5462\n","Epoch 2/50\n","500/500 [==============================] - 162s 323ms/step - loss: 2.9890 - sparse_categorical_accuracy: 0.5656 - val_loss: 2.8341 - val_sparse_categorical_accuracy: 0.5914\n","Epoch 3/50\n","500/500 [==============================] - 164s 329ms/step - loss: 2.6649 - sparse_categorical_accuracy: 0.6021 - val_loss: 2.7075 - val_sparse_categorical_accuracy: 0.6026\n","Epoch 4/50\n","500/500 [==============================] - 161s 322ms/step - loss: 2.4895 - sparse_categorical_accuracy: 0.6168 - val_loss: 2.6167 - val_sparse_categorical_accuracy: 0.6100\n","Epoch 5/50\n","500/500 [==============================] - 180s 359ms/step - loss: 2.3704 - sparse_categorical_accuracy: 0.6253 - val_loss: 2.5509 - val_sparse_categorical_accuracy: 0.6152\n","Epoch 6/50\n","500/500 [==============================] - 180s 360ms/step - loss: 2.2744 - sparse_categorical_accuracy: 0.6322 - val_loss: 2.4846 - val_sparse_categorical_accuracy: 0.6237\n","Epoch 7/50\n","500/500 [==============================] - 185s 370ms/step - loss: 2.2012 - sparse_categorical_accuracy: 0.6380 - val_loss: 2.4575 - val_sparse_categorical_accuracy: 0.6327\n","Epoch 8/50\n","500/500 [==============================] - 165s 329ms/step - loss: 2.1441 - sparse_categorical_accuracy: 0.6417 - val_loss: 2.4076 - val_sparse_categorical_accuracy: 0.6406\n","Epoch 9/50\n","500/500 [==============================] - 160s 321ms/step - loss: 2.0911 - sparse_categorical_accuracy: 0.6460 - val_loss: 2.3996 - val_sparse_categorical_accuracy: 0.6520\n","Epoch 10/50\n","500/500 [==============================] - 168s 336ms/step - loss: 2.0515 - sparse_categorical_accuracy: 0.6495 - val_loss: 2.3626 - val_sparse_categorical_accuracy: 0.6526\n","Epoch 11/50\n","500/500 [==============================] - 164s 328ms/step - loss: 2.0135 - sparse_categorical_accuracy: 0.6530 - val_loss: 2.3497 - val_sparse_categorical_accuracy: 0.6539\n","Epoch 12/50\n","500/500 [==============================] - 159s 317ms/step - loss: 1.9775 - sparse_categorical_accuracy: 0.6554 - val_loss: 2.3367 - val_sparse_categorical_accuracy: 0.6562\n","Epoch 13/50\n","500/500 [==============================] - 163s 327ms/step - loss: 1.9495 - sparse_categorical_accuracy: 0.6578 - val_loss: 2.3176 - val_sparse_categorical_accuracy: 0.6596\n","Epoch 14/50\n","500/500 [==============================] - 161s 322ms/step - loss: 1.9298 - sparse_categorical_accuracy: 0.6584 - val_loss: 2.3186 - val_sparse_categorical_accuracy: 0.6617\n","Epoch 15/50\n","500/500 [==============================] - 157s 314ms/step - loss: 1.9022 - sparse_categorical_accuracy: 0.6608 - val_loss: 2.3005 - val_sparse_categorical_accuracy: 0.6630\n","Epoch 16/50\n","500/500 [==============================] - 167s 334ms/step - loss: 1.8830 - sparse_categorical_accuracy: 0.6625 - val_loss: 2.3051 - val_sparse_categorical_accuracy: 0.6659\n","Epoch 17/50\n","500/500 [==============================] - 161s 323ms/step - loss: 1.8586 - sparse_categorical_accuracy: 0.6651 - val_loss: 2.3002 - val_sparse_categorical_accuracy: 0.6685\n","Epoch 18/50\n","500/500 [==============================] - 162s 324ms/step - loss: 1.8467 - sparse_categorical_accuracy: 0.6664 - val_loss: 2.2997 - val_sparse_categorical_accuracy: 0.6671\n","Epoch 19/50\n","500/500 [==============================] - 161s 322ms/step - loss: 1.8324 - sparse_categorical_accuracy: 0.6672 - val_loss: 2.3156 - val_sparse_categorical_accuracy: 0.6655\n","Epoch 20/50\n","500/500 [==============================] - 163s 326ms/step - loss: 1.8195 - sparse_categorical_accuracy: 0.6678 - val_loss: 2.3049 - val_sparse_categorical_accuracy: 0.6718\n"]}]},{"cell_type":"markdown","source":["### Valutazione dell'addestramento\n","Avendo in output il log ed i risultati dell'addestramento, possiamo visualizzare\n","queste informazioni relativamente alle metriche di interesse."],"metadata":{"id":"L0w4wF79UhAp"}},{"cell_type":"code","source":["# visualizzazione andamento addestramento\n","# su un grafico composto da due sub-plot\n","# uno per il loss, l'altro per l'accuracy\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n","\n","# Errore durante l'addestramento\n","ax1.plot(history.history['loss'], label='Loss')\n","ax1.plot(history.history['val_loss'], label='Validation Loss')\n","ax1.set_title('Training Loss')\n","ax1.legend()\n","\n","# Accuratezza durante l'addestramento\n","ax2.plot(history.history['accuracy'], label='Accuracy')\n","ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","ax2.set_title('Training Accuracy')\n","ax2.legend()\n","\n","plt.show()"],"metadata":{"id":"RpXR2p5VAdoG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Test del modello\n","La seguente cella permette di caricare l'ultimo checkpoint dell'addestramento\n","precedentemente salvato."],"metadata":{"id":"ReOkcBp2WHWW"}},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"5PIf_6-RSBb1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Translate:\n","  def __init__(self, transformer_block, tokenizers):\n","    self.transformer = transformer_block\n","    self.tokenizers = tokenizers\n","\n","  def predict(self, input_text, max_length):\n","    if input_text is None:\n","      input_text = input_data[np.random.choice(len(input_data))]\n","      print(input_text)\n","\n","    # print(input_text)\n","    inputs_encoder = self.tokenizers.en.tokenize(input_text).to_tensor()\n","    inputs_encoder = keras.preprocessing.sequence.pad_sequences(inputs_encoder, maxlen=max_length, padding='post')\n","\n","    # print(inputs_encoder)\n","    \n","    start_end = self.tokenizers.it.tokenize([''])[0]\n","    start = start_end[0][tf.newaxis]\n","    end = (start_end[1][tf.newaxis]).numpy()[0]\n","\n","    output_array = tf.TensorArray(dtype=tf.int64, size=max_length, dynamic_size=True)\n","    output_array = output_array.write(0, start)     \n","\n","    out_words = []\n","\n","    for i in tf.range(max_length):\n","      # decodifica e recupero probabilità di output\n","      output = tf.transpose(output_array.stack())\n","      # print('Output', output)\n","      transformer_output = transformer([inputs_encoder, output], \n","                                        training=False,\n","                                        debug=False)\n","\n","      predictions = transformer_output[:, -1:, :]\n","\n","      # selezione della parola più probabile\n","      predict = tf.argmax(predictions, -1)\n","      pred_values = (K.argmax(transformer_output, axis=-1)).numpy()\n","      # preds = pred_values[0][predict.numpy()[0][0]]\n","      \n","      # print('predict',  predict)\n","      # print('predictions', transformer_output)\n","      # print('pred_values', pred_values[0][0])\n","      # print('predict[0]', pred_values[0][i])\n","      \n","  \n","      # print('Preds', preds)\n","      # print('Detokenize', (tokenizers.it.detokenize(pred_values)))\n","      # print('##########################')\n","    \n","      # inserimento della parola nella sequenza di output\n","      output_array = output_array.write(i+1, [pred_values[0][i]])\n","      # output_array = output_array.write(i+1, predict[0])\n","\n","      # termine del ciclo quando si incontra il token <end-of-sentence>\n","      # oppure la lunghezza massima prevista della sequenza\n","      # print(end)\n","      if pred_values[0][i] == end:\n","        break\n","\n","    output = tf.transpose(output_array.stack())\n","    text = tokenizers.it.detokenize(output)[0]  \n","\n","    tokens = tokenizers.it.lookup(output)[0]\n","\n","    return text, tokens"],"metadata":{"id":"L2PEoJVb1V8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_sequences = [test_input_data[41], test_input_data[182], test_input_data[612], test_input_data[432], test_input_data[222]]\n","\n","translate = Translate(transformer_block=transformer,\n","                      tokenizers=tokenizers)\n","\n","for test_sequence in test_sequences:\n","  text, token = translate.predict(tf.constant([test_sequence]), MAX_SEQ_LENGTH)\n","\n","  print(f'{\"Input:\":15s}: {test_sequence}')\n","  print(f'{\"Prediction\":15s}: {text.numpy().decode(\"utf-8\")}')  \n","  # print(f'tokens : {token}')\n","  # print(target_data[41])\n","  # break\n","  print('---------------------------------------------')\n","\n","print(test_target_data[41])\n","print(test_target_data[102])\n","print(test_target_data[612])\n","print(test_target_data[432])\n","print(test_target_data[222])"],"metadata":{"id":"udIjI2jZWR6g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Tensorboard"],"metadata":{"id":"YJf4hjv4PMAJ"}},{"cell_type":"code","source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"metadata":{"id":"vcwHe7VJWt-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_dir"],"metadata":{"id":"7AB28JmGPQgi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir drive/MyDrive/BERT/logs/fit/20221026-134720"],"metadata":{"id":"2ZkkDKVwPT2O"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":["gAu1IXlRZzlq","_iq7Y-d4eRd8","grNE3Ww9e6Av","ne4zTOG_NKfV","YJf4hjv4PMAJ"]},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}