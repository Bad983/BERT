{"cells":[{"cell_type":"code","source":["!pip install -q -U 'tensorflow-text==2.8.*'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NE4enZGpvMRX","executionInfo":{"status":"ok","timestamp":1671026112818,"user_tz":-60,"elapsed":73682,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"68a886bf-46f2-4eb4-aabc-f4069ed24f2e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 4.9 MB 24.2 MB/s \n","\u001b[K     |████████████████████████████████| 498.0 MB 11 kB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 71.2 MB/s \n","\u001b[K     |████████████████████████████████| 462 kB 69.9 MB/s \n","\u001b[K     |████████████████████████████████| 1.4 MB 62.5 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install -q tf-models-official"],"metadata":{"id":"FPtWz_qHuofc","executionInfo":{"status":"ok","timestamp":1671026194135,"user_tz":-60,"elapsed":81324,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6f91cd9a-0dfc-48ae-b248-9cb413996619"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 2.4 MB 18.6 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 61.7 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n","\u001b[K     |████████████████████████████████| 662 kB 58.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 52.2 MB/s \n","\u001b[K     |████████████████████████████████| 118 kB 56.5 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 62.4 MB/s \n","\u001b[K     |████████████████████████████████| 2.3 MB 52.1 MB/s \n","\u001b[K     |████████████████████████████████| 38.2 MB 1.2 MB/s \n","\u001b[K     |████████████████████████████████| 588.3 MB 20 kB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 60.3 MB/s \n","\u001b[K     |████████████████████████████████| 238 kB 74.5 MB/s \n","\u001b[K     |████████████████████████████████| 6.0 MB 62.7 MB/s \n","\u001b[K     |████████████████████████████████| 1.7 MB 61.2 MB/s \n","\u001b[K     |████████████████████████████████| 439 kB 70.3 MB/s \n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"hJy-juNOpUOY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671026224863,"user_tz":-60,"elapsed":30737,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"2a743f2b-9f7c-4b58-b844-dfe7665478dc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"id":"UaAiWsEuC_4K","executionInfo":{"status":"ok","timestamp":1671026230481,"user_tz":-60,"elapsed":5622,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"outputs":[],"source":["import os\n","import re\n","import time\n","import unicodedata\n","import datetime\n","import pathlib\n","from pathlib import Path\n","\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","from keras import layers\n","\n","import tensorflow_hub as hub\n","import tensorflow_models as tfm\n","\n","import tensorflow_text as text\n","from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"]},{"cell_type":"code","source":["tf.get_logger().setLevel('ERROR')\n","tf.config.run_functions_eagerly(True)"],"metadata":{"id":"uKEqRlKowOQS","executionInfo":{"status":"ok","timestamp":1671026230482,"user_tz":-60,"elapsed":15,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Parametri BERT"],"metadata":{"id":"BehZY4rETECN"}},{"cell_type":"code","source":["bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'  \n","tfhub_handle_encoder =  'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n","tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n","gs_folder_bert = 'gs://cloud-tpu-checkpoints/bert/v3/uncased_L-12_H-768_A-12'\n","bert_vocab = os.path.join(gs_folder_bert, 'vocab.txt')\n","\n","print('BERT model selected                : ', tfhub_handle_encoder)\n","print('Preprocessing model auto-selected  : ', tfhub_handle_preprocess)\n","print('BERT vocab                         : ', bert_vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fodDcY6sm392","executionInfo":{"status":"ok","timestamp":1671026230483,"user_tz":-60,"elapsed":13,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"e7af112a-e03b-4df1-af6b-d1d7831fc1ef"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT model selected                :  https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n","Preprocessing model auto-selected  :  https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n","BERT vocab                         :  gs://cloud-tpu-checkpoints/bert/v3/uncased_L-12_H-768_A-12/vocab.txt\n"]}]},{"cell_type":"markdown","source":["### Variabili Globali"],"metadata":{"id":"HRe16D-rUBLA"}},{"cell_type":"code","source":["# PARAMETRI GLOBALI\n","root_folder = 'drive/MyDrive/BERT/'\n","\n","# DATI\n","data_folder_name = 'data'\n","train_filename = 'ita.txt'\n","\n","DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n","train_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n","\n","# PATH LOG Tensorboard\n","PATH_LOG = 'logs/fit/transformer_bert'\n","PATH_LOG = os.path.abspath(os.path.join(root_folder, PATH_LOG))\n","log_dir =  os.path.abspath(os.path.join(PATH_LOG, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))) \n","\n","# PATH WEIGHTS Tensorboard\n","PATH_WEIGHTS = 'weights/transformer_bert'\n","PATH_WEIGHTS = os.path.abspath(os.path.join(root_folder, PATH_WEIGHTS))\n","checkpoint_path = os.path.abspath(os.path.join(PATH_WEIGHTS, 'cp.ckpt'))\n","\n","# VOCABOLARIO\n","vocab_folder = 'vocab'\n","en_vocab_finalname = 'en_vocab_custom.txt'\n","it_vocab_finalname = 'it_vocab_custom.txt'\n","\n","VOCAB_PATH = os.path.abspath(os.path.join(root_folder, vocab_folder))\n","en_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, en_vocab_finalname))\n","it_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, it_vocab_finalname))"],"metadata":{"id":"ewLgCIuEpczO","executionInfo":{"status":"ok","timestamp":1671026230483,"user_tz":-60,"elapsed":9,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# parametri per il modello\n","INPUT_COLUMN = 'input'\n","TARGET_COLUMN = 'target'\n","\n","# parametri per il modello\n","NUM_SAMPLES = 300000 \n","TRAIN = 18016\n","VALIDATION = 6016\n","TEST = 100\n","\n","MAX_VOCAB_SIZE = 20000 \n","EMBEDDING_DIM = 64 \n","HIDDEN_DIM = 1024 # numero di celle nei layer ricorrenti nascosti\n","\n","BATCH_SIZE = 32\n","BUFFER_SIZE = 2000\n","MAX_SEQ_LENGTH = 64\n","\n","NUM_LAYERS = 1 # Numero di layer di Encoder e Decoder del Transformer\n","NUM_HEADS = 8 # Numero di meccanismi di multi-head attention\n","FF_DIM = 16 # Numero di celle dei Layer Feed Forward\n","DROPUOT = 0.5\n","\n","# Ottimizzatore Adam\n","LEARNING_RATE_ADAM = 1e-4\n","BETA_1 = 0.66\n","BETA_2 = 0.999\n","EPOCHS_ADAM = 20\n","\n","# IMPOSTO IL DEBUG A TRUE \n","debug = True\n","training = True"],"metadata":{"id":"8CN-4Uzoqbjl","executionInfo":{"status":"ok","timestamp":1671026230484,"user_tz":-60,"elapsed":9,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## DATASET"],"metadata":{"id":"5DPeN9Vanbvv"}},{"cell_type":"markdown","source":["### Caricamento Dati"],"metadata":{"id":"LU7AorKXT8K7"}},{"cell_type":"code","source":["# Caricamento dataset: frasi in inglese, frasi in italiano\n","df = pd.read_csv(\n","    train_filenamepath,\n","    sep=\"\\t\",\n","    header=None,\n","    names=[INPUT_COLUMN, TARGET_COLUMN],\n","    usecols=[0,1],\n","    nrows=NUM_SAMPLES\n",")\n","\n","df = df[-(TRAIN+VALIDATION+TEST):].reset_index(drop=True)\n","\n","# Mischio il dataset in modo che sia più uniforme tra train e test\n","df = df.iloc[np.random.permutation(df.index)].reset_index(drop=True)\n","\n","print(df.iloc[-4:], '\\n')\n","\n","# Preprocessing dei dati di Input\n","input_data = df[INPUT_COLUMN].tolist()\n","\n","# Preprocessing dei dati Target con aggiunta del token di fine frase\n","target_data = df[TARGET_COLUMN].tolist()\n","\n","train_input_data = input_data[:TRAIN]\n","train_target_data = target_data[:TRAIN]\n","\n","validation_input_data = input_data[TRAIN:TRAIN+VALIDATION]\n","validation_target_data = target_data[TRAIN:TRAIN+VALIDATION]\n","\n","test_input_data = input_data[TRAIN+VALIDATION:]\n","test_target_data = target_data[TRAIN+VALIDATION:]\n","\n","print('-----------TRAIN SET--------------')\n","print(train_input_data[-4:])\n","print(train_target_data[-4:])\n","print('-----------VALIDATION SET---------------')\n","print(validation_input_data[-4:])\n","print(validation_target_data[-4:])\n","print('-----------TEST SET---------------')\n","print(test_input_data[-4:])\n","print(test_target_data[-4:])"],"metadata":{"id":"-K_qU8ouq5lO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671026233715,"user_tz":-60,"elapsed":3240,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"56fc75e6-858e-431b-e7aa-c19597d734ab"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["                                      input  \\\n","24128  We're running a bit behind schedule.   \n","24129   Do you really think it's necessary?   \n","24130    I have to tell Tom and the others.   \n","24131    Tom doesn't seem to be very tired.   \n","\n","                                     target  \n","24128     Noi siamo leggermente in ritardo.  \n","24129  Tu pensi davvero che sia necessaria?  \n","24130     Io devo dirlo a Tom e agli altri.  \n","24131   Tom non sembra essere molto stanco.   \n","\n","-----------TRAIN SET--------------\n","['Tom was thinking of going to Boston.', 'We measured the depth of the river.', \"Don't interrupt me when I'm talking.\", 'Are you a senior high school student?']\n","['Tom stava pensando di andare a Boston.', 'Abbiamo misurato la profondità del fiume.', 'Non mi interrompete quando sto parlando.', 'Sei uno studente delle superiori?']\n","-----------VALIDATION SET---------------\n","['Wake me up early tomorrow morning.', \"I don't need to tell you anything.\", \"I'm three years younger than he is.\", \"Who's your favorite jazz violinist?\"]\n","['Svegliatemi presto domattina.', 'Io non devo dirvi niente.', 'Ho tre anni in meno di lui.', 'Chi è il suo violinista jazz preferito?']\n","-----------TEST SET---------------\n","[\"We're running a bit behind schedule.\", \"Do you really think it's necessary?\", 'I have to tell Tom and the others.', \"Tom doesn't seem to be very tired.\"]\n","['Noi siamo leggermente in ritardo.', 'Tu pensi davvero che sia necessaria?', 'Io devo dirlo a Tom e agli altri.', 'Tom non sembra essere molto stanco.']\n"]}]},{"cell_type":"markdown","source":["### Analisi Dati"],"metadata":{"id":"q1u_rcHxUaqV"}},{"cell_type":"code","source":["print(f'Esempi nel Dataset di Train                            : {len(train_input_data)}')\n","print(f'Frase più corta in inglese nel Dataset di Train        : {min(train_input_data, key = len)}')\n","print(f'Frase più corta in italiano nel Dataset di Train       : {min(train_target_data, key = len)}')\n","print(f'Frase più lunga in inglese nel Dataset di Train        : {max(train_input_data, key = len)}')\n","print(f'Frase più lunga in italiano nel Dataset di Train       : {max(train_target_data, key = len)}')\n","print('---------------------------------------------------------------------------------------')\n","print(f'Esempi nel Dataset di Validation                       : {len(validation_input_data)}')\n","print(f'Frase più corta in inglese nel Dataset di Validation   : {min(validation_input_data, key = len)}')\n","print(f'Frase più corta in italiano nel Dataset di Validation  : {min(validation_target_data, key = len)}')\n","print(f'Frase più lunga in inglese nel Dataset di Validation   : {max(validation_input_data, key = len)}')\n","print(f'Frase più lunga in italiano nel Dataset di Validation  : {max(validation_target_data, key = len)}')\n","print('---------------------------------------------------------------------------------------')\n","print(f'Esempi nel Dataset di Test                             : {len(test_input_data)}')\n","print(f'Frase più corta in inglese nel Dataset di Test         : {min(test_input_data, key = len)}')\n","print(f'Frase più corta in italiano nel Dataset di Test        : {min(test_target_data, key = len)}')\n","print(f'Frase più lunga in inglese nel Dataset di Test         : {max(test_input_data, key = len)}')\n","print(f'Frase più lunga in italiano nel Dataset di Test        : {max(test_target_data, key = len)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rssHK6CUcRL","executionInfo":{"status":"ok","timestamp":1671026233716,"user_tz":-60,"elapsed":8,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"8977bfd8-9211-48a1-a71b-7277cf8f35df"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Esempi nel Dataset di Train                            : 18016\n","Frase più corta in inglese nel Dataset di Train        : Are you in a hurry? \"Not really.\"\n","Frase più corta in italiano nel Dataset di Train       : La aspetterò.\n","Frase più lunga in inglese nel Dataset di Train        : A group of gangsters stole the money.\n","Frase più lunga in italiano nel Dataset di Train       : Per gli adulti la tariffa generale di ammissione è di sette dollari.\n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Validation                       : 6016\n","Frase più corta in inglese nel Dataset di Validation   : What time is it now? \"It's 2:30.\"\n","Frase più corta in italiano nel Dataset di Validation  : Ti aspetterò.\n","Frase più lunga in inglese nel Dataset di Validation   : Can you tell the Jackson twins apart?\n","Frase più lunga in italiano nel Dataset di Validation  : Per favore, non fare bollire le uova fino a farle diventare così dure.\n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Test                             : 100\n","Frase più corta in inglese nel Dataset di Test         : She is a native speaker of French.\n","Frase più corta in italiano nel Dataset di Test        : Ci aiuterà a farlo, vero?\n","Frase più lunga in inglese nel Dataset di Test         : Americans buy a lot of Japanese cars.\n","Frase più lunga in italiano nel Dataset di Test        : Lui ha cercato nella sua borsa le chiavi della macchina.\n"]}]},{"cell_type":"markdown","source":["## Tokenizer\n","\n","Carico il modello di tokenizer di BERT e creo un Tokenizer per il set di dati a disposizione"],"metadata":{"id":"njyY9RWlFMWu"}},{"cell_type":"markdown","source":["### Tokenizer Bert"],"metadata":{"id":"0KUcCnjXVjt3"}},{"cell_type":"code","source":["# Tokenizer BERT\n","tokenizer_encoder = hub.KerasLayer(tfhub_handle_preprocess, name='Bert_Preprocessing')"],"metadata":{"id":"-4B-HWWcmsmz","executionInfo":{"status":"ok","timestamp":1671026242001,"user_tz":-60,"elapsed":8289,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### Tokenizer Custom"],"metadata":{"id":"mICEGEzJVnvx"}},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices((input_data, target_data))\n","dataset = dataset.shuffle(len(input_data)).batch(BATCH_SIZE, drop_remainder=True)\n","\n","train_en = dataset.map(lambda en, it: en)\n","train_it = dataset.map(lambda en, it: it)\n","\n","bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","bert_vocab_args = dict(\n","    # The target vocabulary size\n","    vocab_size = MAX_VOCAB_SIZE,\n","    # Reserved tokens that must be included in the vocabulary\n","    reserved_tokens=reserved_tokens,\n","    # Arguments for `text.BertTokenizer`\n","    bert_tokenizer_params=bert_tokenizer_params,\n","    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","    learn_params={},\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abBEnJJGV0AD","executionInfo":{"status":"ok","timestamp":1671026242002,"user_tz":-60,"elapsed":22,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"46c91ce7-2df0-4cfe-fb02-36c64aff5b1f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def write_vocab_file(filepath, vocab):\n","  with open(filepath, 'w') as f:\n","    for token in vocab:\n","      print(token, file=f)"],"metadata":{"id":"fPqihfIGVz9o","executionInfo":{"status":"ok","timestamp":1671026242591,"user_tz":-60,"elapsed":606,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(en_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  en_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_en.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(en_vocab_filenamepath, en_vocab)"],"metadata":{"id":"dGsP1V4nVz6S","executionInfo":{"status":"ok","timestamp":1671026242591,"user_tz":-60,"elapsed":4,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(it_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  it_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_it.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(it_vocab_filenamepath, it_vocab)"],"metadata":{"id":"GTMPQWlmVz1W","executionInfo":{"status":"ok","timestamp":1671026242592,"user_tz":-60,"elapsed":5,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["en_tokenizer = text.BertTokenizer(en_vocab_filenamepath, **bert_tokenizer_params)\n","it_tokenizer = text.BertTokenizer(it_vocab_filenamepath, **bert_tokenizer_params)"],"metadata":{"id":"l4rnN0BsVzxq","executionInfo":{"status":"ok","timestamp":1671026244326,"user_tz":-60,"elapsed":1738,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["START = tf.argmax(tf.constant(reserved_tokens) == \"[START]\")\n","END = tf.argmax(tf.constant(reserved_tokens) == \"[END]\")\n","\n","def add_start_end(ragged):\n","  count = ragged.bounding_shape()[0]\n","  starts = tf.fill([count,1], START)\n","  ends = tf.fill([count,1], END)\n","  x = tf.concat([starts, ragged, ends], axis=1)\n","  # x = keras.preprocessing.sequence.pad_sequences(x.numpy(), maxlen=MAX_SEQ_LENGTH, padding='post')\n","  return x\n","\n","def cleanup_text(reserved_tokens, token_txt):\n","  # Drop the reserved tokens, except for \"[UNK]\".\n","  bad_tokens = [re.escape(tok) for tok in reserved_tokens if tok != \"[UNK]\"]\n","  bad_token_re = \"|\".join(bad_tokens)\n","\n","  bad_cells = tf.strings.regex_full_match(token_txt, bad_token_re)\n","  result = tf.ragged.boolean_mask(token_txt, ~bad_cells)\n","\n","  # Join them into strings.\n","  result = tf.strings.reduce_join(result, separator=' ', axis=-1)\n","\n","  return result"],"metadata":{"id":"BeaD2-uLWT50","executionInfo":{"status":"ok","timestamp":1671026244326,"user_tz":-60,"elapsed":7,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["#### Classe Tokenizer Custom"],"metadata":{"id":"jgPVS9ZEWWVI"}},{"cell_type":"code","source":["class CustomTokenizer(tf.Module):\n","  def __init__(self, reserved_tokens, vocab_path):\n","    self.tokenizer = text.BertTokenizer(vocab_path, lower_case=True)\n","    self._reserved_tokens = reserved_tokens\n","    self._vocab_path = tf.saved_model.Asset(vocab_path)\n","\n","    vocab = pathlib.Path(vocab_path).read_text().splitlines()\n","    self.vocab = tf.Variable(vocab)\n","\n","    ## Create the signatures for export:   \n","\n","    # Include a tokenize signature for a batch of strings. \n","    self.tokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None], dtype=tf.string))\n","    \n","    # Include `detokenize` and `lookup` signatures for:\n","    #   * `Tensors` with shapes [tokens] and [batch, tokens]\n","    #   * `RaggedTensors` with shape [batch, tokens]\n","    self.detokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int64))\n","    self.detokenize.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int64))\n","\n","    self.lookup.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int64))\n","    self.lookup.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int64))\n","\n","    # These `get_*` methods take no arguments\n","    self.get_vocab_size.get_concrete_function()\n","    self.get_vocab_path.get_concrete_function()\n","    self.get_reserved_tokens.get_concrete_function()\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    enc = self.tokenizer.tokenize(strings)\n","    # Merge the `word` and `word-piece` axes.\n","    enc = enc.merge_dims(-2,-1)\n","    enc = add_start_end(enc)\n","    return enc\n","\n","  @tf.function\n","  def detokenize(self, tokenized):\n","    words = self.tokenizer.detokenize(tokenized)\n","    return cleanup_text(self._reserved_tokens, words)\n","\n","  @tf.function\n","  def lookup(self, token_ids):\n","    return tf.gather(self.vocab, token_ids)\n","\n","  @tf.function\n","  def get_vocab_size(self):\n","    return tf.shape(self.vocab)[0]\n","\n","  @tf.function\n","  def get_vocab_path(self):\n","    return self._vocab_path\n","\n","  @tf.function\n","  def get_reserved_tokens(self):\n","    return tf.constant(self._reserved_tokens)"],"metadata":{"id":"iaAW-xm5WT1_","executionInfo":{"status":"ok","timestamp":1671026244327,"user_tz":-60,"elapsed":7,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["tokenizers = tf.Module()\n","tokenizers.en = CustomTokenizer(reserved_tokens, en_vocab_filenamepath)\n","tokenizers.it = CustomTokenizer(reserved_tokens, it_vocab_filenamepath)"],"metadata":{"id":"svlLobM4WTzC","executionInfo":{"status":"ok","timestamp":1671026251439,"user_tz":-60,"elapsed":7119,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["### Analisi Dati Tokenizzati"],"metadata":{"id":"pKZxiQ5_Whmw"}},{"cell_type":"code","source":["print(f'Vocabolario Italiano : {tokenizers.it.get_vocab_size()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jrg6TwQzW5LN","executionInfo":{"status":"ok","timestamp":1671026251439,"user_tz":-60,"elapsed":18,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"a14cf5d0-617f-40f3-c8a5-14da8868bac0"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabolario Italiano : 2179\n"]}]},{"cell_type":"code","source":["print(input_data[-2:])\n","print(tokenizer_encoder(input_data[-2:])['input_word_ids'][:, :16])\n","print('------------------------------------------------------------------')\n","print(target_data[-2:])\n","print(tokenizers.it.tokenize(target_data[-2:]))\n","print(keras.preprocessing.sequence.pad_sequences(tokenizers.it.tokenize(target_data[-2:]).numpy(), maxlen=MAX_SEQ_LENGTH, padding='post')[:, :16])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKEFeDdGFIGS","executionInfo":{"status":"ok","timestamp":1671026252056,"user_tz":-60,"elapsed":632,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"02fed035-3015-47ed-c8f4-feb3b25b756a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["['I have to tell Tom and the others.', \"Tom doesn't seem to be very tired.\"]\n","tf.Tensor(\n","[[ 101 1045 2031 2000 2425 3419 1998 1996 2500 1012  102    0    0    0\n","     0    0]\n"," [ 101 3419 2987 1005 1056 4025 2000 2022 2200 5458 1012  102    0    0\n","     0    0]], shape=(2, 16), dtype=int32)\n","------------------------------------------------------------------\n","['Io devo dirlo a Tom e agli altri.', 'Tom non sembra essere molto stanco.']\n","<tf.RaggedTensor [[2, 60, 205, 1202, 24, 52, 28, 1509, 796, 11, 3],\n"," [2, 52, 53, 160, 81, 71, 391, 11, 3]]>\n","[[   2   60  205 1202   24   52   28 1509  796   11    3    0    0    0\n","     0    0]\n"," [   2   52   53  160   81   71  391   11    3    0    0    0    0    0\n","     0    0]]\n"]}]},{"cell_type":"code","source":["print([min(train_input_data, key = len)])\n","print(tokenizer_encoder([min(train_input_data, key = len)])['input_word_ids'][:, :16])\n","print('------------------------------------------------------------------')\n","print([min(train_target_data, key = len)])\n","print(tokenizers.en.tokenize([min(train_target_data, key = len)]))\n","print(keras.preprocessing.sequence.pad_sequences(tokenizers.en.tokenize([min(train_target_data, key = len)]).numpy(), maxlen=MAX_SEQ_LENGTH, padding='post')[:, :16])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O85BUq2INK5j","executionInfo":{"status":"ok","timestamp":1671026252632,"user_tz":-60,"elapsed":580,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"50fcad16-74ef-4643-b81a-d9160d29d6cf"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["['Are you in a hurry? \"Not really.\"']\n","tf.Tensor(\n","[[ 101 2024 2017 1999 1037 9241 1029 1000 2025 2428 1012 1000  102    0\n","     0    0]], shape=(1, 16), dtype=int32)\n","------------------------------------------------------------------\n","['La aspetterò.']\n","<tf.RaggedTensor [[2, 35, 294, 114, 748, 614, 581, 381, 11, 3]]>\n","[[  2  35 294 114 748 614 581 381  11   3   0   0   0   0   0   0]]\n"]}]},{"cell_type":"code","source":["print([min(train_input_data, key = len)])\n","print(tokenizer_encoder([max(train_input_data, key = len)])['input_word_ids'][:, :16])\n","print('------------------------------------------------------------------')\n","print([max(train_target_data, key = len)])\n","print(tokenizers.en.tokenize([max(train_target_data, key = len)]))\n","print(keras.preprocessing.sequence.pad_sequences(tokenizers.en.tokenize([max(train_target_data, key = len)]).numpy(), maxlen=MAX_SEQ_LENGTH, padding='post')[:, :40])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JzJl4YGBPR3Z","executionInfo":{"status":"ok","timestamp":1671026253113,"user_tz":-60,"elapsed":485,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"a10867cc-8bd8-42d8-de9b-77d2a3e4f47d"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["['Are you in a hurry? \"Not really.\"']\n","tf.Tensor(\n","[[  101  1037  2177  1997 20067  2015 10312  1996  2769  1012   102     0\n","      0     0     0     0]], shape=(1, 16), dtype=int32)\n","------------------------------------------------------------------\n","['Per gli adulti la tariffa generale di ammissione è di sette dollari.']\n","<tf.RaggedTensor [[2, 39, 166, 30, 812, 537, 24, 149, 1725, 1405, 537, 35, 294, 43, 569,\n","  537, 684, 684, 294, 30, 510, 166, 297, 173, 27, 537, 206, 528, 537, 794,\n","  328, 173, 28, 27, 537, 1466, 1621, 57, 1504, 569, 537, 11, 3]]>\n","[[   2   39  166   30  812  537   24  149 1725 1405  537   35  294   43\n","   569  537  684  684  294   30  510  166  297  173   27  537  206  528\n","   537  794  328  173   28   27  537 1466 1621   57 1504  569]]\n"]}]},{"cell_type":"markdown","source":["## Creazione dataset\n","Utilizzo della libreria tf.data per la gestione del dataset da utilizzare.\n","Verranno creati batch di esempi che verranno utilizzati durante l'addestramento."],"metadata":{"id":"5QIDajkEsVU1"}},{"cell_type":"code","source":["def prepare_batch(en, it):\n","  zero = tf.zeros([BATCH_SIZE, MAX_SEQ_LENGTH], tf.int64)\n","\n","  # Tokenizzo l'input per l'Encoder\n","  encoder = tokenizer_encoder(en)          \n","\n","  # Tokenizzo l'input per il Decder e creo la variabile Target\n","  it = tokenizers.it.tokenize(it)\n","  decoder = it[:, :-1].to_tensor()  # Drop the [END] tokens\n","  target = it[:, 1:].to_tensor()   # Drop the [START] tokens\n","  \n","  decoder = tf.concat([decoder, zero], 1)\n","  decoder = decoder[:, :(MAX_SEQ_LENGTH)]\n","\n","  target = tf.concat([target, zero], 1)\n","  target = target[:, :(MAX_SEQ_LENGTH)]\n","\n","  return (encoder, decoder), target"],"metadata":{"id":"ccH3jHoABPzV","executionInfo":{"status":"ok","timestamp":1671026253114,"user_tz":-60,"elapsed":4,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def make_batches(ds):\n","  return (\n","      ds\n","      .shuffle(BUFFER_SIZE)\n","      .batch(BATCH_SIZE)\n","      .map(prepare_batch, tf.data.AUTOTUNE)\n","      .prefetch(buffer_size=tf.data.AUTOTUNE))"],"metadata":{"id":"l_dswlCiBTdR","executionInfo":{"status":"ok","timestamp":1671026253114,"user_tz":-60,"elapsed":4,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Definizione del dataset\n","# [from_tensor_slices] permette di recuperare batch\n","# di esempi dai dataset di riferimento\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_input_data, train_target_data))\n","validation_dataset = tf.data.Dataset.from_tensor_slices((validation_input_data, validation_target_data))\n","\n","# impostazione del recupero di esempi presi in maniera\n","# casuale in gruppi di [BATCH_SIZE] tra quelli disponibili\n","train_dataset = make_batches(train_dataset)\n","validation_dataset = make_batches(validation_dataset)"],"metadata":{"id":"tktJ5YuIsYe3","executionInfo":{"status":"ok","timestamp":1671026255218,"user_tz":-60,"elapsed":2108,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# Recupero un batch di esempi per la verifica delle classi custom che andrò a creare\n","for (enc_input, dec_input), target in train_dataset.take(1):\n","  print('----------------------- ENCODER  -------------------------------')\n","  print(f'Shape                    : {enc_input[\"input_word_ids\"].shape}')\n","  print(f'Word Ids                 : {enc_input[\"input_word_ids\"][0, :MAX_SEQ_LENGTH]}')\n","  print(f'Input Mask               : {enc_input[\"input_mask\"][0, :MAX_SEQ_LENGTH]}')\n","  print(f'Type Ids                 : {enc_input[\"input_type_ids\"][0, :MAX_SEQ_LENGTH]}')  \n","  print('--------------------- DECODER ----------------------------------')\n","  print(f'Shape it input           : {dec_input.shape}')\n","  print(f'Example it input         : {dec_input[0]}')  \n","  print('--------------------- TARGET -----------------------------------')\n","  print(f'Shape it input           : {target.shape}')\n","  print(f'Example it target        : {target[0]}')  "],"metadata":{"id":"VH_aKPlV_AWA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671026255817,"user_tz":-60,"elapsed":603,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"453a60ae-0f2c-42cd-9f6f-9a29ff8bd3c5"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------- ENCODER  -------------------------------\n","Shape                    : (32, 128)\n","Word Ids                 : [ 101 1045 2123 1005 1056 2272 2067 2182 2200 2411 1012  102    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n","Input Mask               : [1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","Type Ids                 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","--------------------- DECODER ----------------------------------\n","Shape it input           : (32, 64)\n","Example it input         : [   2   60   53 1933   94   71  332   11    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n","--------------------- TARGET -----------------------------------\n","Shape it input           : (32, 64)\n","Example it target        : [  60   53 1933   94   71  332   11    3    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n"]}]},{"cell_type":"markdown","source":["## Encoder BERT\n","\n","Predispondo la classe necessaria per la costruzione di BERT\n"],"metadata":{"id":"8dtVuZGJpvXl"}},{"cell_type":"code","source":["class EncoderBert(layers.Layer):\n","  def __init__(self, bert_encoder, embedding_dim, max_len):\n","    super(EncoderBert, self).__init__()\n","    self.encoder = hub.KerasLayer(bert_encoder, name='BERT_encoder')\n","    self.conv_1 = tf.keras.layers.Conv1D(embedding_dim * 4, 1, activation='relu') \n","    self.conv_2 = tf.keras.layers.Conv1D(embedding_dim, 1, activation='relu') \n","    self.lambda_layer = tf.keras.layers.Lambda(lambda x: x[:,:max_len])\n","    self.max_len = max_len\n","\n","  def call(self, x, debug=False):\n","    # x = self.preprocess(input_sequnces)\n","\n","    if debug:\n","      print(f'****************** DEBUG ENCODER BERT ******************')\n","      print(f\"First example\")\n","      print(f'Keys                         : {list(x.keys())}')\n","      print(f'Shape                        : {x[\"input_word_ids\"].shape}')\n","      print(f'Word Ids                     : {x[\"input_word_ids\"][0, :self.max_len]}')\n","      print(f'Input Mask                   : {x[\"input_mask\"][0, :self.max_len]}')\n","      print(f'Type Ids                     : {x[\"input_type_ids\"][0, :self.max_len]}')\n","      \n","    # x = self.encoder(x)['sequence_output'] \n","    # encoder_outputs stato intermedio di BERT prima che esegua la traduzione recuperare la metà della lunghezza\n","    x = self.encoder(x)['encoder_outputs'] \n","    x = x[int(len(x) / 2) - 1]\n","\n","    if debug:\n","      print()\n","      print(f'Encoder Outputs BERT Shape   : {x.shape}')\n","      print(f'Encoder Outputs BERT Values  : {x[0, :1, :self.max_len]}')\n","\n","    x = self.conv_1(x)\n","    if debug:\n","      print()\n","      print(f'Sequence Conv1 Shape         : {x.shape}')\n","\n","    x = self.conv_2(x)\n","    if debug:\n","      print(f'Sequence Conv2 Shape         : {x.shape}')\n","\n","    x = self.lambda_layer(x)\n","    if debug:\n","      print(f'Sequence Lambda Layer        : {x.shape}')\n","      print()\n","      print(f'Sequence Outputs Values      : {x[0, 0, :self.max_len]}')      \n","      print('*********************************************************') \n","\n","    return x"],"metadata":{"id":"m7v9Y-Lep4CD","executionInfo":{"status":"ok","timestamp":1671026255817,"user_tz":-60,"elapsed":6,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["encoder_bert = EncoderBert(tfhub_handle_encoder, \n","                           EMBEDDING_DIM, \n","                           MAX_SEQ_LENGTH)\n","\n","bert_outputs = encoder_bert(enc_input, debug) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"morr6J7rp-SP","executionInfo":{"status":"ok","timestamp":1671026293084,"user_tz":-60,"elapsed":37273,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"ede564f7-5535-456c-9ff6-737ab8a4dd56"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_mask', 'input_word_ids', 'input_type_ids']\n","Shape                        : (32, 128)\n","Word Ids                     : [ 101 1045 2123 1005 1056 2272 2067 2182 2200 2411 1012  102    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","Type Ids                     : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[ 0.22106194 -0.96542096 -0.37428582 -0.6272429   0.0583532  -0.16103199\n","  -0.24861616  0.05359972 -0.11010458 -1.1252642  -0.37616986  0.9752986\n","   0.00896828  0.35516414 -0.2775844  -0.31455863  0.04073174  0.27869362\n","  -0.500407    0.2665623  -0.63888067 -0.02280685 -0.01827518  0.0577082\n","   0.3273244  -0.10073972 -0.19291942 -0.11234237 -0.01832768 -0.17731303\n","  -0.58567727  0.58872396 -0.11112063 -0.2824148   0.2808824   0.06454185\n","   0.21357533 -0.23042992  0.27877814 -0.21532312 -0.06658616  0.24621242\n","  -0.00689673 -0.1562238   0.09796156 -0.10751657 -5.7846913   0.788972\n","   0.9315485  -0.2737619   0.96031237 -1.319607   -0.39624333  0.7258636\n","   1.2405813  -0.16471419 -0.43522     0.1252049   0.45068765 -0.27869028\n","  -0.01775353  0.23959568 -0.45241633  0.2391867 ]]\n","\n","Sequence Conv1 Shape         : (32, 128, 256)\n","Sequence Conv2 Shape         : (32, 128, 64)\n","Sequence Lambda Layer        : (32, 64, 64)\n","\n","Sequence Outputs Values      : [4.9014300e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n"," 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n"," 0.0000000e+00 9.5476806e-01 0.0000000e+00 6.6026658e-02 0.0000000e+00\n"," 3.9693221e-02 5.5074155e-01 5.0765938e-01 3.7346333e-02 0.0000000e+00\n"," 1.2572268e-01 9.1459370e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n"," 1.1775100e+00 0.0000000e+00 1.2435436e-01 0.0000000e+00 2.9784146e-01\n"," 0.0000000e+00 0.0000000e+00 7.4304610e-01 1.2212992e-04 3.5316423e-01\n"," 0.0000000e+00 0.0000000e+00 9.7018933e-01 0.0000000e+00 0.0000000e+00\n"," 4.9253607e-01 1.5142441e-01 0.0000000e+00 0.0000000e+00 9.5490158e-01\n"," 3.7469393e-01 8.5767210e-01 8.7641585e-01 1.0568433e+00 1.2113163e+00\n"," 4.4838372e-01 1.4075208e-01 6.8923497e-01 1.3059615e+00 7.1387219e-01\n"," 0.0000000e+00 8.8955456e-01 0.0000000e+00 8.0609727e-01 0.0000000e+00\n"," 0.0000000e+00 4.3760425e-01 7.2299910e-01 2.7084655e-01]\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["## Decoder\n","\n","Predispondo la classe necessaria per la costruzione di un Layer di Decoder"],"metadata":{"id":"ReEQ5rX7aGtl"}},{"cell_type":"markdown","source":["### TOKEN AND POSITION EMBEDDING\n","\n","Implementazione del blocco Embedding per l'utilizzo di vettori posizionali insieme ai vettori di token di parole tramite estensione della classe Layer di Keras. "],"metadata":{"id":"gAu1IXlRZzlq"}},{"cell_type":"code","source":["class TokenAndPositionEmbedding(layers.Layer):\n","  def __init__(self, maxlen, vocab_size, embed_dim):\n","    super(TokenAndPositionEmbedding, self).__init__()\n","    self.maxlen = maxlen\n","    self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n","    self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","  def call(self, x, debug=False):\n","    x = keras.preprocessing.sequence.pad_sequences(x, maxlen=self.maxlen, padding='post')\n","    maxlen = tf.shape(x)[-1]\n","\n","    if debug:\n","      print('********** DEBUG TOKEN AND POSITION EMBEDDING ***********')\n","      print(f'Sequence Max len                          : {maxlen}')\n","      print(f'Sequence Shape                            : {tf.shape(x)}')\n","\n","    positions = tf.range(start=0, limit=maxlen, delta=1)\n","    positions = self.pos_emb(positions)\n","    x = self.token_emb(x)\n","    output = x + positions\n","\n","    if debug:\n","      print(f'Shape TokenAndPositionEmbedding           : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"o9-RSKTqsmUC","executionInfo":{"status":"ok","timestamp":1671026293085,"user_tz":-60,"elapsed":14,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["token_position_it = TokenAndPositionEmbedding(MAX_SEQ_LENGTH, tokenizers.it.get_vocab_size(), EMBEDDING_DIM)\n","\n","inputs_decoder = token_position_it(dec_input, debug)"],"metadata":{"id":"rr_EWQUX8EWP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671026293085,"user_tz":-60,"elapsed":11,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"881c965d-d662-4d03-9d6d-f820c233d830"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 64\n","Sequence Shape                            : [32 64]\n","Shape TokenAndPositionEmbedding           : (32, 64, 64)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["### LAYER DECODER\n","\n","Implementazione di un blocco di DecoderTransformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"XdLv-6nidKGK"}},{"cell_type":"markdown","source":["#### DecodeBert\n","\n","Implmentazione di un blocco di  decodifica custom per decodificare l'output dal layer EncoderBert prima di passarlo al Decoder del Transformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"_iq7Y-d4eRd8"}},{"cell_type":"code","source":["class DecodeBert(layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DecodeBert'):\n","    super(DecodeBert, self).__init__()\n","    self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = keras.Sequential(\n","      [layers.Dense(ff_dim, activation='relu'), layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = layers.LayerNormalization()\n","    self.layernorm2 = layers.LayerNormalization()\n","    self.dropout1 = layers.Dropout(rate)\n","    self.dropout2 = layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, bert_outputs, training=False, debug=False):\n","    attn_output = self.att(query=bert_outputs,\n","                           value=bert_outputs, \n","                           key=bert_outputs)\n","    \n","    attn_output = self.dropout1(attn_output)\n","    out1 = self.layernorm1(bert_outputs + attn_output)\n","\n","    ffn_output = self.ffn(out1)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","\n","    output = self.layernorm2(out1 + ffn_output)\n","\n","    if debug:\n","      print('********************* DEBUG DECODE-BERT *********************')\n","      print(f'Shape Input Layer Decode-Bert       : {bert_outputs.shape}')\n","      print(f'Shape Output Layer Decode-Bert      : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"joTBTlWF8ETD","executionInfo":{"status":"ok","timestamp":1671026293086,"user_tz":-60,"elapsed":7,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["encoder = DecodeBert(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_encoder = encoder(bert_outputs=bert_outputs,\n","                          training=training, \n","                          debug=debug)"],"metadata":{"id":"JaIzBxFCfKe9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671026295766,"user_tz":-60,"elapsed":2687,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"065f58d8-735d-49b9-9f7a-2b96a1b73c6a"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 64, 64)\n","Shape Output Layer Decode-Bert      : (32, 64, 64)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["#### Layer Decoder"],"metadata":{"id":"dMTKLwd3dRw5"}},{"cell_type":"code","source":["class Decoder(layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DEC'):\n","    super(Decoder, self).__init__()\n","    self.decode_bert = DecodeBert(max_len=max_len, embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, rate=rate)\n","    self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.att2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = keras.Sequential(\n","      [layers.Dense(ff_dim, activation='relu'), layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = layers.LayerNormalization()\n","    self.layernorm2 = layers.LayerNormalization()\n","    self.layernorm3 = layers.LayerNormalization()\n","    self.dropout1 = layers.Dropout(rate)\n","    self.dropout2 = layers.Dropout(rate)\n","    self.dropout3 = layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, inputs, bert_outputs, training=False, debug=False):\n","    attn_output1 = self.att1(query=inputs,\n","                             value=inputs, \n","                             key=inputs, \n","                             use_causal_mask=True)\n","    \n","    attn_output1 = self.dropout1(attn_output1)\n","    out1 = self.layernorm1(inputs + attn_output1)\n","\n","    dec_bert = self.decode_bert(bert_outputs=bert_outputs, training=training, debug=debug)\n","\n","    attn_output2 = self.att2(key=dec_bert, \n","                             value=dec_bert, \n","                             query=out1)\n","    \n","    attn_output2 = self.dropout2(attn_output2, training=training)\n","    out2 = self.layernorm2(out1 + attn_output2)\n","\n","    ffn_output = self.ffn(out2)\n","    ffn_output = self.dropout3(ffn_output, training=training)\n","\n","    output = self.layernorm3(out2 + ffn_output)\n","\n","    if debug:\n","      print('******************* DEBUG DECODER ***********************')\n","      print(f'Input Shape                       : {inputs.shape}')\n","      print(f'Shape Outputs Decoder             : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"SO5rYsFpfFS_","executionInfo":{"status":"ok","timestamp":1671026295766,"user_tz":-60,"elapsed":7,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_decoder = decoder(inputs=inputs_decoder, \n","                          bert_outputs=bert_outputs,  \n","                          training=training,\n","                          debug=debug)"],"metadata":{"id":"yysVdkHH8EPH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671026420438,"user_tz":-60,"elapsed":595,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"e6faa835-f31f-460e-d33c-5f61090f5ecd"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 64, 64)\n","Shape Output Layer Decode-Bert      : (32, 64, 64)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 64, 64)\n","Shape Outputs Decoder             : (32, 64, 64)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["## TRANSFORMER\n","\n","Implementazione del blocco Transformer tramite estensione della classe Layer di Keras."],"metadata":{"id":"ne4zTOG_NKfV"}},{"cell_type":"code","execution_count":36,"metadata":{"pycharm":{"name":"#%%\n"},"id":"lw2xMCAMC_4M","executionInfo":{"status":"ok","timestamp":1671026295767,"user_tz":-60,"elapsed":4,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"outputs":[],"source":["class TransformerBlock(keras.Model):\n","  def __init__(self, \n","               num_layers, \n","               embed_dim, \n","               num_heads, \n","               ff_dim, \n","               max_len,\n","               vocab_size,\n","               tfhub_handle_encoder,\n","               rate=0.5):\n","    \n","    super(TransformerBlock, self).__init__()\n","\n","    self.num_layers = num_layers\n","\n","    self.token_pos_dec = TokenAndPositionEmbedding(max_len, vocab_size, embed_dim)\n","\n","    self.encoder = EncoderBert(tfhub_handle_encoder, embed_dim, max_len)\n","    self.decoder = [Decoder(max_len, embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n","\n","    self.dropout = layers.Dropout(rate)\n","    self.final_layer = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, training=False, debug=False):\n","    inputs_encoder, inputs_decoder  = inputs\n","\n","    encoder_output = self.encoder(inputs_encoder, debug) \n","\n","    inputs_decoder = self.token_pos_dec(inputs_decoder, debug)\n","\n","    if debug:\n","      print(f'---------------- DEBUG TRANSFORMER BLOCK ----------------')\n","      print(f'inputs_encoder       : {inputs_encoder[\"input_word_ids\"].shape}')\n","      print(f'inputs_decoder       : {inputs_decoder.shape}')      \n","\n","    transformer_output = inputs_decoder\n","      \n","    for i in range(self.num_layers):\n","      transformer_output = self.decoder[i](inputs=transformer_output, \n","                                           bert_outputs=encoder_output, \n","                                           training=training,\n","                                           debug=debug)\n","\n","    transformer_output = self.dropout(transformer_output)\n","    logits = self.final_layer(transformer_output)\n","\n","    if debug:\n","      print(f'Output Shape       : {logits.shape}')\n","      print(f'Output Transformer : {logits[0, :1, :12]}')    \n","      print(f'---------------------------------------------------------')\n","\n","    return logits"]},{"cell_type":"code","source":["transformer = TransformerBlock(NUM_LAYERS, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.it.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               DROPUOT)\n","\n","transformer_output = transformer((enc_input, dec_input), \n","                                 training=training,\n","                                 debug=debug)"],"metadata":{"id":"pr--G0ZZVAMi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671026310032,"user_tz":-60,"elapsed":14269,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"a21f95b8-146e-41fa-b3fc-1cca300b17c4"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_mask', 'input_word_ids', 'input_type_ids']\n","Shape                        : (32, 128)\n","Word Ids                     : [ 101 1045 2123 1005 1056 2272 2067 2182 2200 2411 1012  102    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","Type Ids                     : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[ 0.22106194 -0.96542096 -0.37428582 -0.6272429   0.0583532  -0.16103199\n","  -0.24861616  0.05359972 -0.11010458 -1.1252642  -0.37616986  0.9752986\n","   0.00896828  0.35516414 -0.2775844  -0.31455863  0.04073174  0.27869362\n","  -0.500407    0.2665623  -0.63888067 -0.02280685 -0.01827518  0.0577082\n","   0.3273244  -0.10073972 -0.19291942 -0.11234237 -0.01832768 -0.17731303\n","  -0.58567727  0.58872396 -0.11112063 -0.2824148   0.2808824   0.06454185\n","   0.21357533 -0.23042992  0.27877814 -0.21532312 -0.06658616  0.24621242\n","  -0.00689673 -0.1562238   0.09796156 -0.10751657 -5.7846913   0.788972\n","   0.9315485  -0.2737619   0.96031237 -1.319607   -0.39624333  0.7258636\n","   1.2405813  -0.16471419 -0.43522     0.1252049   0.45068765 -0.27869028\n","  -0.01775353  0.23959568 -0.45241633  0.2391867 ]]\n","\n","Sequence Conv1 Shape         : (32, 128, 256)\n","Sequence Conv2 Shape         : (32, 128, 64)\n","Sequence Lambda Layer        : (32, 64, 64)\n","\n","Sequence Outputs Values      : [0.82311624 0.         1.1547416  0.71202445 0.         0.\n"," 0.49250662 0.         0.13779715 0.6816917  0.36180955 1.2509155\n"," 0.         0.74355966 0.2143089  1.0806823  0.         0.\n"," 1.1270664  0.         0.         0.         0.         0.5327311\n"," 0.         1.2312065  0.         0.         0.         0.21904406\n"," 1.6676131  0.19549142 0.65810174 0.6640512  0.         1.7190516\n"," 0.         0.20916569 0.04610008 2.4770796  0.         0.40197027\n"," 1.7203152  0.         1.1853735  1.6490799  0.737711   0.52662\n"," 0.4224488  0.         0.86335754 0.         0.         1.5436382\n"," 1.4721045  0.         0.7831602  0.         0.7668781  0.\n"," 0.         0.15668407 0.         0.        ]\n","*********************************************************\n","********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 64\n","Sequence Shape                            : [32 64]\n","Shape TokenAndPositionEmbedding           : (32, 64, 64)\n","*********************************************************\n","---------------- DEBUG TRANSFORMER BLOCK ----------------\n","inputs_encoder       : (32, 128)\n","inputs_decoder       : (32, 64, 64)\n","********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 64, 64)\n","Shape Output Layer Decode-Bert      : (32, 64, 64)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 64, 64)\n","Shape Outputs Decoder             : (32, 64, 64)\n","*********************************************************\n","Output Shape       : (32, 64, 2179)\n","Output Transformer : [[-0.31332907  0.17405966  0.2810725  -0.3452687  -0.17232275  0.00871015\n","  -0.05935469  0.10201195  0.35130557  0.19564429 -0.30273747 -0.48616636]]\n","---------------------------------------------------------\n"]}]},{"cell_type":"code","source":["transformer.summary()"],"metadata":{"id":"_kwqvJSu8liP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671026310032,"user_tz":-60,"elapsed":26,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"d49bc801-a55f-40db-93e5-621946e0650f"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer_block\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," token_and_position_embeddin  multiple                 143552    \n"," g_1 (TokenAndPositionEmbedd                                     \n"," ing)                                                            \n","                                                                 \n"," encoder_bert_1 (EncoderBert  multiple                 109695553 \n"," )                                                               \n","                                                                 \n"," DEC (Decoder)               multiple                  402912    \n","                                                                 \n"," dropout_16 (Dropout)        multiple                  0         \n","                                                                 \n"," dense_10 (Dense)            multiple                  141635    \n","                                                                 \n","=================================================================\n","Total params: 110,383,652\n","Trainable params: 901,411\n","Non-trainable params: 109,482,241\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["### Addestramento modello con ottimizzatore ADAM"],"metadata":{"id":"IFmcHTSDTvYk"}},{"cell_type":"markdown","source":["### Compilazione"],"metadata":{"id":"tiuqPlHo0Z0n"}},{"cell_type":"code","source":["transformer.compile(\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_ADAM, \n","                                       beta_1=BETA_1, \n","                                       beta_2=BETA_2),\n","    metrics=[keras.metrics.SparseCategoricalAccuracy()])"],"metadata":{"id":"bOyqCyjIr-L2","executionInfo":{"status":"ok","timestamp":1671026436697,"user_tz":-60,"elapsed":459,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 save_best_only=True)\n","\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"],"metadata":{"id":"3hurmpSjJ_dT","executionInfo":{"status":"ok","timestamp":1671026438135,"user_tz":-60,"elapsed":5,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["### Addestramento"],"metadata":{"id":"Day7C7Qh0b4G"}},{"cell_type":"code","source":["start = datetime.datetime.now()\n","history = transformer.fit(train_dataset,\n","                          epochs=EPOCHS_ADAM,\n","                          shuffle=True,\n","                          validation_data=validation_dataset,\n","                          callbacks=[tensorboard_callback, \n","                                     cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"etOGtBcer9yi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"020cbd8d-427f-4e46-8d7d-44bf8d2cf9c6","executionInfo":{"status":"ok","timestamp":1671020826851,"user_tz":-60,"elapsed":13203494,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","563/563 [==============================] - 651s 1s/step - loss: 3.7819 - sparse_categorical_accuracy: 0.7962 - val_loss: 1.3195 - val_sparse_categorical_accuracy: 0.8337\n","Epoch 2/20\n","563/563 [==============================] - 644s 1s/step - loss: 1.1354 - sparse_categorical_accuracy: 0.8525 - val_loss: 0.9239 - val_sparse_categorical_accuracy: 0.8665\n","Epoch 3/20\n","563/563 [==============================] - 628s 1s/step - loss: 0.9215 - sparse_categorical_accuracy: 0.8682 - val_loss: 0.8379 - val_sparse_categorical_accuracy: 0.8738\n","Epoch 4/20\n","563/563 [==============================] - 622s 1s/step - loss: 0.8448 - sparse_categorical_accuracy: 0.8744 - val_loss: 0.7819 - val_sparse_categorical_accuracy: 0.8807\n","Epoch 5/20\n","563/563 [==============================] - 637s 1s/step - loss: 0.7910 - sparse_categorical_accuracy: 0.8799 - val_loss: 0.7373 - val_sparse_categorical_accuracy: 0.8845\n","Epoch 6/20\n","563/563 [==============================] - 636s 1s/step - loss: 0.7506 - sparse_categorical_accuracy: 0.8833 - val_loss: 0.7018 - val_sparse_categorical_accuracy: 0.8871\n","Epoch 7/20\n","563/563 [==============================] - 636s 1s/step - loss: 0.7185 - sparse_categorical_accuracy: 0.8857 - val_loss: 0.6729 - val_sparse_categorical_accuracy: 0.8894\n","Epoch 8/20\n","563/563 [==============================] - 635s 1s/step - loss: 0.6915 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.6480 - val_sparse_categorical_accuracy: 0.8913\n","Epoch 9/20\n","563/563 [==============================] - 636s 1s/step - loss: 0.6677 - sparse_categorical_accuracy: 0.8897 - val_loss: 0.6259 - val_sparse_categorical_accuracy: 0.8934\n","Epoch 10/20\n","563/563 [==============================] - 623s 1s/step - loss: 0.6476 - sparse_categorical_accuracy: 0.8913 - val_loss: 0.6085 - val_sparse_categorical_accuracy: 0.8946\n","Epoch 11/20\n","563/563 [==============================] - 638s 1s/step - loss: 0.6290 - sparse_categorical_accuracy: 0.8928 - val_loss: 0.5897 - val_sparse_categorical_accuracy: 0.8968\n","Epoch 12/20\n","563/563 [==============================] - 639s 1s/step - loss: 0.6133 - sparse_categorical_accuracy: 0.8942 - val_loss: 0.5738 - val_sparse_categorical_accuracy: 0.8981\n","Epoch 13/20\n","563/563 [==============================] - 624s 1s/step - loss: 0.5987 - sparse_categorical_accuracy: 0.8956 - val_loss: 0.5590 - val_sparse_categorical_accuracy: 0.8997\n","Epoch 14/20\n","563/563 [==============================] - 624s 1s/step - loss: 0.5850 - sparse_categorical_accuracy: 0.8968 - val_loss: 0.5461 - val_sparse_categorical_accuracy: 0.9008\n","Epoch 15/20\n","563/563 [==============================] - 639s 1s/step - loss: 0.5723 - sparse_categorical_accuracy: 0.8980 - val_loss: 0.5340 - val_sparse_categorical_accuracy: 0.9019\n","Epoch 16/20\n","563/563 [==============================] - 626s 1s/step - loss: 0.5608 - sparse_categorical_accuracy: 0.8990 - val_loss: 0.5240 - val_sparse_categorical_accuracy: 0.9031\n","Epoch 17/20\n","563/563 [==============================] - 640s 1s/step - loss: 0.5494 - sparse_categorical_accuracy: 0.9002 - val_loss: 0.5119 - val_sparse_categorical_accuracy: 0.9044\n","Epoch 18/20\n","563/563 [==============================] - 640s 1s/step - loss: 0.5390 - sparse_categorical_accuracy: 0.9012 - val_loss: 0.5027 - val_sparse_categorical_accuracy: 0.9058\n","Epoch 19/20\n","563/563 [==============================] - 640s 1s/step - loss: 0.5297 - sparse_categorical_accuracy: 0.9020 - val_loss: 0.4939 - val_sparse_categorical_accuracy: 0.9072\n","Epoch 20/20\n","563/563 [==============================] - 639s 1s/step - loss: 0.5207 - sparse_categorical_accuracy: 0.9033 - val_loss: 0.4843 - val_sparse_categorical_accuracy: 0.9081\n","Tempo necessario per l'addestramento: 3:40:03.154714\n"]}]},{"cell_type":"markdown","source":["### Valutazione dell'addestramento\n","Avendo in output il log ed i risultati dell'addestramento, possiamo visualizzare\n","queste informazioni relativamente alle metriche di interesse."],"metadata":{"id":"L0w4wF79UhAp"}},{"cell_type":"code","source":["# visualizzazione andamento addestramento\n","# su un grafico composto da due sub-plot\n","# uno per il loss, l'altro per l'accuracy\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n","\n","# Errore durante l'addestramento\n","ax1.plot(history.history['loss'], label='Loss')\n","ax1.plot(history.history['val_loss'], label='Validation Loss')\n","ax1.set_title('Training Loss')\n","ax1.legend()\n","\n","# Accuratezza durante l'addestramento\n","ax2.plot(history.history['sparse_categorical_accuracy'], label='Accuracy')\n","ax2.plot(history.history['val_sparse_categorical_accuracy'], label='Validation Accuracy')\n","ax2.set_title('Training Accuracy')\n","ax2.legend()\n","\n","plt.show()"],"metadata":{"id":"RpXR2p5VAdoG","colab":{"base_uri":"https://localhost:8080/","height":537},"executionInfo":{"status":"error","timestamp":1671020828446,"user_tz":-60,"elapsed":1053,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"0adcf329-8da4-4295-98d4-418b1b64b6e4"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-74c684bde1c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Accuratezza durante l'addestramento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'accuracy'"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x360 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### Addestramento 2"],"metadata":{"id":"FOXy7yFkxt4q"}},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"bxKgmkMrxsZr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671026467411,"user_tz":-60,"elapsed":15450,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"1fd676b2-bbfa-4319-a5bc-b63b1ba0d3ba"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f38933d1070>"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","history = transformer.fit(train_dataset,\n","                          initial_epoch=EPOCHS_ADAM,\n","                          epochs=EPOCHS_ADAM+EPOCHS_ADAM,\n","                          shuffle=True,\n","                          validation_data=validation_dataset,\n","                          callbacks=[tensorboard_callback, \n","                                     cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KHTgL6iyyBU2","outputId":"790e9276-f384-4597-ca61-1d1b06b873b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 21/40\n","563/563 [==============================] - 629s 1s/step - loss: 0.5231 - sparse_categorical_accuracy: 0.9031 - val_loss: 0.4435 - val_sparse_categorical_accuracy: 0.9127\n","Epoch 22/40\n","563/563 [==============================] - 631s 1s/step - loss: 0.5120 - sparse_categorical_accuracy: 0.9040 - val_loss: 0.4374 - val_sparse_categorical_accuracy: 0.9135\n","Epoch 23/40\n","563/563 [==============================] - 611s 1s/step - loss: 0.5043 - sparse_categorical_accuracy: 0.9047 - val_loss: 0.4313 - val_sparse_categorical_accuracy: 0.9143\n","Epoch 24/40\n","563/563 [==============================] - 627s 1s/step - loss: 0.4967 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.4266 - val_sparse_categorical_accuracy: 0.9150\n","Epoch 25/40\n","563/563 [==============================] - 627s 1s/step - loss: 0.4892 - sparse_categorical_accuracy: 0.9067 - val_loss: 0.4203 - val_sparse_categorical_accuracy: 0.9156\n","Epoch 26/40\n","563/563 [==============================] - 627s 1s/step - loss: 0.4817 - sparse_categorical_accuracy: 0.9075 - val_loss: 0.4159 - val_sparse_categorical_accuracy: 0.9167\n","Epoch 27/40\n","563/563 [==============================] - 625s 1s/step - loss: 0.4750 - sparse_categorical_accuracy: 0.9083 - val_loss: 0.4093 - val_sparse_categorical_accuracy: 0.9177\n","Epoch 28/40\n","563/563 [==============================] - 627s 1s/step - loss: 0.4689 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.4043 - val_sparse_categorical_accuracy: 0.9184\n","Epoch 29/40\n","563/563 [==============================] - 612s 1s/step - loss: 0.4624 - sparse_categorical_accuracy: 0.9098 - val_loss: 0.4000 - val_sparse_categorical_accuracy: 0.9188\n","Epoch 30/40\n","563/563 [==============================] - 626s 1s/step - loss: 0.4565 - sparse_categorical_accuracy: 0.9106 - val_loss: 0.3961 - val_sparse_categorical_accuracy: 0.9195\n","Epoch 31/40\n","563/563 [==============================] - 609s 1s/step - loss: 0.4513 - sparse_categorical_accuracy: 0.9113 - val_loss: 0.3909 - val_sparse_categorical_accuracy: 0.9203\n","Epoch 32/40\n","563/563 [==============================] - 627s 1s/step - loss: 0.4455 - sparse_categorical_accuracy: 0.9118 - val_loss: 0.3871 - val_sparse_categorical_accuracy: 0.9210\n","Epoch 33/40\n","563/563 [==============================] - 625s 1s/step - loss: 0.4394 - sparse_categorical_accuracy: 0.9125 - val_loss: 0.3835 - val_sparse_categorical_accuracy: 0.9215\n","Epoch 34/40\n","563/563 [==============================] - 626s 1s/step - loss: 0.4345 - sparse_categorical_accuracy: 0.9136 - val_loss: 0.3783 - val_sparse_categorical_accuracy: 0.9224\n","Epoch 35/40\n","563/563 [==============================] - 610s 1s/step - loss: 0.4301 - sparse_categorical_accuracy: 0.9141 - val_loss: 0.3758 - val_sparse_categorical_accuracy: 0.9229\n","Epoch 36/40\n","563/563 [==============================] - 626s 1s/step - loss: 0.4262 - sparse_categorical_accuracy: 0.9144 - val_loss: 0.3734 - val_sparse_categorical_accuracy: 0.9228\n","Epoch 37/40\n","563/563 [==============================] - 603s 1s/step - loss: 0.4202 - sparse_categorical_accuracy: 0.9153 - val_loss: 0.3700 - val_sparse_categorical_accuracy: 0.9235\n","Epoch 38/40\n","563/563 [==============================] - 625s 1s/step - loss: 0.4168 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.3664 - val_sparse_categorical_accuracy: 0.9245\n","Epoch 39/40\n","563/563 [==============================] - 608s 1s/step - loss: 0.4125 - sparse_categorical_accuracy: 0.9163 - val_loss: 0.3650 - val_sparse_categorical_accuracy: 0.9247\n","Epoch 40/40\n","548/563 [============================>.] - ETA: 14s - loss: 0.4080 - sparse_categorical_accuracy: 0.9169"]}]},{"cell_type":"markdown","source":["### Test del modello\n","La seguente cella permette di caricare l'ultimo checkpoint dell'addestramento\n","precedentemente salvato."],"metadata":{"id":"ReOkcBp2WHWW"}},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"5PIf_6-RSBb1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Translate:\n","  def __init__(self, transformer_block, tokenizers, tokenizer_bert):\n","    self.transformer = transformer_block\n","    self.tokenizers = tokenizers\n","    self.tokenizer_bert = tokenizer_bert\n","\n","  def predict(self, input_text, max_length):\n","    if input_text is None:\n","      input_text = input_data[np.random.choice(len(input_data))]\n","      print(input_text)\n","\n","    inputs_bert = self.tokenizer_bert(input_text)\n","\n","    start_end = self.tokenizers.it.tokenize([''])[0]\n","    start = start_end[0][tf.newaxis]\n","    end = (start_end[1][tf.newaxis]).numpy()[0]\n","\n","    output_array = tf.TensorArray(dtype=tf.int64, size=max_length, dynamic_size=True)\n","    output_array = output_array.write(0, start)     \n","\n","    out_words = []\n","\n","    for i in tf.range(max_length):\n","      # decodifica e recupero probabilità di output\n","      output = tf.transpose(output_array.stack())\n","      \n","      transformer_output = transformer([inputs_bert, output], \n","                                        training=False,\n","                                        debug=False)\n","\n","      predictions = transformer_output[:, -1:, :]\n","\n","      # selezione della parola più probabile\n","      predict = tf.argmax(predictions, -1)\n","      pred_values = (K.argmax(transformer_output, axis=-1)).numpy()\n","    \n","      # inserimento della parola nella sequenza di output\n","      output_array = output_array.write(i+1, [pred_values[0][i]])\n","\n","      if pred_values[0][i] == end:\n","        break\n","\n","    output = tf.transpose(output_array.stack())\n","    text = tokenizers.it.detokenize(output)[0]  \n","\n","    tokens = tokenizers.it.lookup(output)[0]\n","\n","    return text, tokens"],"metadata":{"id":"L2PEoJVb1V8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_sequences = [test_input_data[41], test_input_data[30], test_input_data[10], \n","                  test_input_data[57], test_input_data[82], test_input_data[15], \n","                  test_input_data[4], test_input_data[42]]\n","\n","translate = Translate(transformer_block=transformer,\n","                      tokenizers=tokenizers,\n","                      tokenizer_bert=tokenizer_encoder)\n","\n","for test_sequence in test_sequences:\n","  text, token = translate.predict(tf.constant([test_sequence]), MAX_SEQ_LENGTH)\n","\n","  print(f'{\"Input:\":15s}: {test_sequence}')\n","  print(f'{\"Prediction\":15s}: {text.numpy().decode(\"utf-8\")}')  \n","  # print(f'tokens : {token}')\n","  # print(target_data[41])\n","  # break\n","  print('---------------------------------------------')\n","\n","print(test_target_data[41])\n","print(test_target_data[30])\n","print(test_target_data[10])\n","print(test_target_data[57])\n","print(test_target_data[82])\n","print(test_target_data[15])\n","print(test_target_data[4])\n","print(test_target_data[42])"],"metadata":{"id":"udIjI2jZWR6g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Tensorboard"],"metadata":{"id":"YJf4hjv4PMAJ"}},{"cell_type":"code","source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"metadata":{"id":"vcwHe7VJWt-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_dir"],"metadata":{"id":"7AB28JmGPQgi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir drive/MyDrive/BERT/logs/fit/20221026-134720"],"metadata":{"id":"2ZkkDKVwPT2O"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":["FOXy7yFkxt4q","YJf4hjv4PMAJ"]},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}