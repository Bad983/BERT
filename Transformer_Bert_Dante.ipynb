{"cells":[{"cell_type":"code","source":["!pip install -q -U 'tensorflow-text==2.8.*'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NE4enZGpvMRX","executionInfo":{"status":"ok","timestamp":1672872256330,"user_tz":-60,"elapsed":47688,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"bd7bbe9f-9d7b-4735-df8c-385cc519595e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 KB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install -q tf-models-official"],"metadata":{"id":"FPtWz_qHuofc","executionInfo":{"status":"ok","timestamp":1672872311021,"user_tz":-60,"elapsed":54699,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba1cec47-8ad6-4659-c1e3-5f6ea7a6d783"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"hJy-juNOpUOY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672872332748,"user_tz":-60,"elapsed":21744,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"f8906011-4941-4064-bd4e-076577f8f276"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"UaAiWsEuC_4K"},"outputs":[],"source":["import os\n","import re\n","import time\n","import unicodedata\n","import datetime\n","import pathlib\n","import json\n","\n","from pathlib import Path\n","\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","from keras import layers\n","\n","import tensorflow_hub as hub\n","import tensorflow_models as tfm\n","\n","import tensorflow_text as text\n","from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"]},{"cell_type":"code","source":["tf.get_logger().setLevel('ERROR')\n","tf.config.run_functions_eagerly(True)"],"metadata":{"id":"uKEqRlKowOQS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Parametri BERT"],"metadata":{"id":"BehZY4rETECN"}},{"cell_type":"code","source":["bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'  \n","tfhub_handle_encoder =  'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n","\n","print('BERT model selected                : ', tfhub_handle_encoder)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fodDcY6sm392","executionInfo":{"status":"ok","timestamp":1672872341074,"user_tz":-60,"elapsed":22,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"88a330ab-b956-4afe-fc8e-02ea9ceb0fe0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT model selected                :  https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n"]}]},{"cell_type":"markdown","source":["### Variabili Globali"],"metadata":{"id":"HRe16D-rUBLA"}},{"cell_type":"code","source":["# PARAMETRI GLOBALI\n","root_folder = 'drive/MyDrive/BERT/'\n","\n","# DATI\n","data_folder_name = 'data'\n","data_filename = 'dataset_dantesco.csv'\n","train_filename = 'train_dataset_dantesco_v2.csv'\n","\n","DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n","data_filenamepath = os.path.abspath(os.path.join(DATA_PATH, data_filename))\n","train_data_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n","\n","# PATH LOG Tensorboard\n","PATH_LOG = 'logs/fit/transformer_bert_dante'\n","PATH_LOG = os.path.abspath(os.path.join(root_folder, PATH_LOG))\n","log_dir =  os.path.abspath(os.path.join(PATH_LOG, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))) \n","log_history = os.path.abspath(os.path.join(PATH_LOG, 'histrory.json'))\n","\n","# PATH WEIGHTS Tensorboard\n","PATH_WEIGHTS = 'weights/transformer_bert_dante'\n","PATH_WEIGHTS = os.path.abspath(os.path.join(root_folder, PATH_WEIGHTS))\n","checkpoint_path = os.path.abspath(os.path.join(PATH_WEIGHTS, 'cp.ckpt'))\n","\n","# VOCABOLARIO\n","vocab_folder = 'vocab'\n","ita_vocab_finalname = 'ita_vocab_dante.txt'\n","dan_vocab_finalname = 'dan_vocab_dante.txt'\n","\n","VOCAB_PATH = os.path.abspath(os.path.join(root_folder, vocab_folder))\n","ita_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, ita_vocab_finalname))\n","dan_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, dan_vocab_finalname))"],"metadata":{"id":"ewLgCIuEpczO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# parametri per il modello\n","ORIGINAL_COLUMN = 'Original'\n","TRANSLATE_COLUMN = 'Translate'\n","\n","# parametri per il modello\n","NUM_SAMPLES = 68248 \n","TRAIN = 16000 \n","VALIDATION = 16000\n","N_VALIDATION = 5\n","TEST = 100\n","\n","MAX_VOCAB_SIZE = 20000 \n","EMBEDDING_DIM = 64\n","HIDDEN_DIM = 1024 # numero di celle nei layer ricorrenti nascosti\n","\n","BATCH_SIZE = 32\n","BUFFER_SIZE = 2000\n","MAX_SEQ_LENGTH = 64\n","\n","NUM_LAYERS = 1 # Numero di layer di Decoder del Transformer\n","NUM_HEADS = 8 # Numero di meccanismi di multi-head attention\n","FF_DIM = 16 # Numero di celle dei Layer Feed Forward\n","DROPUOT = 0.5\n","\n","# Ottimizzatore Adam\n","LEARNING_RATE_ADAM = 3e-4\n","BETA_1 = 0.66\n","BETA_2 = 0.999\n","EPOCHS_ADAM = 5\n","\n","# IMPOSTO IL DEBUG A TRUE \n","debug = True\n","training = True"],"metadata":{"id":"8CN-4Uzoqbjl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## DATASET"],"metadata":{"id":"5DPeN9Vanbvv"}},{"cell_type":"markdown","source":["### Caricamento Dati"],"metadata":{"id":"LU7AorKXT8K7"}},{"cell_type":"code","source":["exist_data_file = Path(train_data_filenamepath)\n","\n","if not exist_data_file.exists():\n","  # Caricamento dataset: frasi in inglese, frasi in italiano\n","  df = pd.read_csv(\n","    data_filenamepath,\n","    usecols=[ORIGINAL_COLUMN, TRANSLATE_COLUMN],\n","    names=[ORIGINAL_COLUMN, TRANSLATE_COLUMN],\n","    dtype={ORIGINAL_COLUMN: str, TRANSLATE_COLUMN: str}\n","  )\n","\n","  # df = df[-(TRAIN+VALIDATION+TEST):].reset_index(drop=True)\n","\n","  # Mischio il dataset in modo che sia più uniforme tra train e test\n","  df = df.iloc[np.random.permutation(df.index)].reset_index(drop=True)\n","\n","  print(df.iloc[-4:], '\\n')\n","\n","  df.to_csv(train_data_filenamepath, header=False, index=False, sep='|', columns=[ORIGINAL_COLUMN, TRANSLATE_COLUMN])"],"metadata":{"id":"vU7qvEPQ581U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def unicode_to_ascii(s):\n","  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n","\n","def preprocess_sentence(w):\n","  '''\n","  Preprocessing dei testi di input, impostando tutti i caratteri\n","  minuscoli, aggiungendo uno spazio prima di ogni punto e sostituendo\n","  qualsiasi carattere con uno spazio se non è compreso nel seguente elenco:\n","  (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","  '''\n","  w = unicode_to_ascii(w.lower().strip())\n","\n","  # inserimento di uno spazio tra ogni parola e il successivo punto,\n","  # punto esclamativo, punto interrogativo e virgola\n","  # esempio: \"ciao, come và?\" => \"ciao , come và ?\"\n","  w = re.sub(r\"([?.!,])\", r\" \\1 \", w) # inserimento di uno spazio\n","\n","  # sostituzione dei caratteri non desiderati con uno spazio\n","  w = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", w)\n","\n","  w = re.sub(r'[\" \"]+', \" \", w) # rimozione di più spazi consecutivi\n","  return w"],"metadata":{"id":"Jm_Up6gyOTgW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\n","  train_data_filenamepath,\n","  usecols=[ORIGINAL_COLUMN, TRANSLATE_COLUMN],\n","  names=[ORIGINAL_COLUMN, TRANSLATE_COLUMN],\n","  sep = '|'\n",")\n","\n","# Preprocessing dei dati di Input\n","input_data = df[TRANSLATE_COLUMN].apply(lambda x : preprocess_sentence(x)).tolist()\n","\n","# Preprocessing dei dati Target con aggiunta del token di fine frase\n","target_data = df[ORIGINAL_COLUMN].apply(lambda x : preprocess_sentence(x)).tolist()\n","\n","train_input_data = input_data[:TRAIN]\n","train_target_data = target_data[:TRAIN]\n","\n","validation_input_data = input_data[TRAIN:TRAIN+VALIDATION]\n","validation_target_data = target_data[TRAIN:TRAIN+VALIDATION]\n","\n","test_input_data = input_data[TRAIN+VALIDATION:TRAIN+VALIDATION+TEST]\n","test_target_data = target_data[TRAIN+VALIDATION:TRAIN+VALIDATION+TEST]\n","\n","print(f'Dati totali presenti nel Dataset               : {len(df)}')\n","print(f'Dati totali presenti nel Dataset di Train      : {len(train_input_data)}')\n","print(f'Dati totali presenti nel Dataset di Validation : {len(validation_input_data)}')\n","print(f'Dati totali presenti nel Dataset di Test       : {len(test_input_data)}\\n')\n","\n","\n","print('-----------TRAIN SET--------------')\n","print(train_input_data[-4:])\n","print(train_target_data[-4:])\n","print('-----------VALIDATION SET---------------')\n","print(validation_input_data[-4:])\n","print(validation_target_data[-4:])\n","print('-----------TEST SET---------------')\n","print(test_input_data[-4:])\n","print(test_target_data[-4:])"],"metadata":{"id":"NcEcrx2L2m5z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672872350146,"user_tz":-60,"elapsed":7805,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"ef3525bc-256e-4df7-a72f-c8f8de75e610"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dati totali presenti nel Dataset               : 68249\n","Dati totali presenti nel Dataset di Train      : 16000\n","Dati totali presenti nel Dataset di Validation : 16000\n","Dati totali presenti nel Dataset di Test       : 100\n","\n","-----------TRAIN SET--------------\n","['queste persone guardano dove veli il sole . ', 'ho detto dentro di me , perche ho sentito', ' colui che hai scritto , la vita risplende , ', 'quest uomo non ha ancora visto il suo ultimo tramonto , ']\n","['tutta rimira la dove l sol veli . ', 'fra me stesso dicea , che mi sentiva', ' inclita vita per cui la larghezza', 'che sono in voi si come studio in ape']\n","-----------VALIDATION SET---------------\n","['e come il bordo delle palpebre sog', 'erano tutti i cerchi della sacra montagna , ', 'che era il gap attraverso il quale io e la mia guida , ', 'insieme con le nostre caratteristiche al forno e sterile , ']\n","['e si come di lei bevve la gronda', 'de l alto di i giron del sacro monte , ', 'che non era la calla onde saline', 'rende in dispetto noi e nostri prieghi , ']\n","-----------TEST SET---------------\n","['insomma , il paradiso stesso . anch io ho gloriato in te . ', 'e vi ho veduto una folla tremenda', 'ha la piu somiglianza per la sua luminosita solo', 'guarda con amore il suo creatore . ']\n","['dico nel cielo , io me ne gloriai . ', 'e vidivi entro terribile stipa', 'piu si somiglia , che la sua chiarezza', 'che la prima virtu creasse mai . ']\n"]}]},{"cell_type":"markdown","source":["### Analisi Dati"],"metadata":{"id":"q1u_rcHxUaqV"}},{"cell_type":"code","source":["print(f'Esempi nel Dataset di Train                            : {len(train_input_data)}')\n","print(f'Frase più corta in Italiano nel Dataset di Train       : {min(train_input_data, key = len)}')\n","print(f'Frase più corta in Dantesco nel Dataset di Train       : {min(train_target_data, key = len)}')\n","print(f'Frase più lunga in Italiano nel Dataset di Train       : {max(train_input_data, key = len)}')\n","print(f'Frase più lunga in Dantesco nel Dataset di Train       : {max(train_target_data, key = len)}')\n","print('---------------------------------------------------------------------------------------')\n","print(f'Esempi nel Dataset di Validation                       : {len(validation_input_data)}')\n","print(f'Frase più corta in Italiano nel Dataset di Validation  : {min(validation_input_data, key = len)}')\n","print(f'Frase più corta in Dantesco nel Dataset di Validation  : {min(validation_target_data, key = len)}')\n","print(f'Frase più lunga in Italiano nel Dataset di Validation  : {max(validation_input_data, key = len)}')\n","print(f'Frase più lunga in Dantesco nel Dataset di Validation  : {max(validation_target_data, key = len)}')\n","print('---------------------------------------------------------------------------------------')\n","print(f'Esempi nel Dataset di Test                             : {len(test_input_data)}')\n","print(f'Frase più corta in Italiano nel Dataset di Test        : {min(test_input_data, key = len)}')\n","print(f'Frase più corta in Dantesco nel Dataset di Test        : {min(test_target_data, key = len)}')\n","print(f'Frase più lunga in Italiano nel Dataset di Test        : {max(test_input_data, key = len)}')\n","print(f'Frase più lunga in Dantesco nel Dataset di Test        : {max(test_target_data, key = len)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rssHK6CUcRL","executionInfo":{"status":"ok","timestamp":1672872350146,"user_tz":-60,"elapsed":36,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"fe260eb5-807c-4a03-a718-de81d4d2a7d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Esempi nel Dataset di Train                            : 16000\n","Frase più corta in Italiano nel Dataset di Train       : e poi ho detto \n","Frase più corta in Dantesco nel Dataset di Train       : trasumanar significar\n","Frase più lunga in Italiano nel Dataset di Train       : l impatto sull ambiente e sull ambiente di lavoro e di gran lunga superiore a quello degli altri paesi . \n","Frase più lunga in Dantesco nel Dataset di Train       : dal quinto il quarto , e poi dal sesto il quinto . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Validation                       : 16000\n","Frase più corta in Italiano nel Dataset di Validation  : translate\n","Frase più corta in Dantesco nel Dataset di Validation  : original\n","Frase più lunga in Italiano nel Dataset di Validation  : il peccatore affondo , poi si alzo di nuovo , la sua faccia tutta intonazione . \n","Frase più lunga in Dantesco nel Dataset di Validation  :  oh ! , diss io , padre , che voci son queste ? . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Test                             : 100\n","Frase più corta in Italiano nel Dataset di Test        : il grembo di trento\n","Frase più corta in Dantesco nel Dataset di Test        : ne quella rodopea che delusa\n","Frase più lunga in Italiano nel Dataset di Test        : cantava in modo tale saggio che il discorso non poteva dirlo . \n","Frase più lunga in Dantesco nel Dataset di Test        : molti han giustizia in cuore , e tardi scocca\n"]}]},{"cell_type":"markdown","source":["## Tokenizer\n","\n","Creo due differenti tokenizer che mi servizranno per la predisposizione dei dati di input:\n","\n","\n","*   EncTokenizer classe custom per la tokenizzazione dei dati di input al Layer di Encoder di Bert\n","*   DecTokenizer classe custom per la tokenizzazione dei dati di input al Layer di Decoder\n","\n"],"metadata":{"id":"njyY9RWlFMWu"}},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices((input_data, target_data))\n","dataset = dataset.shuffle(len(input_data)).batch(BATCH_SIZE, drop_remainder=True)\n","\n","train_ita = dataset.map(lambda ita, dan: ita)\n","train_dan = dataset.map(lambda ita, dan: dan)"],"metadata":{"id":"fUG1fTAYekOy","executionInfo":{"status":"ok","timestamp":1672872353954,"user_tz":-60,"elapsed":3837,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e2aee8fd-5bcf-4210-a009-d837b4e12966"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def write_vocab_file(filepath, vocab):\n","  with open(filepath, 'w') as f:\n","    for token in vocab:\n","      print(token, file=f)"],"metadata":{"id":"xWO-LrXJe0cF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cleanup_text(reserved_tokens, token_txt):\n","\n","  # Drop the reserved tokens, except for \"[UNK]\".\n","  bad_tokens = [re.escape(tok) for tok in reserved_tokens if tok != \"[UNK]\"]\n","  bad_token_re = \"|\".join(bad_tokens)\n","\n","  bad_cells = tf.strings.regex_full_match(token_txt, bad_token_re)\n","  result = tf.ragged.boolean_mask(token_txt, ~bad_cells)\n","\n","  # Join them into strings.\n","  result = tf.strings.reduce_join(result, separator=' ', axis=-1)\n","\n","  return result"],"metadata":{"id":"yGdsrOoKiYUK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizers = tf.Module()"],"metadata":{"id":"qbKNS_uQhHLz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Classe EncTokenizer\n","\n","Classe custom per la tokenizzazione dei dati di Dante e che crea i tre vettori necessari al layer di Encoder \n","Bert:\n","\n","\n","*   input_word_ids\n","*   input_type_ids\n","*   input_mask\n","\n","\n","\n"],"metadata":{"id":"0KUcCnjXVjt3"}},{"cell_type":"code","source":["bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens = {\n","    'start_of_sequence_id': 101,\n","    'end_of_segment_id': 102,\n","    'padding_id': 0,\n","    'mask_id': 103\n","}\n","\n","bert_vocab_args = dict(\n","    # The target vocabulary size\n","    vocab_size = MAX_VOCAB_SIZE,\n","    # Reserved tokens that must be included in the vocabulary\n","    reserved_tokens=reserved_tokens,\n","    # Arguments for `text.BertTokenizer`\n","    bert_tokenizer_params=bert_tokenizer_params,\n","    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","    learn_params={},\n",")"],"metadata":{"id":"Yr0izOZLembx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(ita_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  ita_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_ita.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(ita_vocab_filenamepath, ita_vocab)"],"metadata":{"id":"BwSKtlLSe7bH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EncTokenizer(tf.Module):\n","  def __init__(self, reserved_tokens, vocab_path, max_len):\n","    self.tokenizer = text.BertTokenizer(vocab_path, lower_case=True, token_out_type=tf.int32)\n","    self._reserved_tokens_vocab = reserved_tokens\n","    self._vocab_path = tf.saved_model.Asset(vocab_path)\n","    self.packer_input = tfm.nlp.layers.BertPackInputs(seq_length=max_len,\n","                                                      special_tokens_dict=reserved_tokens)\n","    \n","    vocab = pathlib.Path(vocab_path).read_text().splitlines()\n","    self.vocab = tf.Variable(vocab)\n","\n","    ## Create the signatures for export:   \n","\n","    # Include a tokenize signature for a batch of strings. \n","    self.tokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None], dtype=tf.string))\n","    \n","    # Include `detokenize` and `lookup` signatures for:\n","    #   * `Tensors` with shapes [tokens] and [batch, tokens]\n","    #   * `RaggedTensors` with shape [batch, tokens]\n","    self.detokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.detokenize.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    self.lookup.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.lookup.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    # These `get_*` methods take no arguments\n","    self.get_vocab_size.get_concrete_function()\n","    self.get_vocab_path.get_concrete_function()\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    enc = self.tokenizer.tokenize(strings, )\n","    # Merge the `word` and `word-piece` axes.\n","    enc = enc.merge_dims(-2,-1)\n","    enc = self.packer_input([enc])\n","    return enc\n","\n","  @tf.function\n","  def detokenize(self, tokenized):\n","    words = self.tokenizer.detokenize(tokenized)\n","    return cleanup_text(self._reserved_tokens_vocab, words)\n","\n","  @tf.function\n","  def lookup(self, token_ids):\n","    return tf.gather(self.vocab, token_ids)\n","\n","  @tf.function\n","  def get_vocab_size(self):\n","    return tf.shape(self.vocab)[0]\n","\n","  @tf.function\n","  def get_vocab_path(self):\n","    return self._vocab_path"],"metadata":{"id":"WmsNdDLNf6vr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizers.ita = EncTokenizer(reserved_tokens, ita_vocab_filenamepath, MAX_SEQ_LENGTH*2)"],"metadata":{"id":"-4B-HWWcmsmz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Classe DecTokenizer\n","\n","Classe custom per la tokenizzazione dei dati in lingua italiana per il layer di Decoder\n"],"metadata":{"id":"mICEGEzJVnvx"}},{"cell_type":"code","source":["bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens_vocab=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","bert_vocab_args = dict(\n","    # The target vocabulary size\n","    vocab_size = MAX_VOCAB_SIZE,\n","    # Reserved tokens that must be included in the vocabulary\n","    reserved_tokens=reserved_tokens_vocab,\n","    # Arguments for `text.BertTokenizer`\n","    bert_tokenizer_params=bert_tokenizer_params,\n","    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","    learn_params={},\n",")"],"metadata":{"id":"abBEnJJGV0AD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(dan_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  dan_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_dan.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(dan_vocab_filenamepath, dan_vocab)"],"metadata":{"id":"dGsP1V4nVz6S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["START = tf.argmax(tf.constant(reserved_tokens_vocab) == \"[START]\")\n","END = tf.argmax(tf.constant(reserved_tokens_vocab) == \"[END]\")\n","\n","def add_start_end(ragged):\n","  count = ragged.bounding_shape(out_type=tf.int32)[0]\n","\n","  starts = tf.fill([count,1], START)\n","  starts = tf.cast(starts, tf.int32)\n","\n","  ends = tf.fill([count,1], END)\n","  ends = tf.cast(ends, tf.int32)\n","\n","  x = tf.concat([starts, ragged, ends], axis=1)\n","  return x"],"metadata":{"id":"BeaD2-uLWT50"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DecTokenizer(tf.Module):\n","  def __init__(self, reserved_tokens_vocab, vocab_path):\n","    self.tokenizer = text.BertTokenizer(vocab_path, lower_case=True, token_out_type=tf.int32)\n","    self._reserved_tokens_vocab = reserved_tokens_vocab\n","    self._vocab_path = tf.saved_model.Asset(vocab_path)\n","\n","    vocab = pathlib.Path(vocab_path).read_text().splitlines()\n","    self.vocab = tf.Variable(vocab)\n","\n","    ## Create the signatures for export:   \n","\n","    # Include a tokenize signature for a batch of strings. \n","    self.tokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None], dtype=tf.string))\n","    \n","    # Include `detokenize` and `lookup` signatures for:\n","    #   * `Tensors` with shapes [tokens] and [batch, tokens]\n","    #   * `RaggedTensors` with shape [batch, tokens]\n","    self.detokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.detokenize.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    self.lookup.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.lookup.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    # These `get_*` methods take no arguments\n","    self.get_vocab_size.get_concrete_function()\n","    self.get_vocab_path.get_concrete_function()\n","    self.get_reserved_tokens.get_concrete_function()\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    enc = self.tokenizer.tokenize(strings)\n","    # Merge the `word` and `word-piece` axes.\n","    enc = enc.merge_dims(-2,-1)\n","    enc = add_start_end(enc)\n","    return enc\n","\n","  @tf.function\n","  def detokenize(self, tokenized):\n","    words = self.tokenizer.detokenize(tokenized)\n","    return cleanup_text(self._reserved_tokens_vocab, words)\n","\n","  @tf.function\n","  def lookup(self, token_ids):\n","    return tf.gather(self.vocab, token_ids)\n","\n","  @tf.function\n","  def get_vocab_size(self):\n","    return tf.shape(self.vocab)[0]\n","\n","  @tf.function\n","  def get_vocab_path(self):\n","    return self._vocab_path\n","\n","  @tf.function\n","  def get_reserved_tokens(self):\n","    return tf.constant(self._reserved_tokens_vocab)"],"metadata":{"id":"iaAW-xm5WT1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizers.dan = DecTokenizer(reserved_tokens_vocab, dan_vocab_filenamepath)"],"metadata":{"id":"svlLobM4WTzC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Analisi Dati Tokenizzati"],"metadata":{"id":"pKZxiQ5_Whmw"}},{"cell_type":"code","source":["print(f'Vocabolario Italiano : {tokenizers.ita.get_vocab_size()}')\n","print(f'Vocabolario Dantesco : {tokenizers.dan.get_vocab_size()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jrg6TwQzW5LN","executionInfo":{"status":"ok","timestamp":1672872363577,"user_tz":-60,"elapsed":21,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"656cdef6-897b-4d99-cc92-2fba154be50c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabolario Italiano : 5140\n","Vocabolario Dantesco : 6312\n"]}]},{"cell_type":"code","source":["print(input_data[-2:])\n","print(tokenizers.ita.tokenize(input_data[-2:])['input_word_ids'][:, :32])\n","print('------------------------------------------------------------------')\n","print(target_data[-2:])\n","print(tokenizers.dan.tokenize(target_data[-2:]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKEFeDdGFIGS","executionInfo":{"status":"ok","timestamp":1672872363999,"user_tz":-60,"elapsed":437,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"cc0789ee-f36a-4873-97d9-8b0a97c8efaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['era quasi al punto in cui si imposta . ', ' o anima che parla cosi bene , ']\n","tf.Tensor(\n","[[ 101   63  520   60  219   39   72   41   16  890 1684  794    6  102\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0]\n"," [ 101   22  192   34  572   45  151    5  102    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0]], shape=(2, 32), dtype=int32)\n","------------------------------------------------------------------\n","['lo sole in pria , che gia nel corcar era . ', ' o anima che tanto ben favelle , ']\n","<tf.RaggedTensor [[2, 51, 267, 38, 166, 5, 31, 70, 62, 4880, 64, 6, 3],\n"," [2, 20, 203, 31, 72, 79, 1906, 5, 3]]>\n"]}]},{"cell_type":"code","source":["print([min(train_input_data, key = len)])\n","print(tokenizers.ita.tokenize([min(train_input_data, key = len)])['input_word_ids'][:, :32])\n","print('------------------------------------------------------------------')\n","print([min(train_target_data, key = len)])\n","print(tokenizers.dan.tokenize([min(train_target_data, key = len)]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O85BUq2INK5j","executionInfo":{"status":"ok","timestamp":1672872364000,"user_tz":-60,"elapsed":17,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"576d9910-d6ab-4f92-ddfc-25cddf3ce697"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['e poi ho detto ']\n","tf.Tensor(\n","[[101  12  82  52 169 102   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(1, 32), dtype=int32)\n","------------------------------------------------------------------\n","['trasumanar significar']\n","<tf.RaggedTensor [[2, 115, 440, 4446, 2893, 80, 34, 982, 4085, 80, 3]]>\n"]}]},{"cell_type":"code","source":["print([max(train_input_data, key = len)])\n","print(tokenizers.ita.tokenize([max(train_input_data, key = len)])['input_word_ids'])\n","print('------------------------------------------------------------------')\n","print([max(train_target_data, key = len)])\n","print(tokenizers.dan.tokenize([max(train_target_data, key = len)]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JzJl4YGBPR3Z","executionInfo":{"status":"ok","timestamp":1672872364306,"user_tz":-60,"elapsed":316,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"13787a63-5c80-4415-ac32-a14b194e4296"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['l impatto sull ambiente e sull ambiente di lavoro e di gran lunga superiore a quello degli altri paesi . ']\n","tf.Tensor(\n","[[ 101   19   16  890 1257  443  408    8  890 1265 1680   12  408    8\n","   890 1265 1680   37 1240   12   37 1402  588 1897    8   92  298  159\n","    23  205 2389  199    6  102    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]], shape=(1, 128), dtype=int32)\n","------------------------------------------------------------------\n","['dal quinto il quarto , e poi dal sesto il quinto . ']\n","<tf.RaggedTensor [[2, 93, 1264, 45, 1424, 5, 12, 60, 93, 1149, 45, 1264, 6, 3]]>\n"]}]},{"cell_type":"markdown","source":["## Creazione dataset\n","Utilizzo della libreria tf.data per la gestione del dataset da utilizzare.\n","Verranno creati batch di esempi che verranno utilizzati durante l'addestramento."],"metadata":{"id":"5QIDajkEsVU1"}},{"cell_type":"code","source":["def prepare_batch(dan, ita):\n","  zero = tf.zeros([BATCH_SIZE, MAX_SEQ_LENGTH], tf.int32)\n","\n","  # Tokenizzo l'input per l'Encoder\n","  encoder = tokenizers.ita.tokenize(ita)          \n","\n","  # Tokenizzo l'input per il Decder e creo la variabile Target\n","  dan = tokenizers.dan.tokenize(dan)\n","  decoder = dan[:, :-1].to_tensor()  # Drop the [END] tokens\n","  target = dan[:, 1:].to_tensor()   # Drop the [START] tokens\n","  \n","  decoder = tf.concat([decoder, zero], 1)\n","  decoder = decoder[:, :(MAX_SEQ_LENGTH)]\n","\n","  target = tf.concat([target, zero], 1)\n","  target = target[:, :(MAX_SEQ_LENGTH)]\n","\n","  return (encoder, decoder), target"],"metadata":{"id":"ccH3jHoABPzV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_batches(ds):\n","  return (\n","      ds\n","      .shuffle(BUFFER_SIZE)\n","      .batch(BATCH_SIZE)\n","      .map(prepare_batch, tf.data.AUTOTUNE)\n","      .prefetch(buffer_size=tf.data.AUTOTUNE))"],"metadata":{"id":"l_dswlCiBTdR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Suddivido il dataset di validation in n parti per effettuare una validation incrociata\n","num_record_validation = len(validation_input_data) / N_VALIDATION\n","val_input_data = []\n","val_target_data = []\n","\n","for i in range(N_VALIDATION):\n","  df_input = validation_input_data[int((i*num_record_validation)):int(((i+1)*num_record_validation))]\n","  df_target = validation_target_data[int((i*num_record_validation)):int(((i+1)*num_record_validation))]\n","\n","  val_input_data.append(df_input)\n","  val_target_data.append(df_target)"],"metadata":{"id":"ess3ZrYA3H0h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Definizione del dataset\n","# [from_tensor_slices] permette di recuperare batch\n","# di esempi dai dataset di riferimento\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_input_data, train_target_data))\n","validation_dataset = [tf.data.Dataset.from_tensor_slices((val_input, val_target)) \n","                            for val_input, val_target in zip(val_input_data, val_target_data)]\n","\n","# impostazione del recupero di esempi presi in maniera\n","# casuale in gruppi di [BATCH_SIZE] tra quelli disponibili\n","train_dataset = make_batches(train_dataset)\n","validation_dataset = [make_batches(val_dataset) for val_dataset in validation_dataset]"],"metadata":{"id":"tktJ5YuIsYe3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Recupero un batch di esempi per la verifica delle classi custom che andrò a creare\n","for (enc_input, dec_input), target in train_dataset.take(1):\n","  print('----------------------- ENCODER  -------------------------------')\n","  print(f'Shape                    : {enc_input[\"input_word_ids\"].shape}')\n","  print(f'Word Ids                 : {enc_input[\"input_word_ids\"][0, :MAX_SEQ_LENGTH]}')\n","  print(f'Input Mask               : {enc_input[\"input_mask\"][0, :MAX_SEQ_LENGTH]}')\n","  print(f'Type Ids                 : {enc_input[\"input_type_ids\"][0, :MAX_SEQ_LENGTH]}')  \n","  print('--------------------- DECODER ----------------------------------')\n","  print(f'Shape it input           : {dec_input.shape}')\n","  print(f'Example it input         : {dec_input[0]}')  \n","  print('--------------------- TARGET -----------------------------------')\n","  print(f'Shape it input           : {target.shape}')\n","  print(f'Example it target        : {target[0]}')  "],"metadata":{"id":"VH_aKPlV_AWA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672872374860,"user_tz":-60,"elapsed":575,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"39972143-875d-4405-be50-9f3ae15eced4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------- ENCODER  -------------------------------\n","Shape                    : (32, 128)\n","Word Ids                 : [ 101 2304   34    5   43  112   36  620  205   27 1256  452  102    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n","Input Mask               : [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","Type Ids                 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","--------------------- DECODER ----------------------------------\n","Shape it input           : (32, 64)\n","Example it input         : [   2   47  297    8  247  177 4106  145  440 1575 1495    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n","--------------------- TARGET -----------------------------------\n","Shape it input           : (32, 64)\n","Example it target        : [  47  297    8  247  177 4106  145  440 1575 1495    3    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n"]}]},{"cell_type":"markdown","source":["## Encoder BERT\n","\n","Predispondo la classe necessaria per la costruzione di BERT\n"],"metadata":{"id":"8dtVuZGJpvXl"}},{"cell_type":"code","source":["class EncoderBert(layers.Layer):\n","  def __init__(self, bert_encoder, embedding_dim, max_len):\n","    super(EncoderBert, self).__init__()\n","\n","    self.encoder = hub.KerasLayer(bert_encoder, name='BERT_encoder', trainable=False)\n","\n","    self.conv_1 = tf.keras.layers.Conv1D(embedding_dim * 4, 1, activation='relu') \n","    self.conv_2 = tf.keras.layers.Conv1D(embedding_dim, 1, activation='relu') \n","    self.lambda_layer = tf.keras.layers.Lambda(lambda x: x[:,:max_len])\n","    self.max_len = max_len\n","\n","  def call(self, x, debug=False):\n","\n","    if debug:\n","      print(f'****************** DEBUG ENCODER BERT ******************')\n","      print(f\"First example\")\n","      print(f'Keys                         : {list(x.keys())}')\n","      print(f'Shape                        : {x[\"input_word_ids\"].shape}')\n","      print(f'Word Ids                     : {x[\"input_word_ids\"][0, :16]}')\n","      print(f'Input Mask                   : {x[\"input_mask\"][0, :16]}')\n","      print(f'Type Ids                     : {x[\"input_type_ids\"][0, :16]}')\n","      \n","    # x = self.encoder(x)['sequence_output'] \n","    # encoder_outputs stato intermedio di BERT prima che esegua la traduzione recuperare la metà della lunghezza\n","    x = self.encoder(x)['encoder_outputs'] \n","    x = x[int(len(x) / 2) - 1]\n","\n","    if debug:\n","      print()\n","      print(f'Encoder Outputs BERT Shape   : {x.shape}')\n","      print(f'Encoder Outputs BERT Values  : {x[0, :1, :16]}')\n","\n","    x = self.conv_1(x)\n","    if debug:\n","      print()\n","      print(f'Sequence Conv1 Shape         : {x.shape}')\n","\n","    x = self.conv_2(x)\n","    if debug:\n","      print(f'Sequence Conv2 Shape         : {x.shape}')\n","\n","    x = self.lambda_layer(x)\n","    if debug:\n","      print(f'Sequence Lambda Layer        : {x.shape}')\n","      print()\n","      print(f'Sequence Outputs Values      : {x[0, 0, :16]}')      \n","      print('*********************************************************') \n","\n","    return x"],"metadata":{"id":"m7v9Y-Lep4CD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_bert = EncoderBert(tfhub_handle_encoder, \n","                           EMBEDDING_DIM, \n","                           MAX_SEQ_LENGTH)\n","\n","bert_outputs = encoder_bert(enc_input, debug) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q08luTkusEfn","executionInfo":{"status":"ok","timestamp":1672872396179,"user_tz":-60,"elapsed":21324,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"16dc5b4f-807b-44a2-8b04-76770115ba86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_word_ids', 'input_mask', 'input_type_ids']\n","Shape                        : (32, 128)\n","Word Ids                     : [ 101 2304   34    5   43  112   36  620  205   27 1256  452  102    0\n","    0    0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n","Type Ids                     : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[-0.33405063 -1.0129808   0.10644107 -0.6329155   0.00306238  0.2516003\n","  -0.3812657  -0.05663675 -0.02651703 -0.70113814 -0.21248774  0.91945016\n","  -0.15525888 -0.06765453 -0.2951241   0.25734887]]\n","\n","Sequence Conv1 Shape         : (32, 128, 256)\n","Sequence Conv2 Shape         : (32, 128, 64)\n","Sequence Lambda Layer        : (32, 64, 64)\n","\n","Sequence Outputs Values      : [0.         0.83197504 0.         0.4509676  0.08894029 0.22460845\n"," 0.         0.         0.         0.0495643  0.66169274 0.\n"," 0.08349717 0.81322867 0.11187759 0.10332558]\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["## Decoder\n","\n","Predispondo la classe necessaria per la costruzione di un Layer di Decoder"],"metadata":{"id":"ReEQ5rX7aGtl"}},{"cell_type":"markdown","source":["### TOKEN AND POSITION EMBEDDING\n","\n","Implementazione del blocco Embedding per l'utilizzo di vettori posizionali insieme ai vettori di token di parole tramite estensione della classe Layer di Keras. "],"metadata":{"id":"gAu1IXlRZzlq"}},{"cell_type":"code","source":["class TokenAndPositionEmbedding(layers.Layer):\n","  def __init__(self, maxlen, vocab_size, embed_dim):\n","    super(TokenAndPositionEmbedding, self).__init__()\n","    self.maxlen = maxlen\n","    self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n","    self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","  def call(self, x, debug=False):\n","    x = keras.preprocessing.sequence.pad_sequences(x, maxlen=self.maxlen, padding='post')\n","    maxlen = tf.shape(x)[-1]\n","\n","    if debug:\n","      print('********** DEBUG TOKEN AND POSITION EMBEDDING ***********')\n","      print(f'Sequence Max len                          : {maxlen}')\n","      print(f'Sequence Shape                            : {tf.shape(x)}')\n","\n","    positions = tf.range(start=0, limit=maxlen, delta=1)\n","    positions = self.pos_emb(positions)\n","    x = self.token_emb(x)\n","    output = x + positions\n","\n","    if debug:\n","      print(f'Shape TokenAndPositionEmbedding           : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"o9-RSKTqsmUC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["token_position_it = TokenAndPositionEmbedding(MAX_SEQ_LENGTH, tokenizers.ita.get_vocab_size(), EMBEDDING_DIM)\n","\n","inputs_decoder = token_position_it(dec_input, debug)"],"metadata":{"id":"rr_EWQUX8EWP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672872396180,"user_tz":-60,"elapsed":7,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"f2a0540c-63f6-430c-d471-acc07d172cdc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 64\n","Sequence Shape                            : [32 64]\n","Shape TokenAndPositionEmbedding           : (32, 64, 64)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["### LAYER DECODER\n","\n","Implementazione di un blocco di DecoderTransformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"XdLv-6nidKGK"}},{"cell_type":"markdown","source":["#### DecodeBert\n","\n","Implmentazione di un blocco di  decodifica custom per decodificare l'output dal layer EncoderBert prima di passarlo al Decoder del Transformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"_iq7Y-d4eRd8"}},{"cell_type":"code","source":["class DecodeBert(layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DecodeBert'):\n","    super(DecodeBert, self).__init__()\n","    self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = keras.Sequential(\n","      [layers.Dense(ff_dim, activation='relu'), layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = layers.LayerNormalization()\n","    self.layernorm2 = layers.LayerNormalization()\n","    self.dropout1 = layers.Dropout(rate)\n","    self.dropout2 = layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, bert_outputs, training=False, debug=False):\n","    attn_output = self.att(query=bert_outputs,\n","                           value=bert_outputs, \n","                           key=bert_outputs)\n","    \n","    attn_output = self.dropout1(attn_output)\n","    out1 = self.layernorm1(bert_outputs + attn_output)\n","\n","    ffn_output = self.ffn(out1)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","\n","    output = self.layernorm2(out1 + ffn_output)\n","\n","    if debug:\n","      print('********************* DEBUG DECODE-BERT *********************')\n","      print(f'Shape Input Layer Decode-Bert       : {bert_outputs.shape}')\n","      print(f'Shape Output Layer Decode-Bert      : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"joTBTlWF8ETD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder = DecodeBert(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_encoder = encoder(bert_outputs=bert_outputs,\n","                          training=training, \n","                          debug=debug)"],"metadata":{"id":"JaIzBxFCfKe9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672872398631,"user_tz":-60,"elapsed":2047,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"a4a6745e-cf83-4bf1-a9e8-859311bdb644"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 64, 64)\n","Shape Output Layer Decode-Bert      : (32, 64, 64)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["#### Layer Decoder"],"metadata":{"id":"dMTKLwd3dRw5"}},{"cell_type":"code","source":["class Decoder(layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DEC'):\n","    super(Decoder, self).__init__()\n","    self.decode_bert = DecodeBert(max_len=max_len, embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, rate=rate)\n","    self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.att2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = keras.Sequential(\n","      [layers.Dense(ff_dim, activation='relu'), layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = layers.LayerNormalization()\n","    self.layernorm2 = layers.LayerNormalization()\n","    self.layernorm3 = layers.LayerNormalization()\n","    self.dropout1 = layers.Dropout(rate)\n","    self.dropout2 = layers.Dropout(rate)\n","    self.dropout3 = layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, inputs, bert_outputs, training=False, debug=False):\n","    attn_output1 = self.att1(query=inputs,\n","                             value=inputs, \n","                             key=inputs, \n","                             use_causal_mask=True)\n","    \n","    attn_output1 = self.dropout1(attn_output1)\n","    out1 = self.layernorm1(inputs + attn_output1)\n","\n","    dec_bert = self.decode_bert(bert_outputs=bert_outputs, training=training, debug=debug)\n","\n","    attn_output2 = self.att2(key=dec_bert, \n","                             value=dec_bert, \n","                             query=out1)\n","    \n","    attn_output2 = self.dropout2(attn_output2, training=training)\n","    out2 = self.layernorm2(out1 + attn_output2)\n","\n","    ffn_output = self.ffn(out2)\n","    ffn_output = self.dropout3(ffn_output, training=training)\n","\n","    output = self.layernorm3(out2 + ffn_output)\n","\n","    if debug:\n","      print('******************* DEBUG DECODER ***********************')\n","      print(f'Input Shape                       : {inputs.shape}')\n","      print(f'Shape Outputs Decoder             : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"SO5rYsFpfFS_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_decoder = decoder(inputs=inputs_decoder, \n","                          bert_outputs=bert_outputs,  \n","                          training=training,\n","                          debug=debug)"],"metadata":{"id":"yysVdkHH8EPH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672872398632,"user_tz":-60,"elapsed":7,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"d5a15fb0-0d51-4d1c-8ed7-bca034674baf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 64, 64)\n","Shape Output Layer Decode-Bert      : (32, 64, 64)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 64, 64)\n","Shape Outputs Decoder             : (32, 64, 64)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["## TRANSFORMER\n","\n","Implementazione del blocco Transformer tramite estensione della classe Layer di Keras."],"metadata":{"id":"ne4zTOG_NKfV"}},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"id":"lw2xMCAMC_4M"},"outputs":[],"source":["class TransformerBlock(keras.Model):\n","  def __init__(self, \n","               num_layers, \n","               embed_dim, \n","               num_heads, \n","               ff_dim, \n","               max_len,\n","               vocab_size,\n","               tfhub_handle_encoder,\n","               rate=0.5):\n","    \n","    super(TransformerBlock, self).__init__()\n","\n","    self.num_layers = num_layers\n","\n","    self.token_pos_dec = TokenAndPositionEmbedding(max_len, vocab_size, embed_dim)\n","\n","    self.encoder = EncoderBert(tfhub_handle_encoder, embed_dim, max_len)\n","    self.decoder = [Decoder(max_len, embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n","\n","    self.dropout = layers.Dropout(rate)\n","    self.final_layer = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, training=False, debug=False):\n","    inputs_encoder, inputs_decoder  = inputs\n","\n","    encoder_output = self.encoder(inputs_encoder, debug) \n","\n","    inputs_decoder = self.token_pos_dec(inputs_decoder, debug)\n","\n","    if debug:\n","      print(f'---------------- DEBUG TRANSFORMER BLOCK ----------------')\n","      print(f'inputs_encoder       : {inputs_encoder[\"input_word_ids\"].shape}')\n","      print(f'inputs_decoder       : {inputs_decoder.shape}')      \n","\n","    transformer_output = inputs_decoder\n","      \n","    for i in range(self.num_layers):\n","      transformer_output = self.decoder[i](inputs=transformer_output, \n","                                           bert_outputs=encoder_output, \n","                                           training=training,\n","                                           debug=debug)\n","\n","    transformer_output = self.dropout(transformer_output)\n","    logits = self.final_layer(transformer_output)\n","\n","    if debug:\n","      print(f'Output Shape       : {logits.shape}')\n","      print(f'Output Transformer : {logits[0, :1, :12]}')    \n","      print(f'---------------------------------------------------------')\n","\n","    return logits"]},{"cell_type":"code","source":["transformer = TransformerBlock(NUM_LAYERS, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.dan.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               DROPUOT)\n","\n","transformer_output = transformer((enc_input, dec_input), \n","                                 training=training,\n","                                 debug=debug)"],"metadata":{"id":"pr--G0ZZVAMi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672872413546,"user_tz":-60,"elapsed":14918,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"c773357a-bc7b-410d-d5af-fdc598b66cf3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_word_ids', 'input_mask', 'input_type_ids']\n","Shape                        : (32, 128)\n","Word Ids                     : [ 101 2304   34    5   43  112   36  620  205   27 1256  452  102    0\n","    0    0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n","Type Ids                     : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[-0.33405063 -1.0129808   0.10644107 -0.6329155   0.00306238  0.2516003\n","  -0.3812657  -0.05663675 -0.02651703 -0.70113814 -0.21248774  0.91945016\n","  -0.15525888 -0.06765453 -0.2951241   0.25734887]]\n","\n","Sequence Conv1 Shape         : (32, 128, 256)\n","Sequence Conv2 Shape         : (32, 128, 64)\n","Sequence Lambda Layer        : (32, 64, 64)\n","\n","Sequence Outputs Values      : [0.3097276  0.         0.90809953 0.         0.         0.88079226\n"," 0.         0.         0.         0.         0.         0.25963035\n"," 0.         0.         0.         0.84513384]\n","*********************************************************\n","********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 64\n","Sequence Shape                            : [32 64]\n","Shape TokenAndPositionEmbedding           : (32, 64, 64)\n","*********************************************************\n","---------------- DEBUG TRANSFORMER BLOCK ----------------\n","inputs_encoder       : (32, 128)\n","inputs_decoder       : (32, 64, 64)\n","********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 64, 64)\n","Shape Output Layer Decode-Bert      : (32, 64, 64)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 64, 64)\n","Shape Outputs Decoder             : (32, 64, 64)\n","*********************************************************\n","Output Shape       : (32, 64, 6312)\n","Output Transformer : [[-0.5057161  -0.3176019   0.0241624   0.04089455  0.15703702 -0.03964978\n","   0.03117747  0.22435635  0.09987283 -0.06287577  0.18590194  0.06904369]]\n","---------------------------------------------------------\n"]}]},{"cell_type":"code","source":["transformer.summary()"],"metadata":{"id":"_kwqvJSu8liP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672872413547,"user_tz":-60,"elapsed":25,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"481e0537-d3d9-4ff7-9ebc-b1c03432b4a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer_block\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," token_and_position_embeddin  multiple                 408064    \n"," g_1 (TokenAndPositionEmbedd                                     \n"," ing)                                                            \n","                                                                 \n"," encoder_bert_1 (EncoderBert  multiple                 109695553 \n"," )                                                               \n","                                                                 \n"," DEC (Decoder)               multiple                  402912    \n","                                                                 \n"," dropout_16 (Dropout)        multiple                  0         \n","                                                                 \n"," dense_10 (Dense)            multiple                  410280    \n","                                                                 \n","=================================================================\n","Total params: 110,916,809\n","Trainable params: 1,434,568\n","Non-trainable params: 109,482,241\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## Addestramento modello con ottimizzatore ADAM"],"metadata":{"id":"IFmcHTSDTvYk"}},{"cell_type":"markdown","source":["### Compilazione"],"metadata":{"id":"tiuqPlHo0Z0n"}},{"cell_type":"code","source":["transformer.compile(\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_ADAM, \n","                                       beta_1=BETA_1, \n","                                       beta_2=BETA_2),\n","    metrics=[keras.metrics.SparseCategoricalAccuracy()])"],"metadata":{"id":"bOyqCyjIr-L2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 save_best_only=True)\n","\n","# Create a callback Tensorboard\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n","\n","# Create a callback save the log history\n","json_logging_callback = tf.keras.callbacks.LambdaCallback(\n","    on_epoch_end=lambda epoch, logs: json_log.write(\n","        json.dumps({'epoch': epoch, \n","                    'loss': logs['loss'],\n","                    'sparse_categorical_accuracy': logs['sparse_categorical_accuracy'],\n","                    'val_loss': logs['val_loss'],\n","                    'val_sparse_categorical_accuracy': logs['val_sparse_categorical_accuracy']}) + '\\n'),\n","    on_train_end=lambda logs: json_log.close()\n",")"],"metadata":{"id":"3hurmpSjJ_dT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Addestramento 1"],"metadata":{"id":"Day7C7Qh0b4G"}},{"cell_type":"code","source":["start = datetime.datetime.now()\n","initial_epoch = 0\n","epochs = EPOCHS_ADAM\n","\n","for val_dataset in validation_dataset:\n","  json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","  transformer.fit(train_dataset,\n","                  initial_epoch=initial_epoch,\n","                  epochs=epochs,\n","                  shuffle=True,\n","                  validation_data=val_dataset,\n","                  callbacks=[tensorboard_callback,\n","                             json_logging_callback, \n","                             cp_callback])\n","  \n","  initial_epoch = epochs\n","  epochs = epochs + EPOCHS_ADAM\n","\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"etOGtBcer9yi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"940f919e-660c-437d-f086-0b440bd2e70f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","500/500 [==============================] - 544s 1s/step - loss: 2.8789 - sparse_categorical_accuracy: 0.7874 - val_loss: 1.2110 - val_sparse_categorical_accuracy: 0.8195\n","Epoch 2/5\n","500/500 [==============================] - 538s 1s/step - loss: 1.1814 - sparse_categorical_accuracy: 0.8214 - val_loss: 1.0735 - val_sparse_categorical_accuracy: 0.8289\n","Epoch 3/5\n","500/500 [==============================] - 533s 1s/step - loss: 1.0747 - sparse_categorical_accuracy: 0.8288 - val_loss: 1.0081 - val_sparse_categorical_accuracy: 0.8340\n","Epoch 4/5\n","500/500 [==============================] - 524s 1s/step - loss: 1.0206 - sparse_categorical_accuracy: 0.8323 - val_loss: 0.9709 - val_sparse_categorical_accuracy: 0.8357\n","Epoch 5/5\n","500/500 [==============================] - 523s 1s/step - loss: 0.9875 - sparse_categorical_accuracy: 0.8341 - val_loss: 0.9487 - val_sparse_categorical_accuracy: 0.8367\n","Epoch 6/10\n","500/500 [==============================] - 530s 1s/step - loss: 0.9656 - sparse_categorical_accuracy: 0.8353 - val_loss: 0.9369 - val_sparse_categorical_accuracy: 0.8369\n","Epoch 7/10\n","500/500 [==============================] - 532s 1s/step - loss: 0.9493 - sparse_categorical_accuracy: 0.8363 - val_loss: 0.9267 - val_sparse_categorical_accuracy: 0.8373\n","Epoch 8/10\n","500/500 [==============================] - 531s 1s/step - loss: 0.9358 - sparse_categorical_accuracy: 0.8367 - val_loss: 0.9170 - val_sparse_categorical_accuracy: 0.8379\n","Epoch 9/10\n","500/500 [==============================] - 530s 1s/step - loss: 0.9260 - sparse_categorical_accuracy: 0.8373 - val_loss: 0.9104 - val_sparse_categorical_accuracy: 0.8380\n","Epoch 10/10\n","500/500 [==============================] - 521s 1s/step - loss: 0.9168 - sparse_categorical_accuracy: 0.8378 - val_loss: 0.9041 - val_sparse_categorical_accuracy: 0.8384\n","Epoch 11/15\n","500/500 [==============================] - 521s 1s/step - loss: 0.9093 - sparse_categorical_accuracy: 0.8385 - val_loss: 0.8992 - val_sparse_categorical_accuracy: 0.8398\n","Epoch 12/15\n","500/500 [==============================] - 532s 1s/step - loss: 0.9021 - sparse_categorical_accuracy: 0.8391 - val_loss: 0.8981 - val_sparse_categorical_accuracy: 0.8400\n","Epoch 13/15\n","500/500 [==============================] - 530s 1s/step - loss: 0.8962 - sparse_categorical_accuracy: 0.8395 - val_loss: 0.8924 - val_sparse_categorical_accuracy: 0.8405\n","Epoch 14/15\n","500/500 [==============================] - 525s 1s/step - loss: 0.8906 - sparse_categorical_accuracy: 0.8401 - val_loss: 0.8894 - val_sparse_categorical_accuracy: 0.8409\n","Epoch 15/15\n","500/500 [==============================] - 530s 1s/step - loss: 0.8862 - sparse_categorical_accuracy: 0.8402 - val_loss: 0.8890 - val_sparse_categorical_accuracy: 0.8408\n","Epoch 16/20\n","500/500 [==============================] - 524s 1s/step - loss: 0.8817 - sparse_categorical_accuracy: 0.8407 - val_loss: 0.8789 - val_sparse_categorical_accuracy: 0.8424\n","Epoch 17/20\n","500/500 [==============================] - 522s 1s/step - loss: 0.8776 - sparse_categorical_accuracy: 0.8410 - val_loss: 0.8792 - val_sparse_categorical_accuracy: 0.8423\n","Epoch 18/20\n","500/500 [==============================] - 522s 1s/step - loss: 0.8744 - sparse_categorical_accuracy: 0.8412 - val_loss: 0.8753 - val_sparse_categorical_accuracy: 0.8430\n","Epoch 19/20\n","500/500 [==============================] - 526s 1s/step - loss: 0.8693 - sparse_categorical_accuracy: 0.8418 - val_loss: 0.8788 - val_sparse_categorical_accuracy: 0.8421\n","Epoch 20/20\n","500/500 [==============================] - 529s 1s/step - loss: 0.8669 - sparse_categorical_accuracy: 0.8420 - val_loss: 0.8742 - val_sparse_categorical_accuracy: 0.8430\n","Epoch 21/25\n","500/500 [==============================] - 518s 1s/step - loss: 0.8635 - sparse_categorical_accuracy: 0.8422 - val_loss: 0.8813 - val_sparse_categorical_accuracy: 0.8417\n","Epoch 22/25\n","500/500 [==============================] - 525s 1s/step - loss: 0.8608 - sparse_categorical_accuracy: 0.8425 - val_loss: 0.8807 - val_sparse_categorical_accuracy: 0.8418\n","Epoch 23/25\n","500/500 [==============================] - 526s 1s/step - loss: 0.8580 - sparse_categorical_accuracy: 0.8427 - val_loss: 0.8813 - val_sparse_categorical_accuracy: 0.8419\n","Epoch 24/25\n","500/500 [==============================] - 517s 1s/step - loss: 0.8549 - sparse_categorical_accuracy: 0.8431 - val_loss: 0.8807 - val_sparse_categorical_accuracy: 0.8417\n","Epoch 25/25\n","307/500 [=================>............] - ETA: 3:05 - loss: 0.8524 - sparse_categorical_accuracy: 0.8434"]}]},{"cell_type":"markdown","source":["### Addestramento 2"],"metadata":{"id":"qDYaeyzJ4AZP"}},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"dQjPtbe34D-Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672838236948,"user_tz":-60,"elapsed":19705,"user":{"displayName":"Daniele Badiali","userId":"15682358814001311695"}},"outputId":"3304e575-00e4-452e-8e83-d08168460377"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f7d120e3190>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","initial_epoch = 25\n","epochs = initial_epoch + EPOCHS_ADAM\n","\n","for val_dataset in validation_dataset:\n","  json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","  transformer.fit(train_dataset,\n","                  initial_epoch=initial_epoch,\n","                  epochs=epochs,\n","                  shuffle=True,\n","                  validation_data=val_dataset,\n","                  callbacks=[tensorboard_callback,\n","                             json_logging_callback, \n","                             cp_callback])\n","\n","  initial_epoch = epochs\n","  epochs = epochs + EPOCHS_ADAM\n","\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"k67wpRqA4HGC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Addestramento 3"],"metadata":{"id":"b4ibAQRvrJDt"}},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zl0eD38DrODN","executionInfo":{"status":"ok","timestamp":1672852953043,"user_tz":-60,"elapsed":13410,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"6c96f461-ab41-4dd3-e104-d27467b040ab"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f2328f9f9a0>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","initial_epoch = 50\n","epochs = initial_epoch + EPOCHS_ADAM\n","\n","for val_dataset in validation_dataset:\n","  json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","  transformer.fit(train_dataset,\n","                  initial_epoch=initial_epoch,\n","                  epochs=epochs,\n","                  shuffle=True,\n","                  validation_data=val_dataset,\n","                  callbacks=[tensorboard_callback,\n","                             json_logging_callback, \n","                             cp_callback])\n","\n","  initial_epoch = epochs\n","  epochs = epochs + EPOCHS_ADAM\n","\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"AnPHFdCXrN3Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Addestramento 4"],"metadata":{"id":"WEXGcXMlB8mx"}},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"WWenzzXbCA58","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671632501334,"user_tz":-60,"elapsed":16358,"user":{"displayName":"Dan Bad","userId":"09439284819205921448"}},"outputId":"c3081fc8-bd78-41a0-9999-ce53ad28982a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f466097ce50>"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","initial_epoch = 75\n","epochs = initial_epoch + EPOCHS_ADAM\n","\n","for val_dataset in validation_dataset:\n","  json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","  transformer.fit(train_dataset,\n","                  initial_epoch=initial_epoch,\n","                  epochs=epochs,\n","                  shuffle=True,\n","                  validation_data=val_dataset,\n","                  callbacks=[tensorboard_callback,\n","                             json_logging_callback, \n","                             cp_callback])\n","\n","  initial_epoch = epochs\n","  epochs = epochs + EPOCHS_ADAM\n","\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"-c_uBg4nCD1X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Valutazione dell'addestramento\n","Avendo in output il log ed i risultati dell'addestramento, possiamo visualizzare\n","queste informazioni relativamente alle metriche di interesse."],"metadata":{"id":"L0w4wF79UhAp"}},{"cell_type":"code","source":["# Recupero il log di addestramento\n","df_history = pd.read_json(log_history, lines=True)\n","\n","# visualizzazione andamento addestramento\n","# su un grafico composto da due sub-plot\n","# uno per il loss, l'altro per l'accuracy\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n","\n","# Errore durante l'addestramento\n","ax1.plot(df_history['loss'], label='Loss')\n","ax1.plot(df_history['val_loss'], label='Validation Loss')\n","ax1.set_title('Training Loss')\n","ax1.legend()\n","\n","# Accuratezza durante l'addestramento\n","ax2.plot(df_history['sparse_categorical_accuracy'], label='Accuracy')\n","ax2.plot(df_history['val_sparse_categorical_accuracy'], label='Validation Accuracy')\n","ax2.set_title('Training Accuracy')\n","ax2.legend()\n","\n","plt.show()"],"metadata":{"id":"RpXR2p5VAdoG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672852138371,"user_tz":-60,"elapsed":11,"user":{"displayName":"Daniele Badiali","userId":"15682358814001311695"}},"outputId":"8d4e1d11-0325-41d0-c48b-77d5baf7f5f5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x360 with 2 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAA2oAAAE/CAYAAAA39zBmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXycZbn/8c81S2ayJ03SNd1XCi1LSwsWaCsCQpEdBNnxiOARF+D8jnoUFUQ4R845iCKIAgIHrWwWEBARgbLbxS6UtStNk25psyeTzMz9++OZpGm6JW2SyUy/79frec3kmWfmuSeUTL657ue6zTmHiIiIiIiI9B2+ZA9AREREREREdqagJiIiIiIi0scoqImIiIiIiPQxCmoiIiIiIiJ9jIKaiIiIiIhIH6OgJiIiIiIi0scoqInshZm9YGaXd/exIiIifYU+60T6JtM6apJuzKyu3ZdZQASIJb7+qnPu0d4f1f4zs1nA/znnSpM9FhER6RvS7bOulZmNBFYBv3bOXZvs8YgkkypqknacczmtG/Ap8IV2+9o+uMwskLxRioiI7L80/qy7DNgOfNHMQr15YjPz9+b5RPZFQU0OGmY2y8zKzOzfzWwj8KCZFZrZn81si5ltT9wvbfecV83sXxL3rzCzN8zsjsSxa8zs1P08dqSZzTezWjP7m5ndbWb/tx/v6ZDEeavMbIWZndHusdPM7P3EOTaY2Y2J/cWJ91llZtvM7HUz088CEZE0kMqfdWZmeEHt+0AL8IUOj59pZkvMrMbMVpnZ5xP7+5nZg2ZWnhjHvPbj6/AazszGJO7/zszuMbPnzawemG1mc8zsn4lzrDezH3V4/nFm9lbiM3R94hxHm9mm9kHPzM4xs6Wd+o8msgf65UwONgOBfsBw4Gq8/wceTHw9DGgEfrmX508HPgKKgf8C7k98sHT12N8D/wCKgB8Bl3b1jZhZEHgW+CvQH7gOeNTMxicOuR9v+ksucBjw98T+G4AyoAQYAHwP0BxoEZH0kaqfdccBpcBc4DGg7Vo4M5sGPAz8G1AAnACsTTz8CN70z0PxPg//dx/nae9LwK1ALvAGUI8XFguAOcC1ZnZWYgzDgReAX+B9hh4BLHHOLQAqgZPbve6lifGK7DcFNTnYxIEfOucizrlG51ylc+5J51yDc64W74f1zL08f51z7jfOuRjwEDAIL+x0+lgzGwYcDdzknGt2zr0BPLMf7+UYIAe4PfE6fwf+DFyUeLwFmGhmec657c65xe32DwKGO+danHOvO12sKiKSTlL1s+5y4AXn3Ha8kPd5M+ufeOzLwAPOuZecc3Hn3Abn3IdmNgg4Fbgm8VnX4px7bV/foHaeds69mXjNJufcq8655YmvlwF/YMf36kvA35xzf0icp9I5tyTx2EPAJeBV+IBTEu9BZL8pqMnBZotzrqn1CzPLMrNfm9k6M6sB5gMFtud56htb7zjnGhJ3c7p47GBgW7t9AOu7+D5IvM5651y83b51wJDE/XOB04B1ZvaamR2b2P8zYCXwVzNbbWbf2Y9zi4hI35Vyn3VmlgmcDzyaeK238a69+1LikKF4TUY6Gpo4z/Y9vfY+7DQmM5tuZq8kpolWA9fgVQv3NgaA/wO+YGbZwAXA6865iv0ckwigoCYHn46VoxuA8cB051we3lQKgD1N8egOFUA/M8tqt2/ofrxOOTC0w/Vlw4ANAM65Bc65M/GmgczDm0aCc67WOXeDc24UcAZwvZmduB/nFxGRvikVP+vOBvKAX5nZxsT1dUPYMf1xPTB6N89bnzhPwW4eq8ebEgmAmQ3czTEdv1e/x6v8DXXO5QP3suP7tKcx4JzbALwNnIM37fGR3R0n0hUKanKwy8Wbq1+VmKrww54+oXNuHbAQ+JGZZSQqXV/Yx9Mws3D7DW/efwPw/8wsaF4b/y8AcxOve7GZ5TvnWoAavKkwmNnpZjYmcQ1BNV475/huTyoiIukgFT7rLgceACbhXft1BDADONzMJuFdd32lmZ1oZj4zG2JmExJVqxfwAl5h4vOwNYguBQ41syMSn5s/6sTQc/EqdE2J6+K+1O6xR4HPmdkFZhYwsyIzO6Ld4w8D/y/xHp7qxLlE9kpBTQ52dwKZwFbgHeAvvXTei4Fj8S4+/gnwR7w1cPZkCN6HbPttKN6H3ql44/8VcJlz7sPEcy4F1iamuVyTOCfAWOBvQB3eX/9+5Zx7pdvemYiI9DV9+rPOzIYAJwJ3Ouc2ttsWJcZ6uXPuH8CVeI1CqoHX8JqjgPd51wJ8CGwGvgXgnPsYuBnvM+8TvGYh+/I14GYzqwVuIjEbJfF6n+JdUnADsA1YAhze7rl/SozpTx2mfIrsFy14LdIHmNkfgQ+dcz3+V04REZFkOBg+68xsFV7H5b8leyyS+lRRE0mCxJoroxPTNz4PnIl3HZmIiEhaONg+68zsXLxr3v6+r2NFOiPVVqsXSRcD8eavF+GtaXatc+6fyR2SiIhItzpoPuvM7FVgInBph27MIvtNUx9FRERERET6GE19FBERERER6WMU1ERERERERPqYpF2jVlxc7EaMGJGs04uISC9atGjRVudcSbLHkSr0GSkicnDY2+dj0oLaiBEjWLhwYbJOLyIivcjM1iV7DKlEn5EiIgeHvX0+auqjiIiIiIhIH6OgJiIiIiIi0scoqImIiIiIiPQxWvBaRPqklpYWysrKaGpqSvZQpAvC4TClpaUEg8FkD0VERCSlKaiJSJ9UVlZGbm4uI0aMwMySPRzpBOcclZWVlJWVMXLkyGQPR0REJKVp6qOI9ElNTU0UFRUppKUQM6OoqEhVUBERkW6goCYifZZCWurRfzMREZHuoaAmIrIHOTk5yR6CiIiIHKQU1ERERERERPqYlG0msrG6ib9/uJnPTexP/9xwsocjIgeJJUuWcM0119DQ0MDo0aN54IEHKCws5K677uLee+8lEAgwceJE5s6dy2uvvcY3v/lNwJsSOH/+fHJzc5P8DkRERGRfmqNx1lXWU93YQnM0TiQWpyUapzkWpzkapyUWp7QwixljintsDCkb1FZvreN7f1rOqJJjFNREpNdcdtll/OIXv2DmzJncdNNN/PjHP+bOO+/k9ttvZ82aNYRCIaqqqgC44447uPvuu5kxYwZ1dXWEw/pZJSIi0pfUR6Ks2lLHys3e9snmOlZtrmPdtgZicbfX586ZPEhBbXdCAT8ATS2xJI9ERHraj59dwfvlNd36mhMH5/HDLxzapedUV1dTVVXFzJkzAbj88ss5//zzAZg8eTIXX3wxZ511FmeddRYAM2bM4Prrr+fiiy/mnHPOobS0tFvfg4iIiHicc7TEHNF43LuNxYnGHS0x7+uN1U2s39bAp+229dsaqKxvbnuNgM8YUZzNuAG5zJk8iDH9c+iXnUGG30cw4CPD7yMjcRsM+MjJ6NkolcJBzbu8LhKNJ3kkIiLw3HPPMX/+fJ599lluvfVWli9fzne+8x3mzJnD888/z4wZM3jxxReZMGFCsocqIiKSUpqjcSrrI2ypjVBe1URFdSMV1U2UV3m3G6ub2FTTRHQfFTAAv88YUpDJ0H6ZnHzoAEoLsxhdks2Y/jkML8om6O87LTxSNqiFgwpqIgeLrla+ekp+fj6FhYW8/vrrHH/88TzyyCPMnDmTeDzO+vXrmT17Nscddxxz586lrq6OyspKJk2axKRJk1iwYAEffvihgpqIiEgHkWiMTzbV8X5FDR9vrGVTbYQttU1srWtmS22E6saWXZ6TEfAxOD/MoPxMpo/qx6D8MFkZAQI+I+D3JW6NoM9HwG8MyAszrF8Wg/LDBPpQGNublA1qrVMfI5r6KCI9pKGhYafpitdffz0PPfRQWzORUaNG8eCDDxKLxbjkkkuorq7GOcc3vvENCgoK+MEPfsArr7yCz+fj0EMP5dRTT03iuxEREUmeWNyxvaGZyrpmNtY08dHGGt4vr+GDilpWbalrq4aFgz4G5oUpzgkxtn8Ox44qoiQ3RHFOiOKcDAYXZDIoP0y/7Iy0X7szdYNaoqLWpIqaiPSQeHz3P1/eeeedXfa98cYbu+z7xS9+0e1jEhER6Usam2NsqvGmHm6saWJzTcS7rY2wtTZCZX2EyrpmtjU04zrMTByUH+aQQXmcNHEAhwzK45BBuQwvysbvS+8A1lmpG9RUURMRERER2W+RaIwV5TWs2lxHXSRKQ3OMukiU+kiU+kiM+kiUhpYYkZZYW1v6SLT1NkZDc4zapugur5sZ9DMgz6uCjSzO5ugR/ShKVMSKsr3bcQNyKczOSMK7Th0pG9R0jZqIiIiISOc459hQ1cg/P63in59WsfjT7bxfXkNzbOffpYN+IzsUIDsjQHbIT2ZGgFDAR04oQCh7R9fDjICPzKCf/nlhBuSFGZgXZkBeiAH5YXJDgbSfltgbUjaoZSQuAlRFTURERETEE4s7yqsaWbO1njVb61m9pY7VW+v5cGMtW2ojgFfwmDykgCtnjODIYQUcMiiPvHCQrJC/bdaaJF/KBjUzIxTwqaImIiIiImmvNYBVVDexrb6ZbfXNbG9obru/rb6ZiupG1lY20Nzu9+OcUICRxdkcP6aYI4cVcOSwQsYPzO1Tbehl91I2qAGEg34FNRERERFJGdFYnHXbGtpazhu0TRP07sP2hhbWVdazdmsDayvrWVtZz/ptDbTEdl0nLDvDT2F2Bv2yMxjWL5tZ4/szsjibUcXZjCzJpiQnpGmIKWqfQc3MwsB8IJQ4/gnn3A87HBMCHgamAJXAF51za7t9tB2EAj6aNPVRRERERPqYeNy7JuzjTbV8tKmWjzfW8vGmOlZuqdup4rU3WRl+hhdlM35ALidPHMiIoiwGF2TSLzuDopwMCrMyCAc1VTFddaaiFgE+65yrM7Mg8IaZveCca9+f+svAdufcGDO7EPhP4Is9MN6dhIKa+igiPWP27Nl85zvf4ZRTTmnbd+edd/LRRx9xzz337PY5s2bN4o477mDq1Kmcdtpp/P73v6egoGCnY370ox+Rk5PDjTfeuMdzz5s3j3HjxjFx4kQAbrrpJk444QQ+97nPHdB7evXVV7njjjv485//fECvIyJysIpEY3y8sY73yqt5b0M171fUsL2+mZaYIxKN05LojNgSi7etC9ZqcH6YcQNzOW5sMeMG5FKUk+h46FpvXFv7+tbpiiW5qoYdzPYZ1JxzDqhLfBlMbB3rrmcCP0rcfwL4pZlZ4rk9JhzwE4mqoiYi3e+iiy5i7ty5OwW1uXPn8l//9V+dev7zzz+/3+eeN28ep59+eltQu/nmm/f7tUREZO+21kX4eGMtNU1RWmLxtq05Gqc55ohEY6zeUs+K8ho+2VTbFsBywwEmDspjcmkBGQEfQb+PUMBH0G9tX/fPDTN+YA5jB+SSFw4m+Z1KqunUNWpm5gcWAWOAu51z73Y4ZAiwHsA5FzWzaqAI2NqNY91FKOijqUUVNRHpfueddx7f//73aW5uJiMjg7Vr11JeXs7xxx/Ptddey4IFC2hsbOS8887jxz/+8S7PHzFiBAsXLqS4uJhbb72Vhx56iP79+zN06FCmTJkCwG9+8xvuu+8+mpubGTNmDI888ghLlizhmWee4bXXXuMnP/kJTz75JLfccgunn3465513Hi+//DI33ngj0WiUo48+mnvuuYdQKMSIESO4/PLLefbZZ2lpaeHxxx9nwoQJnXqvf/jDH/jpT3+Kc445c+bwn//5n8RiMb785S+zcOFCzIyrrrqKb3/729x1113ce++9BAIBJk6cyNy5c7v1+y4i0lOao3FWb63jg4oaPqyo5f2Kmp06Ie5NcU4Ghw7OZ/b4Eg4bks9hg/MZ2i9T1S7pUZ0Kas65GHCEmRUAfzKzw5xz73X1ZGZ2NXA1wLBhw7r69F2EVFETkR7Sr18/pk2bxgsvvMCZZ57J3LlzueCCCzAzbr31Vvr160csFuPEE09k2bJlTJ48ebevs2jRIubOncuSJUuIRqMcddRRbUHtnHPO4Stf+QoA3//+97n//vu57rrrOOOMM9qCWXtNTU1cccUVvPzyy4wbN47LLruMe+65h29961sAFBcXs3jxYn71q19xxx138Nvf/naf77O8vJx///d/Z9GiRRQWFnLyySczb948hg4dyoYNG3jvPe9HfVVVFQC33347a9asIRQKte0TEektsbijsi7CxpomKqqb2NR6W524rW0i0hKnORYnGovTEnNt99vPRMzw+xg7IIcTxpZwyKBcJgzMozA72LY+WNDvba1rhoWDPoUy6XVd6vronKsys1eAzwPtg9oGYChQZmYBIB+vqUjH598H3AcwderUA54WGQr4iKiiJpL+XvgObFzeva85cBKcevteD2md/tga1O6//34AHnvsMe677z6i0SgVFRW8//77ewxqr7/+OmeffTZZWVkAnHHGGW2Pvffee3z/+9+nqqqKurq6naZZ7s5HH33EyJEjGTduHACXX345d999d1tQO+eccwCYMmUKTz31VCe+CbBgwQJmzZpFSUkJABdffDHz58/nBz/4AatXr+a6665jzpw5nHzyyQBMnjyZiy++mLPOOouzzjqrU+cQEeks5xyrt9azrKyK8ioviG2qaWJjTYTNNU1sro0Q63DtV8Bn3oLL+WEmDMwlMxggI2AEfInAFTAyEsFreFEWhwzKY2RxttrTS5/Xma6PJUBLIqRlAifhNQtp7xngcuBt4Dzg7z19fRp47flrm6I9fRoROUideeaZfPvb32bx4sU0NDQwZcoU1qxZwx133MGCBQsoLCzkiiuuoKmpab9e/4orrmDevHkcfvjh/O53v+PVV189oPGGQiEA/H4/0eiB/WwsLCxk6dKlvPjii9x777089thjPPDAAzz33HPMnz+fZ599lltvvZXly5cTCKT0Si8ikkQtsTgrymtYuHYbC9ZuY+Ha7VTWN7c9np8ZZEBeiAF5Ycb2L267PzAvzKD8TAbkhyjODuHzqdol6aczn66DgIcS16n5gMecc382s5uBhc65Z4D7gUfMbCWwDbiwx0bcjtrzixwk9lH56ik5OTnMnj2bq666iosuugiAmpoasrOzyc/PZ9OmTbzwwgvMmjVrj69xwgkncMUVV/Dd736XaDTKs88+y1e/+lUAamtrGTRoEC0tLTz66KMMGTIEgNzcXGpra3d5rfHjx7N27VpWrlzZdk3bzJkzD+g9Tps2jW984xts3bqVwsJC/vCHP3DdddexdetWMjIyOPfccxk/fjyXXHIJ8Xic9evXM3v2bI477jjmzp1LXV3dLp0tReTg0dgcY/XWup0WXd5e30xlYjHmmsYoDodhtM4cNDMs8dxlG6ra+g0ML8pi9oT+HD2ikKOGFVJamEVmhlrPy8GrM10flwFH7mb/Te3uNwHnd+/Q9i0UUHt+EelZF110EWeffXZb04zDDz+cI488kgkTJjB06FBmzJix1+cfddRRfPGLX+Twww+nf//+HH300W2P3XLLLUyfPp2SkhKmT5/eFs4uvPBCvvKVr3DXXXfxxBNPtB0fDod58MEHOf/889uaiVxzzTVdej8vv/wypaWlbV8//vjj3H777cyePbutmciZZ57J0qVLufLKK4nHvZ+xt912G7FYjEsuuYTq6mqcc3zjG99QSBM5iDRH43y4sYZlZdUsK6tiWVk1n2yu22UqohkUZnkLMOeFA5gZzjkc4FyidbhzBP0+Lpo2jKNH9GPq8EL654WT8bZE+izrhRmKuzV16lS3cOHCA3qN7zy5jFc+2sy73zuwtYVEpO/54IMPOOSQQ5I9DNkPu/tvZ2aLnHNTkzSklNMdn5Ei+ysed5RXN/LJ5jpWbqrjk821fLixlg8rammOeX+8KcwKMqm0gMNL85kwMI+S3BD9sr1wlp8ZxK+piD0j2gwNlZBZCMFuCrbOQUsDNDd4ty2NO99iUDIe8kuhLzRUcQ5ize3GmBhntBlKxkEot2uvtfUTCIQgfyj4ev+6xb19Pqb0hQXe1EdV1ERERES6oi4SpaKqkYrqJiqqvdtPtzWwcnMdKzfX0dC849KS4pwQ4wbkcOVxI5g8pIDJpfmUFqo1fVI8dhl8/IJ3P5AJWf0gsx9kFiTuF0K4AML53r729zGoXg9Vn3bY1kPzrtPtdxHKhwETof9EGHCotxWN9QKjLwj+4K5BzjlorodIDTTVQFN14n51YquCxqqd70dqvNAVa4Z4C8Rat2bvNtoIbg+///uCMOwYGHsSjPmcN9aOY2qsgtWvwsq/wcqXobbc2x/M9oJeySFeMC2ZAP0nQN4Q770lQWoHtaDa84uIiIjE4o7NtU2UVzWxtS5CdUMLVY3NbG9ooaqhherGZqoaWthaF6Giumm3zdgG5IUY2z+XC6YOZeyAHMYNyGVMSQ6F2RkHNrh43PtleNsa2L42sa2BaAROvgX6jTqw1z9YfPI3L6QdeYn3PWvYBo3bva1hG2z+IPF1lRdw9iaUBwXDoXAkjDwBcgdCRg4EMxNbduI2ywtIWz6ATe/DphWw/HFYeP/uX9f8XqjxBcF80FwHbh+/q/tDO4fKrCIIhHe8jj8D/AHv1hfcMcaMdmMMZnrnXv+O93166SZvyxsCY06EkTO9f3crX4b173pjCuXD6Nkw+rNe8Nvyobet+jss/X2H71e+F4Sz+nnja92GHAWHndvp/4RdldJBLZy4Rs05p7/qiIiISNpyzrG5NsKqLXWs2lJP2bYGyqubKK9qpKKqkU27aVsPXuv6gqwMCrKCFGQGGVGUzWdGFzMwP8ygfK9z4qD8MAPywmQEOjHtyzmo2wQb34NNiW37WojHAOf9wuuct+G8aWnV671f9luZ35tG17gdfnc6XP4sFI3urm9VeopF4a//4QW0Of8Lgb2EZ5f4vjclKlWNVd59F4eCYd4Uv8wuXl88ot312M5BdZkX2rathljEG19r9Sve4n3t4hDK8UJhOB/CeV7gCed5+1rDWXdN4QSYcBqcdDPUlHsVs09eghXzYPHD3uODDofjvu1V20qP9gLg7jRuhy0fe8GtdqM33bShEhq3ef/+N3/gheP6LQpqexIK+r2KaixOKKCuQCLpRn+EST3Juu5ZJB3E414Y21DVSHlVI+sq61m1pZ5VW+pYvaWeusiOKlhGwJcIWmGOGVXEoAIvdA0uCNM/N+wFs6wMsjP8+/45uvE9ePpO+PQdr0oRykv8Mp2743485v1ivuk97xfWVnmlUDTKq3aYDzDv1hK3/iAccjoUjvCqN4UjvJDmD3rrYz50hhfWrvizwtreLHrQCw1ffHTvIQ28731GlrflDe7+sZhBwVBv66vyBsNRl3lbrAU2LvP+reYO6NzzMwth2HRv25t4z87sS+2glvjLTySqoCaSbsLhMJWVlRQVFSmspQjnHJWVlYTD6twmsieRaIy1Wxv4ZHMtn2yqY/32BjZsb6S8upGN1U20xHb+Y8fg/DCj++dw7lFDGFWSw+iSHEaVZDMwL3zga4d9+g68/j/wyYvetLdxp3iVr0itVy3Yvta731QDOOh/CIw/DQYcBgMP867/yeq3/+cfOMmrpj2ssLZXjVXwyk9hxPEwYU6yR5N6/EEYMqVnXtvXs/kjPYJaSxz0e4FIWiktLaWsrIwtW7YkeyjSBeFweKf2/yIHs4rqRhat286HFbVeMNtcx7rKhrYpimYwKC/MkMJMpgwrZHBBJoMLMhlSkMmQwkxKCzPJyujmX9Wc867Tef2/4dO3vEYUs/8Dpn3FqyLs7Xk98UezgYd5Ye2hL8Dv5sAVzymsdTT/Z95UvFN+2je6LkqvSe2gFvRSrBqKiKSfYDDIyJEjkz0MEZFOicUdH26sYdG67Sxcu51F67azoaoRAL/PGFGUxbj+ucyZNIgx/XMY2z+XUSXZhIO9MCOoqRoqlkHFElj2WGIa2BA45TaYcrk33XFfejIgDDh057B2+Z+heEzPnS+VVK6Cd3/tNRAZNDnZo5FeltpBLVFRU4t+ERER6Q2RaIz12xpYs7WBtVvrWVNZz5ot9SzfUN12DdmAvBBTh/fjy8eNZOqIQiYMzOtco47OiMe9jnXtmzZ0bOJQWw7lS7xgVrHUa/jQqng8nPFLmPzFfV/r1JsGHOoFtPaVtZ4Oa9Fmr9HJ9rVQW+E1mMgd2LPn7KqXbvLW+PrsD5I9EkmCFA9qqqiJiIhI93POsbGmiWVl1Swvq2b5hmpWbamjvKqR9s0VC7K8TopnHjGYo0f0Y8rwwgNfY6xyFTz/b1C+2GtWEI/u2Pa0ftTu5A+DwYfDEV+CQUd6FZmc/vs/rp42YGK7ytppMP0aGH+qt57Vvr6fznmBdP0/Ei3h4+2+b7HE1gI1G2D7Oi+c1WzY+fuZNwQuedK7Fq8vWDMfPvyzF9I62wRD0kpKB7VwcEczEREREZH9Vd3YwqJ121i63gtly8qq2VoXAbypi2P753DksELOOXIII0uyGVGUzcjibAqy9lCVikW9RXU/eNprh370v+y78UYsCm//El69zVtbatK53npSPj/4Au221q8Tiwz7Au3WnAp66zsNOvzAGn0ky4CJXlOReV+Dl3/sbYUjYNypXmgb/pkdiw9XfeqFmTWvw9rXveC1LzkDvdcbPgMKhye6UY7wAtsTV8EDn4cvPbbvbn89LR6DF7/nhe1j/zW5Y5GkSemg1lpRa2pRRU1EREQ6r6qhmX+s2cY7q7fx7ppK3q+owTnwGYzpn8PMcSVMLs1nUmk+Ewflde5aMudgw2JY/hi896S3xlJGLjTXwps/h6lXwrFf3/30uopl8MzXvamKE06H0+6AvEHd/8ZTQf9D4OpXvLWwPv4LfPQCLHwA3r3HW4dr2DFeq/qqdd7xWcUw4jgYeb0XwLKKvPBqvp2DrfnBt5cpqF/+KzxyjteF8vzfecEwWZY86i1fcN4D3mLOclBK7aCmipqIiIh0wta6CAvWbOPdNdt4Z3UlH22qxTnvevejhhXyzRPHMn1kEZNL88kOdfHXo+1rYelcr1HHtlVeNWzcKd51YGNPgsqV8Mb/wtt3e40hjrgYZnwT+o30FiZ+7T/hzbu8gHHBwzDxzB75HqScvMEw9Spva673Kq7/vX4AACAASURBVJQfPe8tKzBwEhzzNRh5gjc1cm8BrLMKR3hh7dHzYO7FcMZdXhOP3haphZdvgaHT4dBzev/80mekdFALt16jpmYiIiLSg8zs88DPAT/wW+fc7R0eHw48AJQA24BLnHNlicf+AhwDvOGcO71XB34QK69q5B+JYPaPNZWs2lIPeJdNTBleyPWTxjF9VBGHD83f/7VY43F451fe9LxYi1fVOe7bcMgXILNgx3EDDoVzfwuzv+cFsiWPwuKH4NCzvaYf21Z5geDkn+y9Rf7BLCPbW0Osp9cRyy72mpo8dik8/a9QtwmOu757ul42bPM6blYs824bKvEWCLedb+s2Qf1muGiu2vEf5FI6qO2oqGnqo4iI9Awz8wN3AycBZcACM3vGOfd+u8PuAB52zj1kZp8FbgMuTTz2MyAL+GovDvugE43F+cfabfx1xSZe/nAT67d5rfFzwwGOHtGP86cOZdrIfhxWECUj3gT+DC92xxrABb2vu1KVqSmHedd6VZ7xc+C0/4L8fawh2G8UfOFOmPnv3rVoCx+EnBK47GkYNWs/37l0u1AOXPRHePpr8PLNULfZW8qgK/8+muvh07e9qbAVS71wVv3pjsfzh0JOa4MQ502bbX/72R9AaQ8t0iwpI7WDWvsFr0VERHrGNGClc241gJnNBc4E2ge1icD1ifuvAPNaH3DOvWxms3pnqAeXxuYY8z/Z0hbOqhpaCAV8HD+2mKtmjGTayH5MGJiH35eoSmxfC3dO9br/7Y4vACNnwpQrvOuTWptWdPTBs/DMdRCNwBd+Dkdd3rXKR94gOOVWOPGmHddQSd8SyICz74Ps/vDO3d41h0OmeuFpyBQYfNTOVdNoBMoWJJqbzIeyhTv+nRWNgdKpcPSXvSYvAydDdlFy3peklBQPamrPLyIiPW4IsL7d12VAx5ZwS4Fz8KZHng3kmlmRc66yd4Z48KiLRHn5g008t6yC+Z9soaklTl44wImHDOCUQwdwwrgSsjL28OvNsse9X55Pu8NrNNG29liz13GxqQpWzPOmvWX3hyMvhqMu8yphAJE6ePG7sPhhGHSEN52xeOz+v5lAaP+fKz3P5/MCdekU+OQl2LAIPn5hx+NFY2HIUd5UxU/fhWij9+9q0BFep8aRJ0Dp0RDOS957kJSW0kGttT2/FrwWEZEkuxH4pZldAcwHNgBd+iuimV0NXA0wbNiw7h5fSmtojvLyB5t5blkFr3y0mUg0zoC8EBdMHcrJEwcyfVQ/gv59TEtzzuvGOHwGTPvKno876RZY+TfvGrI3f+41ARk5EyaeAW//ylur67hvw6zv9a0Fo6VnmMFh53obQGOVt77dhkVQtghWv+YtgzDlCi+YDf/MzpU2kQOQ0kFNFTUREekFG4Ch7b4uTexr45wrx6uoYWY5wLnOuaqunMQ5dx9wH8DUqVPdPg5Pe7G446X3N/Ls0gpe/nATTS1xSnJDXHj0UOZMHszU4YX4fF2YbrhxGWz9GI65du/H+QMw/vPeVlMO/3zUq6A9dwPklXoLMo88/sDenKSuzAIY/VlvE+lhKR3Ugn7DTO35RUSkRy0AxprZSLyAdiHwpfYHmFkxsM05Fwe+i9cBUvbTsrIqvven5by3oYai7AzOm1LKnEmDmTay347rzbpq+ePe9WATz+r8c/IGw8x/g+Ovh4ol3rVG4fz9O7+ISBeldFAzM8IBv4KaiIj0GOdc1My+DryI1yfwAefcCjO7GVjonHsGmAXcZmYOb+rjv7Y+38xeByYAOWZWBnzZOfdib7+PVFDT1MJ/v/gRD7+zjuKcED+/8AjmTBpEYF/TGvclHoflT8KYk7xpal3l83sNJEREelFKBzXwWvQ3tWjqo4iI9Bzn3PPA8x323dTu/hPAE3t4rubJ7YNzjueWV3Dzs++zpS7CZccM54ZTxpMX3kPXxa5a9ybUlsPJt3TP64mI9ILUD2oBn9rzi4iIpKhPKxv4wdPv8drHWzhsSB6/vXwqk0u7uRnD8schmO213BcRSREpH9TCQb+aiYiIiKSYeNzxwJtr+NmLHxH0+/jhFyZy6THDD3yaY0fRCLz/NEyYAxnZ3fvaIiI9KOWDWijgU3t+ERGRFFJR3ciNjy/lzZWVfO6Q/vzkrEkMzA/3zMlW/s1bH23yBT3z+iIiPSQNgpoqaiIiIqnimaXlfP9Py4nGHbefM4kvHj0Us/3s5NgZyx+HrCIYNavnziEi0gNSPqiFgz51fRQREenjqhtbuOnp93h6STlHDivgfy84ghHFPTwVMVILH70AR14C/m5qTCIi0ktSPqiFAn4amqPJHoaIiIjswVurtnLjY0vZVBvh+pPG8bVZo7v/WrTd+eDPEG2CSZr2KCKpJw2Cmo/tDaqoiYiI9EUPvbWWHz27gpFF2Tx17Wc4fGg3d3Tcm+WPQ8EwGDqt984pItJNUj+oaeqjiIhIn/TEojJ++MwKTpo4gJ9feARZGb34a0fdZlj9Ksz4JvTkNXAiIj0k5YNaWM1ERERE+py/vFfB/3tiKcePLeaXXzqSUMDfuwNY8SdwMXV7FJGU1QsTxHtWKKj2/CIiIn3J/I+3cN0f/smRwwr59aVTej+kgTftccBh0P+Q3j+3iEg3SP2gFvATaVFFTUREpC9YtG4bX31kEWP65/LAFUf3zHTHNfNh3r/C4oehqXrXx7etgbIFMOm87j+3iEgvSfmpj7pGTUREpA9wjhUVNVzx4AIG5od5+Kpp5Gd2c0v8zR/ASzfBJ3+FQBiW/B88/28w/jQ4/EIY/VmvDf/yJ7zjD1NQE5HUlfpBLeAnEo3jnOvZBTNFRERkV8318NwNxFf8iWh0GP/un8ips8+myF8PhLrnHDUV8MqtsORRyMiFz/0Ypn8VNq2ApXPhvSdgxVOQXeKFs09ehGGfgYKh3XN+EZEkSIOg5s3ejETjhINJmAMvIiJysKpcBX+8FLf5fV7yHc8ANnOxex57dh48CxSPh2HHwPAZMGom5A7s2utHauHNn8Nbv4R4FKZfCyfcCFn9vMdLp3rbKT+FlS95oW3h/RBrhmO/3u1vV0SkN6V8UGsNZwpqIiIiveijF+Cpr+LM+GnhLfxh2zj++NVjsJIQlC+GT9+GT9+BFfNg8UPec0oOgdGzYdRsGDEDMrJ3fs26zbBxGVQs827XzIeGSjjsXPjsD6DfyN2PJZABE+Z4W+N277xjTurZ9y8i0sP2GdTMbCjwMDAAcMB9zrmfdzhmFvA0sCax6ynn3M3dO9Tda6uotcSgu+fCi4iIyM7iMXj1Npj/Mxg4mcdH38ZvXq7mZ+dN5NDB+d4xwz/jbQDxOGxaDqtegdWvwIL74Z1fgS/oVdsGTobKT7xwVrdxx3kKhsPIE+Az18GQKZ0fX2YhjD+1+96viEiSdKaiFgVucM4tNrNcYJGZveSce7/Dca87507v/iHuXfupjyIiItKDGrbBk/8Cq16GIy5hzfQfcdOvFnLihP6cN6V098/x+WDQ4d523LegpdGrtq36O6x6Ff7xaygeB6NmwaDJXnAbOAkyC3rxjYmI9D37DGrOuQqgInG/1sw+AIYAHYNaUoTapj6qRb+IiEiP2fwB/P4CqN0Ip99J7MjLueHXbxMK+LntnEmdb+gVzPS6M47+rPe1c6BmYCIiu+jSOmpmNgI4Enh3Nw8fa2ZLzewFMzt0D8+/2swWmtnCLVu2dHmwuxNOVNS06LWIiEgPaWmExy6Dlia48i8w9Up++8YaFn9axc1nHkr/vPD+v7ZCmojIbnU6qJlZDvAk8C3nXE2HhxcDw51zhwO/AObt7jWcc/c556Y656aWlJTs75h3ooqaiIhID/v7T2Drx3D2vVA6hU821fLfL33MKYcO4IzDByd7dCIiaalTQc3Mgngh7VHn3FMdH3fO1Tjn6hL3nweCZlbcrSPdgx3NRFRRExER6Xbr3oa374apV8GYE4nG4tzw+FJyQgFuPbsLUx5FRKRL9hnUzPsJfD/wgXPuf/ZwzMDEcZjZtMTrVnbnQPekfXt+ERER6UbN9TDvWigYBifdAsC9r61iWVk1t5x5GMU53bSgtYiI7KIzXR9nAJcCy81sSWLf94BhAM65e4HzgGvNLAo0Ahc651wPjHcXobZr1DT1UUREpFu99EPYvhau+DOEcvigooafv/wJp08exJzJg5I9OhGRtNaZro9vAHud1+Cc+yXwy+4aVFeoPb+IiEgPWP0qLPgNHPM1GHEczdE4Nzy2lPzMIDefeViyRycikvY6U1Hr08JqJiIiItK9mmrg6a9D0Rg48SYA7n9jDe9X1HDfpVPol52R5AGKiKS/lA9qIbXnFxER6V5//Q+o2QBX/RWCmTS1xPjt66uZOa6Ekw8dmOzRiYgcFLq0jlpfpPb8IiIi3ejjv8Lih2HGN2Ho0QA8vqiMyvpmrp01OsmDExE5eKR+UFN7fhERke7RuB2e/Qb0nwizvgtANBbnN/NXc8TQAqaP7JfkAYqIHDxSPqgF/T78PqNJFTUREZED88ptUL8FzroHAl7r/b+s2Min2xq4ZuYorZkmItKLUj6ogVdVU0VNRETkAETqYMnvYdL5MPgIAJxz3PvaKkYVZ3PSRF2bJiLSm9InqKk9v4iIyP5770loroUpV7btemtVJe9tqOErJ4zC71M1TUSkN6VFUAsH/WomIiIiciAWPehdmzZ0Wtuue19bRUluiLOPHJLEgYmIHJzSIqiFAj615xcREdlf5Uug/J9eNS1xHdp7G6p5/ZOtXDVjZNuapSIi0nvSJKipoiYiIrLfFj0IgUyYfEHbrl/PX01OKMCXpg9L4sBERA5eaRHUwkFdoyYiIrJfmmpg2eNw2LmQWQDA+m0NPLesnIunDyM/M5jkAYqIHJzSIqiFAn6aWlRRExER6bLlj0NLPUzd0UTkN6+vxu8zrjpuZBIHJiJycEuPoKaKmoiISNc55017HDAJhkwBoLIuwmML13P2kUMYkBdO8gBFRA5e6RHUAn6toyYiItJVGxbDxuUw9Yq2JiIPvb2OppY4V58wOrljExE5yKVHUAv6aFIzERERka5Z9AAEs2GS10SkoTnKw2+v5aSJAxjTPye5YxMROcilR1AL+FRRExER6YqmanjvKZh0LoTzAHhswXqqGlq4ZqaqaSIiyZYmQc2va9RERES6Ytlj0NLgrZ2W8JcVGzlkUB5ThhcmcWAiIgJpEtS89vya+igiItIpzsHCB2HQ4TDkKAAam2MsXlfF8WOLkzw4ERGBNAlqaiYiIiLSBWULYPOKnappi9ZtpzkW59jRRUkcmIiItEqToOajORYnHnfJHoqIiEjft/BByMiBSee17Xpz1VYCPmPaiH5JHJiIiLRKi6AWDvoBaI6pqiYiIrJXjdthxVMw6XwI5bbtfmvlVo4cVkB2KJDEwYmISKu0CGqhgPc2mlp0nZqIiMheLf0jRJtg6o5pj9WNLSzfUM2xo3V9mohIX5EeQS3ovQ11fhQREdmHNa9B0VivkUjCu6sriTuYoevTRET6jLQIauGAN/VRDUVERET2oXo99Bu50663VlUSDvo4YlhBkgYlIiIdpUVQa62oNalFv4iI9AAz+7yZfWRmK83sO7t5fLiZvWxmy8zsVTMrbffY5Wb2SWK7vHdHvhvVGyBvyE673lq1laNH9COU+MOniIgkX3oENVXURESkh5iZH7gbOBWYCFxkZhM7HHYH8LBzbjJwM3Bb4rn9gB8C04FpwA/NLHmrSTc3QOM2yN8R1DbXNvHxpjpmjNH1aSIifUmaBLXWa9RUURMRkW43DVjpnFvtnGsG5gJndjhmIvD3xP1X2j1+CvCSc26bc2478BLw+V4Y8+7VlHu3eW0FP95eVQnAZ3R9mohIn5IWQa21PX+TKmoiItL9hgDr231dltjX3lLgnMT9s4FcMyvq5HN7T80G77ZdRe2tlZXkhQMcOjg/SYMSEZHdSYugpoqaiIgk2Y3ATDP7JzAT2AB06UPJzK42s4VmtnDLli09McYdQa3dNWpvrtrKsaOL8PusZ84pIiL7JT2Cmtrzi4hIz9kADG33dWliXxvnXLlz7hzn3JHAfyT2VXXmue1e4z7n3FTn3NSSkpLuHP8O1TsHtU8rGyjb3shntH6aiEifkxZBra09vypqIiLS/RYAY81spJllABcCz7Q/wMyKzaz1M/W7wAOJ+y8CJ5tZYaKJyMmJfclRUwZZxRAMA163R4AZY3R9mohIX5MWQa2tPb+uURMRkW7mnIsCX8cLWB8AjznnVpjZzWZ2RuKwWcBHZvYxMAC4NfHcbcAteGFvAXBzYl9yVG/Y6fq0N1dV0j83xOiSnKQNSUREdi+Q7AF0hx3t+VVRExGR7uecex54vsO+m9rdfwJ4Yg/PfYAdFbbkqtkAhSMAcM7x9qqtHDemGDNdnyYi0tekRUUtrGvURERE9q3dYtcfb6pja10zn9H6aSIifVJaBLUMv6Y+ioiI7FWkFiLVbVMf31zpXZ+m9dNERPqmtAhqAb+PgM/UTERERGRP2jo+eotdv7VqK8OLsigtzErioEREZE/2GdTMbKiZvWJm75vZCjP75m6OMTO7y8xWmtkyMzuqZ4a7Z6GAT1MfRURE9qSmzLvNH0I0Fufd1dvUll9EpA/rTDORKHCDc26xmeUCi8zsJefc++2OORUYm9imA/ckbntNOOinSc1EREREdq/dGmrLN1RTG4lq2qOISB+2z4qac67CObc4cb8WrzXxkA6HnQk87DzvAAVmNqjbR7sXqqiJiIjsRU05YJA3mLdWVQK6Pk1EpC/r0jVqZjYCOBJ4t8NDQ4D17b4uY9cw16NCQb+CmoiIyJ7UlEHOAPAHeWvVViYMzKUoJ5TsUYmIyB50OqiZWQ7wJPAt51zN/pzMzK42s4VmtnDLli378xJ7FAr4tI6aiIjIniQWu25qibFw7XZdnyYi0sd1KqiZWRAvpD3qnHtqN4dsAIa2+7o0sW8nzrn7nHNTnXNTS0pK9me8exQK+mlSRU1ERGT3arw11Bav204kGmfGGE17FBHpyzrT9dGA+4EPnHP/s4fDngEuS3R/PAaods5VdOM490kVNRERkT1wLlFRK+WtVZX4fca0kf2SPSoREdmLznR9nAFcCiw3syWJfd8DhgE45+4FngdOA1YCDcCV3T/UvQsH/dQ0tvT2aUVERPq+pipoqYe8IaxcVceIoixyw8Fkj0pERPZin0HNOfcGYPs4xgH/2l2D2h+hgE/t+UVERHantTV//hDqm6MKaSIiKaBLXR/7slDAR7OuURMREdlVzY411OoiUXJCnZlQIyIiyZRGQU3t+UVERHarusy7zRtCvYKaiEhKSJugFg5q6qOIiMhu1WwA80PuQOqaomQrqImI9HlpE9RUURMREdmD6g2QOwh8/sTUR3+yRyQiIvuQPkEt6CMSVUVNRERkFzXeYtfOOeqbY6qoiYikgLQJauGAn5aYIxZ3yR6KiIhI35JY7DoSjROLOwU1EZEUkDZBLRT03oqqaiIiIu04BzXlkO91fATUTEREJAWkT1ALJIJai65TExERadNQCdEmyCulPhHUVFETEen70iaohYPehdFqKCIiItJOa2v+nSpqaiYiItLXpU1Qa62oqUW/iIhIO+0Wu66PeJ+RqqiJiPR9aRTUVFETERHZRXUiqOVr6qOISCpJm6AWVjMRERGRXdWUgT8DsorVTEREJIWkTVBrrag1qZmIiIjIDtUbIG8w+HyqqImIpJD0CWqqqImIiOwqsYYasKOilqGgJiLS16VPUFN7fhERkV1V7whqO5qJqOujiEhflzZBrbU9f5MqaiIiIp54HGq9xa4B6pujhAI+Av60+fgXEUlbafOTWhU1ERGRDuo3Qzy609TH3LCmPYqIpII0Cmpqzy8iIrKTdq35AeqaomokIiKSItImqKk9v4iISAc1Zd5t2zVqUbLVSEREJCWkTVBTe34REZEOOlbUIlGtoSYikiLSKKipoiYiIrKTmg0QyITMQsBrJqKOjyIiqSFtgprPZ2T4fbpGTUREpFV1mdfx0Qzw2vPrGjURkdSQNkENvKpaU4sqaiIiIsBOi12Dpj6KiKSS9ApqQVXURERE2lRvaLs+DRLNRBTURERSQnoFtYBf66iJiIgAxKJQt7GtohaPOxqaNfVRRCRVpFdQC/poUjMRERERqK0AF/euUcNrJAKQo2YiIiIpIb2CmipqIiIinppy77ZtDTXvD5mqqImIpIY0C2o+tecXERGBXRa7rou0VtQU1EREUkFaBbWwmomIiIh42ha7bq2oeUEtO0NBTUQkFaRVUPOmPqqiJiIiQs0GyMiFcD7QLqipoiYikhLSLKipoiYiIgLsWOw6QVMfRURSS1oFtXDQr6AmIiICuyx23db1MaygJiKSCtIqqIUCPpo09VFERCSx2HW7ilpT69RHtecXEUkF6RXU1ExEREQEohGo3wx5pW276hLt+TX1UUQkNaRXUFMzERERkR1rqLWrqNVHovgMMoOqqImIpIK0CmrhoI8mVdRERORgV5NozZ+3czOR7IwAZpakQYmISFfsM6iZ2QNmttnM3tvD47PMrNrMliS2m7p/mJ0TCviJxR3RmMKaiIh0HzP7vJl9ZGYrzew7u3l8mJm9Ymb/NLNlZnZaYn+GmT1oZsvNbKmZzeqVAbdV1HZMfayPRNWaX0QkhXTmJ/bvgF8CD+/lmNedc6d3y4gOQCjg5c5INE7An1bFQhERSRIz8wN3AycBZcACM3vGOfd+u8O+DzzmnLvHzCYCzwMjgK8AOOcmmVl/4AUzO9o517N/Uawu8247dH1UIxERkdSxzzTjnJsPbOuFsRywcGLevTo/iohIN5oGrHTOrXbONQNzgTM7HOOAvMT9fCBR0mIi8HcA59xmoAqY2uMjrtkAmYWQkdW2qy4SUyMREZEU0l1lp2MTUzpeMLNDu+k1u6x9RU1ERKSbDAHWt/u6LLGvvR8Bl5hZGV417brE/qXAGWYWMLORwBRgaM8OF681f97OQ9TURxGR1NIdP7EXA8Odc3WJOfnzgLG7O9DMrgauBhg2bFg3nHpnoaCCmoiIJMVFwO+cc/9tZscCj5jZYcADwCHAQmAd8Baw22kf3foZedSl0Fy/0676SJR+2Vl7eIKIiPQ1B1xRc87VOOfqEvefB4JmVryHY+9zzk11zk0tKSk50FPvIhzwpj5Gopr6KCIi3WYDO1fBShP72vsy8BiAc+5tIAwUO+eizrlvO+eOcM6dCRQAH+/uJN36GTlhDky+YKdddZGopj6KiKSQAw5qZjbQEr1+zWxa4jUrD/R190drRa2pRRU1ERHpNguAsWY20swygAuBZzoc8ylwIoCZHYIX1LaYWZaZZSf2nwREOzQh6TXe1Ec1ExERSRX7/NOamf0BmAUUJ+be/xAIAjjn7gXOA641syjQCFzonHM9NuK9CLVW1NRMREREuolzLmpmXwdeBPzAA865FWZ2M7DQOfcMcAPwGzP7Nl5jkSuccy7R6fFFM4vjVeEuTdLboD4S0zVqIiIpZJ8/sZ1zF+3j8V/ite9PurCuURMRkR6QmNr/fId9N7W7/z4wYzfPWwuM7+nx7UtzNE5zLE5OhoKaiEiqSKvFxloramrPLyIiskN9JAqgipqISApJs6CmipqIiEhHdYmglhNWUBMRSRVpFtRauz4qqImIiLRqC2qqqImIpIy0Cmrhtq6PmvooIiLSSlMfRURST1oFNVXUREREdrWjoqb2/CIiqSK9glpb10dV1ERERFrVR7zPRVXURERSR3oFtdZmIlrwWkREpE3b1Ee15xcRSRlpFdTMjIyAjyZV1ERERNqomYiISOpJq6AGXlVNFTUREZEd1ExERCT1pF1QCwf9aiYiIiLSTl1zlAy/j4xA2n3si4ikrbT7ie1V1DT1UUREpFV9JEq2Oj6KiKSU9AxqqqiJiIi0qY/ENO1RRCTFpGFQ86s9v4iISDt1kagaiYiIpJi0C2rhoI8mNRMRERFp4019VFATEUklaRfUVFETERHZmYKaiEjqSb+gFtQ1aiIiIu15Ux/VTEREJJWkXVALB/w0qeujiIhIm/pIjOwMVdRERFJJ2gU1VdRERER2VheJkhNWUBMRSSXpF9QCPiJqJiIiIgKAc476ZnV9FBFJNWkX1MJBNRMRERFp1dAcwznUTEREJMWkXVALBdSeX0REpFV9JAooqImIpJo0DGpeRc05l+yhiIiIJF1dIqip66OISGpJw6DmI+4gGldQExERqY94lwOo66OISGpJu6AWDnp/MVSLfhERkfYVNQU1EZFUknZBLRT03pJa9IuIiOgaNRGRVJV+QS2goCYiItKqvllBTeT/t3fn8VGVh/7HP885M1lIwpoACkHiT1FcSEUWW63icnupl4qIG9cNa0Hr1aq33l/Vcq3r79frz7bqvRZL1aJeDW4VtdelbqgttrKUuoEVFQxLAYkhZJuZM+f5/XHOTCaQsCZMJvm+X6/zOsucOefJk5k5+eZ5zjMiuajbBTV1fRQREWmhro8iIrmp2wW1dIuahugXERHJ6PqoUR9FRHJJNwxqwYVIX3otIiIC9Rr1UUQkJ3W/oKbBRERERNIaYh698lwcx2S7KCIishu6X1CL6B41ERGRlIaYp4FERERyUDcMampRExERSamPeRpIREQkB3W7oJYa9VFBTUREJGhRU1ATEck93S6opVrU1PVRREQkaFHTiI8iIrmn+wU1DSYiIiKSVh9LqkVNRCQHdb+glhqeXy1qIiIiGkxERCRHdbugVqAWNRERkTQFNRGR3LTToGaMedAYs9EY80E7jxtjzD3GmJXGmPeMMaM7vpi7Ls8Ng5pa1ERERDTqo4hIjtqVFrW5wMQdPP5t4OBwmgnM3vti7TljDPkRRy1qIiLS43lJn5jnU5SnoCYikmt2GtSstW8BNTvYZTLwniatDAAAIABJREFUsA38CehrjNmvowq4JwqirkZ9FBGRHq8hFlwLNeqjiEju6Yh71IYA1Rnra8Jt2zHGzDTGLDbGLN60aVMHnLptalETERGB+rgHoK6PIiI5aJ8OJmKtnWOtHWOtHVNWVtZp58mPKqiJiIg0xIKgpsFERERyT0cEtbVAecb60HBb1hREXGKeuj6KiEjPVh9Ti5qISK7qiKD2HHBhOPrjMcAWa+36DjjuHsuPOjQn1KImIiI9m1rURERy104/uY0xVcAEoNQYswb4CRAFsNbeB7wAnAqsBBqBizursLsqXy1qIiIiGUFNg4mIiOSanQY1a+20nTxugX/psBJ1gPyIQ0wtaiIi0sPVh6M+quujiEju2aeDiewrBVGXZrWoiYhID6eujyIiuatbBjW1qImIiGgwERGRXNZ9g5qG5xcRkQ5ijJlojPnYGLPSGHNdG48PM8a8YYz5izHmPWPMqeH2qDHmIWPM+8aY5caY6/dluetjHhHHkB/plpd7EZFurVt+chdEXZoT6vooIiJ7zxjjAvcC3wYOA6YZYw7bZrdZwBPW2qOAc4FfhtvPAvKttUcCRwOXGmOG74tyQ9D1sSg/gjFmX51SREQ6SLcMampRExGRDjQOWGmt/cxaGwfmAZO32ccCvcPlPsC6jO1FxpgIUAjEgbrOL3KgPuap26OISI7qnkEtquH5RUSkwwwBqjPW14TbMt0EnB9+jc0LwJXh9qeABmA98AVwp7W2plNLmyFoUdPQ/CIiuahbBrWCsEUt+OYAERGRTjcNmGutHUrw3aKPGGMcgta4JLA/UAH80BhzYFsHMMbMNMYsNsYs3rRpU4cUqiGW1IiPIiI5qlsGtfyoi7UQT6r7o4iI7LW1QHnG+tBwW6ZLgCcArLXvAAVAKfDPwEvW2oS1diPwR2BMWyex1s6x1o6x1o4pKyvrkIKr66OISO7qnkEtHN1K96mJiEgHWAQcbIypMMbkEQwW8tw2+3wBnAxgjBlJENQ2hdtPCrcXAccAK/ZRuYOuj3kKaiIiuah7BzV9l5qIiOwla60HXAG8DCwnGN3xQ2PMLcaY08LdfgjMMMb8FagCptug//29QLEx5kOCwPcba+17+6rsqVEfRUQk9+Tup3fdOvjDL+CUmyCvqNVD+dHgxmkN0S8iIh3BWvsCwSAhmdtuzFj+CDi2jefVEwzRnxVB10cNJiIikotyt0WtthrenQN/uGu7h9T1UUREejprLQ1xDSYiIpKrcjeoDRsPR0yFhfcEoS1DfiT476GG6BcRkZ4q5vkkfaugJiKSo3I3qAGccnMwf/WmVpsLosGP1ax71EREpIeqj3kAGvVRRCRH5XZQ61sO3/gBfPAUfPHn9Ga1qImISE/XEAY1taiJiOSm3A5qAMdeBSX7wcvXgx+0oOWHLWpfNSSyWTIREZGsaWlR02AiIiK5KPeDWn4xnPwTWLsE3n8CgBGDSti/TwG3/O5D1m9pynIBRURE9r2GWNCrpDg/muWSiIjInsj9oAYw6hzYf3Rwr1q8geL8CA9ePJaGWJLvzl2c/q+iiIhIT1EfC3qVFKlFTUQkJ3WPoOY4MPGnsHU9/PFuAA4d3Jt7zxvN3zZs5crHluIlNbCIiIj0HPXpFjXdoyYikou6R1CDluH6/3h3erj+E0aUcevkI3jj403c/PxHWGuzXEgREZF9Q4OJiIjktu716X3KzbDif+C1m2Hq/QD88/hhrN7cwK/e+ozhpUVcclxFlgspIiLS+RTURLInkUiwZs0ampubs10U6SIKCgoYOnQo0eiu3zfcvT69U8P1v3UHjJsJ5eMA+NHEQ/mippHb/ucjyvsV8q3DB2e5oCIiIp0rdX92UZ7uURPZ19asWUNJSQnDhw/HGJPt4kiWWWvZvHkza9asoaJi1xuNuk/Xx5TUcP0vXZcert9xDD8/+2uMGtqXq+Yt4701tVkupIiISOdqiHkURB0ibve71It0dc3NzQwYMEAhTQAwxjBgwIDdbmHtfp/emcP1P3warPsLAIV5LvdfOIb+RXlc8tBi/vLFV1kuqIiISOepjyU1kIhIFimkSaY9eT10v6AGUHku/NPPYONHMGcCPP09+Go1ZSX5zL14LNZapvxyId97aDEfravLdmlFREQ6XEPM0/1pIj3c/PnzMcawYsWKbBdF9kD3DGrGwNjvwQ+WwTd/CMufh/8aA7+fxcG9PRb824lc+60R/PnzzZx6z9tc8dhSPt1Un+1Si4iIdJiGmEdRnoKaSE9WVVXFcccdR1VVVaedI5lMdtqxe7ruGdRSCnrDyTfClUvhyLNg4X/B3V+jeOmvuOLYwfzhf5/EFScexOsrNvIPP3+Ta5/8K9U1jdkutYiIyF6rj3nq+ijSg9XX1/OHP/yBBx54gHnz5gFBqLr22ms54ogjGDVqFP/5n/8JwKJFi/jGN75BZWUl48aNY+vWrcydO5crrrgifbxJkyaxYMECAIqLi/nhD39IZWUl77zzDrfccgtjx47liCOOYObMmemvxFq5ciWnnHIKlZWVjB49mk8//ZQLL7yQ+fPnp4973nnn8eyzz+6jWsktPeMTvM8QOP2XcMz34ZWfwMs3wGu30ueQb3PtqLOZfsxx3Pd2NQ//aTXPLlvLKSMHMeWoIUw4ZCB5ke6dZUVEpHtqiHuUFednuxgiPd7Nz3/Y4bfaHLZ/b37yncN3uM+zzz7LxIkTGTFiBAMGDGDJkiW8++67rFq1imXLlhGJRKipqSEej3POOefw+OOPM3bsWOrq6igsLNzhsRsaGhg/fjw/+9nPgvIcdhg33ngjABdccAG/+93v+M53vsN5553Hddddx5QpU2hubsb3fS655BJ+8YtfcPrpp7NlyxYWLlzIQw891DEV0830jKCWMvhIuOC3UP0u/HUefPgMfPhbSgv6Muvw0/n+tNO599Mynv3rel784O/06xVl0qj9mTJ6CEeV99VNoSIikjMaYkmGD+hZl3kRaVFVVcVVV10FwLnnnktVVRWff/45l112GZFI8NnQv39/3n//ffbbbz/Gjh0LQO/evXd6bNd1mTp1anr9jTfe4I477qCxsZGamhoOP/xwJkyYwNq1a5kyZQoQfI8YwAknnMDll1/Opk2bePrpp5k6dWq6PNJaz6yV8nHB9O3/gE/fgPefhPeeZMCSudzYewizRp3MirwjmbepnMcXV/PIn1YzfEAvTj9qCN86bDCHDi7BcRTaRESk61LXR5GuYWctX52hpqaG119/nffffx9jDMlkEmNMOoztikgkgh9+1RXQamj5goICXNdNb7/88stZvHgx5eXl3HTTTTsdhv7CCy/kv//7v5k3bx6/+c1vdvOn6zl6dr8+NwojvgVTfw3/9glMfQD2+xrO8mc57M//xi2fncvy/tfy5v96jPOib/D86wuYdM+bjPs/r/KDqr/wxOJq1tU2ZfunEBER2Y5GfRTpuZ566ikuuOACVq9ezapVq6iurqaiooLKykp+9atf4XkeEAS6Qw45hPXr17No0SIAtm7diud5DB8+nGXLluH7PtXV1bz77rttnisVykpLS6mvr+epp54CoKSkhKFDh6bvR4vFYjQ2BmNBTJ8+nbvuugsIuk1K2/QJnpJXBEeeGUy+Hwztv3ohzuo/csDqPzKj4XfMyAPfRKgxA/n8b/1Z9WF/HrdlxEuGMHDoQVQccAAHl+/P/oPKMPm9wXGz/VOJiEgPlPQtjXF9j5pIT1VVVcWPfvSjVtumTp3K8uXLGTZsGKNGjSIajTJjxgyuuOIKHn/8ca688kqampooLCzk1Vdf5dhjj6WiooLDDjuMkSNHMnr06DbP1bdvX2bMmMERRxzB4MGDW7XaPfLII1x66aXceOONRKNRnnzySQ488EAGDRrEyJEjOf300zu1HnKdSY3Ksq+NGTPGLl68OCvn3m3WwuZP4Yt3oOZTqK3GbqnGq1lNpGEDhrbrMO70ws8vJlLYl0jxACgqhaKBUDywZbmoLBjspPcQBTsR6baMMUustWOyXY5csbfXyLrmBKNu+j0/PnUkM44/sANLJiK7Yvny5YwcOTLbxeiyGhsbOfLII1m6dCl9+vTJdnH2mbZeFzu6PupfbbvCGCg9KJhSm4AogBeHujV4NV+wbv061m7YyJdfbqK2toZ4/VcUxZsoqW9k0Fd1DHbX0s9uoSi5ZftzOFHoWw79hreeCvuBccE4weS4QXmMA72HQnHZvqgBERHJIQ2xoFuTuj6KSFfz6quvcskll3DNNdf0qJC2J/QJvrciedD/QCL9D2TYQTAs46HGuMeH6+r4a3UtC/6+lZWb6lm5oZ6mWDP92EqZ2cIBBQ0cUbSVg/O+ZBgbKfvy7/Re8xeisa924eQGysfDyElw6CToX9FZP6WIiOSQlqCmnhoi0rWccsoprF69OtvFyAkKap2oV16EscP7M3Z4//Q2ay0b6mJ8snErn2yo55ON9SysaeDxmibW1Tbh+UE3yhIaOcDZyLAij7LiKKW9opQVRxlQFKW0l8uAXi6l9X+j8NMXML+fBb+fBYOObAltgw4PWt5ERKTHqY8lAXSPmohIDtulT3BjzETgbsAF7rfW/nSbx6cD/w9YG276L2vt/R1Yzm7DGMPgPgUM7lPANw9u3W3RS/ps2BqjuqYxmL4KwtsntU28WdvEulXNxJN+xjO+huscxaiiGv4pupTja//MQQt+irPg/xJ3i/HyirF5JZiC3jgFvYn26o1bUAJuXtBlMxkDrxm8WMvkuNvcS1cWzsP76gr6BJPupxMR6bLU9VFEJPft9BPcGOMC9wL/AKwBFhljnrPWfrTNro9ba6/ohDL2GBHXYUjfQob0LeSYAwds97jvWzY3xFlXGwS4DXXNbKqPsWnrEP64dQTz66fg+xs5qmkhB3nVFMeaKDZNFNFMiammmCZKTBP5xsNz8kg6eVgnD+vmQyQfE8kn6ngU1rxPfuxLIvG69gubV9IS2gr6QH5xxr10puWeOuMEX4NQVAbFg6BkcBD8igcFU2E/tfx1Bb4P8XpIJiAZBz8RLofrNhncR+nmgRsJ53ngRIIJC9YPjmNTUzIYiMeJBK+B9Dzacq+liHSK+jCoqUVNRCR37con+DhgpbX2MwBjzDxgMrBtUJNO5jiGspJ8ykryqSzv2+5+vn8GW5oSbG6IUxNOaxri1DTE2NwQ56uGOF81JqhtDOZfNcbZ2uxtd5w8EgygjlKzhf0idewfbaA0EqN/pIl+TiN9bCO9mxopbmqg0H6Fa2wwEcydcNlJxnCbvsR4bXz5oXEhWhj80R/JD+cFwb1/bn5LEHDcbZbd8A/+jBCQuRwthGivcCrMmBcGAcH6YAnmqZBhbXDcVJhwoxnLeWG4aCOIGqel/JHCIMhsK+lB42Zo2BROXwbzphpo+qqNqTYoV0EfKOgLhX1bz6O9dhx0jAuOE87dlnkyDvUbg3PXb4SGjVC/CRq/BH/710CncvODEU/7DoO+B7TM+x0AvfcHTFDeZCJo/U0vx8FPBkHQzwiFfjJYdlOBMhqcI7UcyQ/Oay3B7zxzTstrKvV7TwVRNxo87nvBOfxkuOxlnNdmBNSMyXHDMkQzXt/5wTbjtBwnPSVbjpt6TW5bVusH9eAngtdVKlT7ieCxVr/zSMvrFguJZvCawnkzJJqCyWsOW9jjGfOM5VPvCP6pIjlDLWoiIrlvVz7BhwDVGetrgPFt7DfVGHM88DfgGmttdRv7yD7gOIZ+RXn0K8rb5ed4SZ/apgS1jQnqmhPUNSWoa/bY0pRaTlDX5LGiOcHWZo+t6Xmw3BBP7uQMlmKaGBKpozxvK0MidQx26xjo1FFoPHq5HoXGo8B45Pse+YkEeYkEEXxcYrgkcUnikMS1Po5N4uDh+B6ODf64Nb7X8sdrohHa+dqETpcKn6nglmgMAlmb+zphAOsXTL1KYcBB4R/FBpprg9DWXAubPm5ZT8b2vHxuXti1tQxK9of9KoP1wn5hiEiFlIzAkgoVqbDkJzKWve2Da3oy4fMyA0UYShKNsGUt1K6Gj18IwqNkXyrcpv5ZEskLgl1htgsmu0ODiYj0bCeeeCLXXXcd//iP/5jedtddd/Hxxx8ze/bsNp8zYcIE7rzzTsaMGcOpp57KY489Rt++rRsGbrrpJoqLi7n22mvbPff8+fMZMWJE+ousb7zxRo4//nhOOeWUDvjJ4Oqrr+bJJ5+kuroax3E65JhdVUf9q+15oMpaGzPGXAo8BJy07U7GmJnATIBhw4Zt+7BkUcR1KC3Op7Q4f4+en/Qt9TEvmJo96mNBkGtZ92iMJ2mIeTTEPepiSdbFPBoytjfGkjTEg22J5O6FLMcEg7cU5rkU5bkU9HIoivj0dhOUuHFK3ATFTpwiJ06e6xB1XSIRl2jEJeq6RCMO0UiEfMdS4PrkG48CxyfPeOQZn3yTJOpYIg5EHYiaYNk1NmgFSSbC+/3CVgov1tJyES0Mun4WlYbzspb1gr5By9fu2tH3H1qb0dKTbN365LhBK11X7HYYb4Daaqj9AurWBmVMdbFMTxktXemvq3BaL/te+PtItcKFkxeGW2MAs82cltaszACaWjamdQtVuqXKbSnLdi2tpuW1kYy1lMeLBdtsMqOVeJuW48xjbFtW4wattqkgndml1Dht/O79ltbSaGHwz4NoQcs82qullc+Nds3Xhuw2DSYi0rNNmzaNefPmtQpq8+bN44477til57/wwgt7fO758+czadKkdFC75ZZb9vhY2/J9n2eeeYby8nLefPNNTjzxxA47dibP84hEsv/5uSslWAuUZ6wPpWXQEACstZszVu8H2nwVWGvnAHMg+DLP3SqpdGmuY+hTGKVPYbRDjhf3fBrjHk2JJM0Jn6Z4kqZEklgimDclkjTGkzTFg3DXFA/WG+NB8IslfJq94LlbvCTNzT6xcD2e9GlOJIl5PnEvc3CW1HL6W/KAHQdX1zHkuQ55kXByHfIjrdczl6MRh3zXIS/STF5kHXnu34lm7pexf7TVNkOe64bbTXp7xA3X3WD/aPh41IngRDvmd7HP5BXBwEODSUT2SkPMwzFQGFWLmkhPdOaZZzJr1izi8Th5eXmsWrWKdevW8c1vfpPvf//7LFq0iKamJs4880xuvvnm7Z4/fPhwFi9eTGlpKbfffjsPPfQQAwcOpLy8nKOPPhqAX//618yZM4d4PM5BBx3EI488wrJly3juued48803ue2223j66ae59dZbmTRpEmeeeSavvfYa1157LZ7nMXbsWGbPnk1+fj7Dhw/noosu4vnnnyeRSPDkk09y6KHb/z2wYMECDj/8cM455xyqqqrSQW3Dhg1cdtllfPbZZwDMnj2bb3zjGzz88MPceeedGGMYNWoUjzzyCNOnT0+XB6C4uJj6+noWLFjAv//7v9OvXz9WrFjB3/72N04//XSqq6tpbm7mqquuYubMmQC89NJL3HDDDSSTSUpLS3nllVc45JBDWLhwIWVlZfi+z4gRI3jnnXcoK9vz7zzelaC2CDjYGFNBENDOBf45cwdjzH7W2vXh6mnA8j0ukQiEYSWP9u/E6xi+b4knfWKeTywMb6lAt+08Hj4W7Nuy3JxIEvf89HHiqSnZslwf87bfHs4TSX+3WxB3RcQx6cAXDQNkxDVEHEPUTS0Hwc4Nt6WCYjRjnh+GP8cJnus6Dq4xRFyDY0yr87SE0pZtqXNEXKfVuaNOS3kirhOWISyL4+A4atkR2VP1MY+ivAhGLaQi2ffidfD39zv2mIOPhG//tN2H+/fvz7hx43jxxReZPHky8+bN4+yzz8YYw+23307//v1JJpOcfPLJvPfee4waNarN4yxZsoR58+axbNkyPM9j9OjR6aB2xhlnMGPGDABmzZrFAw88wJVXXslpp53WKgilNDc3M336dF577TVGjBjBhRdeyOzZs7n66qsBKC0tZenSpfzyl7/kzjvv5P77tx9AvqqqimnTpjF58mRuuOEGEokE0WiUH/zgB5xwwgk888wzJJNJ6uvr+fDDD7nttttYuHAhpaWl1NS0cxtKhqVLl/LBBx9QURF8N/GDDz5I//79aWpqYuzYsUydOhXf95kxYwZvvfUWFRUV1NTU4DgO559/Po8++ihXX301r776KpWVlXsV0mAXgpq11jPGXAG8TDA8/4PW2g+NMbcAi621zwE/MMacBnhADTB9r0olso84jqHAcSmIutBBrYF7IhUYExkhLuFZ4skgDCaSNh3qgsDo4/lhyPMsCd8nkdovmQp/qSAYbguP6yUtiaRP0rckfIsXbtua8DKekyqHJe4lSSQtSWtJ+sG0LzgGItuEudYhc/vAGXHCVkUnCJKpkJoZFF3H4BqD6wbziNMSQlP7RByDm7GcDpfhsVIBNC/SElwdh/SxW0JtSxkiYctnarv+gJbO1BDzNJCISA+X6v6YCmoPPPAAAE888QRz5szB8zzWr1/PRx991G5Qe/vtt5kyZQq9evUC4LTTTks/9sEHHzBr1ixqa2upr69v1c2yLR9//DEVFRWMGDECgIsuuoh77703HdTOOOMMAI4++mh++9vfbvf8eDzOCy+8wM9//nNKSkoYP348L7/8MpMmTeL111/n4YcfBsB1Xfr06cPDDz/MWWedRWlpKRCE150ZN25cOqQB3HPPPTzzzDMAVFdX88knn7Bp0yaOP/749H6p4373u99l8uTJXH311Tz44INcfPHFOz3fzuzSp7i19gXghW223ZixfD1w/V6XRqSHahUYuzhrLb4lHdqCwGjbbDFMBUYv2bJf5nIyvc3H8y1eeMx0kGz1WCpkZi4Hj2Weo6kpmV5PJH0S2+yb3Gby9lHw3FYqILomCG6OCYNeOLUKqW0E1m0Daupx1wnDoNty7Eir44b7uK0fywypwWNB4HUdwzcPLqMwr+u/NqVFQ9zTQCIiXcUOWr460+TJk7nmmmtYunQpjY2NHH300Xz++efceeedLFq0iH79+jF9+nSam9sYlXsXTJ8+nfnz51NZWcncuXNZsGDBXpU3Pz+43cR1XTxv+5GoX375ZWpraznyyCMBaGxspLCwkEmTJu3WeSKRCL4f3O7i+z7xeDz9WFFRUXp5wYIFvPrqq7zzzjv06tWLCRMm7LCuysvLGTRoEK+//jrvvvsujz766G6Vq82y7vURRKRHMcbghqEikPt/DPqZIdH3SSbDuZ8KljbdyphaTnVZTfo+ST8Irn7Y6piae+HzM/f3kkGITfpBK6XvW5I+6eckrSUZntPzw5CaGVzDcNuc8PGSXuvg6vv4YVmCn8dPB9KEb9M/5+565/qTKMzTsI+5pD6W1EAiIj1ccXExJ554It/97neZNm0aAHV1dRQVFdGnTx82bNjAiy++yIQJE9o9xvHHH8/06dO5/vrr8TyP559/nksvvRSArVu3st9++5FIJHj00UcZMmQIACUlJWzdunW7Yx1yyCGsWrWKlStXpu9pO+GEE3b556mqquL+++9P/ywNDQ1UVFTQ2NjIySefnO5Gmer6eNJJJzFlyhT+9V//lQEDBlBTU0P//v0ZPnw4S5Ys4eyzz+a5554jkUi0eb4tW7bQr18/evXqxYoVK/jTn/4EwDHHHMPll1/O559/nu76mGpV+973vsf555/PBRdcgOvu/d9H+hQXkR7PcQx5YfAs7AbBc2cyg2kq5HnbLCfTrZ6WAUV7NhqsZM9tk48g5u3sa1NEpLubNm0aU6ZMYd68eQBUVlZy1FFHceihh1JeXs6xxx67w+ePHj2ac845h8rKSgYOHMjYsWPTj916662MHz+esrIyxo8fnw5n5557LjNmzOCee+7hqaeeSu9fUFDAb37zG84666z0YCKXXXbZLv0cjY2NvPTSS9x3333pbUVFRRx33HE8//zz3H333cycOZMHHngA13WZPXs2X//61/nxj3/MCSecgOu6HHXUUcydO5cZM2YwefJkKisrmThxYqtWtEwTJ07kvvvuY+TIkRxyyCEcc8wxAJSVlTFnzhzOOOMMfN9n4MCBvPLKK0DQNfTiiy/ukG6PAMbuaJjvTjRmzBi7ePHirJxbRET2LWPMEmvtmGyXI1foGimS25YvX87IkSOzXQzZxxYvXsw111zD22+/3ebjbb0udnR9VIuaiIiIiIjIXvjpT3/K7NmzO+TetJTu/XXeIiIiIiIiney6665j9erVHHfccR12TAU1ERERERGRLkZBTURERESkg2VrHAjpmvbk9aCgJiIiIiLSgQoKCti8ebPCmgBBSNu8eTMFBQW79TwNJiIiIiIi0oGGDh3KmjVr2LRpU7aLIl1EQUEBQ4cO3a3nKKiJiIiIiHSgaDRKRUVFtoshOU5dH0VERERERLoYBTUREREREZEuRkFNRERERESkizHZGo3GGLMJWL2XhykFvuyA4nRHqpv2qW7apnppn+qmbbtTLwdYa8s6szDdia6RnU510zbVS/tUN21TvbRvV+um3etj1oJaRzDGLLbWjsl2Oboi1U37VDdtU720T3XTNtVL16bfT/tUN21TvbRPddM21Uv7OqJu1PVRRERERESki1FQExERERER6WJyPajNyXYBujDVTftUN21TvbRPddM21UvXpt9P+1Q3bVO9tE910zbVS/v2um5y+h41ERERERGR7ijXW9RERERERES6nZwNasaYicaYj40xK40x12W7PNlkjHnQGLPRGPNBxrb+xphXjDGfhPN+2SxjNhhjyo0xbxhjPjLGfGiMuSrcrroxpsAY864x5q9h3dwcbq8wxvw5fF89bozJy3ZZs8EY4xpj/mKM+V24rnoBjDGrjDHvG2OWGWMWh9t6/PupK9I1MqDrY/t0jWybro87p2vk9jrr+piTQc0Y4wL3At8GDgOmGWMOy26psmouMHGbbdcBr1lrDwZeC9d7Gg/4obX2MOAY4F/C14nqBmLASdbaSuAvgcqdAAADWUlEQVRrwERjzDHAfwC/sNYeBHwFXJLFMmbTVcDyjHXVS4sTrbVfyxhyWO+nLkbXyFbmoutje3SNbJuujzuna2TbOvz6mJNBDRgHrLTWfmatjQPzgMlZLlPWWGvfAmq22TwZeChcfgg4fZ8Wqguw1q631i4Nl7cSfKgMQXWDDdSHq9FwssBJwFPh9h5ZN8aYocA/AfeH6wbVy470+PdTF6RrZEjXx/bpGtk2XR93TNfI3bLX76VcDWpDgOqM9TXhNmkxyFq7Plz+OzAom4XJNmPMcOAo4M+oboB014VlwEbgFeBToNZa64W79NT31V3A/wb8cH0AqpcUC/zeGLPEGDMz3Kb3U9eja+SO6TW7DV0jW9P1cYd0jWxbp1wfIx1VOum6rLXWGNNjh/c0xhQDTwNXW2vrgn/+BHpy3Vhrk8DXjDF9gWeAQ7NcpKwzxkwCNlprlxhjJmS7PF3QcdbatcaYgcArxpgVmQ/25PeT5Ca9ZnWNbIuuj23TNXKHOuX6mKstamuB8oz1oeE2abHBGLMfQDjfmOXyZIUxJkpwAXrUWvvbcLPqJoO1thZ4A/g60NcYk/oHTk98Xx0LnGaMWUXQXewk4G5ULwBYa9eG840Ef7yMQ++nrkjXyB3Tazaka+SO6fq4HV0j29FZ18dcDWqLgIPDUWbygHOB57Jcpq7mOeCicPki4NksliUrwn7TDwDLrbU/z3hIdWNMWfifQowxhcA/ENyf8AZwZrhbj6sba+311tqh1trhBJ8rr1trz6OH1wuAMabIGFOSWga+BXyA3k9dka6RO6bXLLpGtkfXx/bpGtm2zrw+5uwXXhtjTiXoJ+sCD1prb89ykbLGGFMFTABKgQ3AT4D5wBPAMGA1cLa1dtsbqrs1Y8xxwNvA+7T0pb6BoA9+T6+bUQQ3troE/7B5wlp7izHmQIL/kvUH/gKcb62NZa+k2RN267jWWjtJ9QJhHTwTrkaAx6y1txtjBtDD309dka6RAV0f26drZNt0fdw1uka26MzrY84GNRERERERke4qV7s+ioiIiIiIdFsKaiIiIiIiIl2MgpqIiIiIiEgXo6AmIiIiIiLSxSioiYiIiIiIdDEKaiIiIiIiIl2MgpqIiIiIiEgXo6AmIiIiIiLSxfx/PobvmpbigO0AAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## Test del modello\n","La seguente cella permette di caricare l'ultimo checkpoint dell'addestramento\n","precedentemente salvato."],"metadata":{"id":"ReOkcBp2WHWW"}},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"5PIf_6-RSBb1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672852139532,"user_tz":-60,"elapsed":1167,"user":{"displayName":"Daniele Badiali","userId":"15682358814001311695"}},"outputId":"aff298aa-17dc-43bc-8549-4110a53a50a0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f7c9a84a8e0>"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["class Translate:\n","  def __init__(self, transformer_block, tokenizers):\n","    self.transformer = transformer_block\n","    self.tokenizers = tokenizers\n","\n","  def predict(self, input_text, max_length):\n","    if input_text is None:\n","      input_text = input_data[np.random.choice(len(input_data))]\n","      print(input_text)\n","\n","    inputs_bert = self.tokenizers.dan.tokenize(input_text)\n","\n","    start_end = self.tokenizers.ita.tokenize([''])[0]\n","    start = (start_end[0][tf.newaxis]).numpy()[0]\n","    end = (start_end[1][tf.newaxis]).numpy()[0]\n","\n","    output_array = tf.TensorArray(dtype=tf.int32, size=max_length, dynamic_size=True)\n","    output_array = output_array.write(0, tf.constant([start]))     \n","\n","    out_words = []\n","\n","    for i in tf.range(max_length):\n","      # decodifica e recupero probabilità di output\n","      output = tf.transpose(output_array.stack())\n","\n","      transformer_output = transformer((inputs_bert, output), \n","                                        training=False,\n","                                        debug=False)\n","\n","      predictions = transformer_output[:, -1:, :]\n","\n","      # selezione della parola più probabile\n","      predict = tf.argmax(predictions, -1)\n","      pred_values = (K.argmax(transformer_output, axis=-1)).numpy()\n","    \n","      # inserimento della parola nella sequenza di output\n","      output_array = output_array.write(i+1, [pred_values[0][i]])\n","\n","      if pred_values[0][i] == end:\n","        break\n","\n","    output = tf.transpose(output_array.stack())\n","    text = tokenizers.ita.detokenize(output)[0]  \n","    tokens = tokenizers.ita.lookup(output)[0]\n","\n","    return text, tokens"],"metadata":{"id":"L2PEoJVb1V8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_sequences = [test_input_data[1], test_input_data[33], test_input_data[10], \n","                  test_input_data[57], test_input_data[62], test_input_data[15], \n","                  test_input_data[4], test_input_data[42]]\n","\n","translate = Translate(transformer_block=transformer,\n","                      tokenizers=tokenizers)\n","\n","for test_sequence in test_sequences:\n","  text, token = translate.predict(tf.constant([test_sequence]), MAX_SEQ_LENGTH)\n","\n","  print(f'{\"Input:\":15s}: {test_sequence}')\n","  print(f'{\"Prediction\":15s}: {text.numpy().decode(\"utf-8\")}')  \n","  print('---------------------------------------------')\n","\n","print(test_target_data[1])\n","print(test_target_data[33])\n","print(test_target_data[10])\n","print(test_target_data[57])\n","print(test_target_data[62])\n","print(test_target_data[15])\n","print(test_target_data[4])\n","print(test_target_data[42])"],"metadata":{"id":"udIjI2jZWR6g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672852150227,"user_tz":-60,"elapsed":10702,"user":{"displayName":"Daniele Badiali","userId":"15682358814001311695"}},"outputId":"45c87635-5494-45bd-d5dc-4b81bfd3eb7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input:         : per la mpacciata via dietro al mio duca , \n","Prediction     : che la mia guida , che si avvicina a me ,\n","---------------------------------------------\n","Input:         : ond io li orecchi con le man copersi . \n","Prediction     : e la sua attraverso il suo pad , e la sua ri ,\n","---------------------------------------------\n","Input:         : credo che s era in ginocchie levata . \n","Prediction     : che non appena il suo aspetto era stato scosa ,\n","---------------------------------------------\n","Input:         : cosi spari e io su mi levai\n","Prediction     : e io sono stati riffffffffffre .\n","---------------------------------------------\n","Input:         : andiam , che la via lunga ne sospigne . \n","Prediction     : e la mia guida mi ha fatto mostrare rivere\n","---------------------------------------------\n","Input:         : e n su la punta de la rotta lacca l infamia di creti era distesa che fu concetta ne la falsa vacca\n","Prediction     : e la mia guida , e stato fatto che signo , e scosa , ma per me , dicendo\n","---------------------------------------------\n","Input:         : che per piacer di novo in voi si lega . \n","Prediction     : e io sono stati in cui la sua gentilezza .\n","---------------------------------------------\n","Input:         : pero non hanno vedere interciso\n","Prediction     : e io non puo essere fuggito dall alto e stato fatto\n","---------------------------------------------\n","sulla via colmata , i miei passi in quelli della guida , \n","che mi fecero tappare con entrambe le mani le orecchie . \n","credo che si fosse messa in ginocchio . \n","con questo egli scomparve e senza una parola , \n","andiamo avanti , per la lunga strada ci spinge . \n","e proprio all inizio del dirupo era distesa la vergogna di creta , che fu concepita nella finta vacca\n","regione del nord , negata quella vista ! \n","ma il nuovo non interrompe mai il loro sguardo , \n"]}]},{"cell_type":"markdown","source":["## Tensorboard"],"metadata":{"id":"YJf4hjv4PMAJ"}},{"cell_type":"code","source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"metadata":{"id":"vcwHe7VJWt-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_dir"],"metadata":{"id":"7AB28JmGPQgi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir drive/MyDrive/BERT/logs/fit/20221026-134720"],"metadata":{"id":"2ZkkDKVwPT2O"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":["qDYaeyzJ4AZP","b4ibAQRvrJDt","WEXGcXMlB8mx","YJf4hjv4PMAJ"]},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}