{"cells":[{"cell_type":"code","source":["!pip install -q -U 'tensorflow-text==2.8.*'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NE4enZGpvMRX","executionInfo":{"status":"ok","timestamp":1672993753838,"user_tz":-60,"elapsed":55723,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"18e1a007-f6d7-4c19-af15-78f739663024"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 KB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install -q tf-models-official"],"metadata":{"id":"FPtWz_qHuofc","executionInfo":{"status":"ok","timestamp":1672993807023,"user_tz":-60,"elapsed":53206,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9fa0ec05-e8eb-4ce8-bf40-39fb694fc570"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"hJy-juNOpUOY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672993832813,"user_tz":-60,"elapsed":25852,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"d3bcd32f-bd23-4162-f3ef-38b9b67d40bb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"id":"UaAiWsEuC_4K","executionInfo":{"status":"ok","timestamp":1672993838565,"user_tz":-60,"elapsed":5772,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"outputs":[],"source":["import os\n","import re\n","import time\n","import unicodedata\n","import datetime\n","import pathlib\n","import json\n","\n","from pathlib import Path\n","\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","from keras import layers\n","\n","import tensorflow_hub as hub\n","import tensorflow_models as tfm\n","\n","import tensorflow_text as text\n","from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"]},{"cell_type":"code","source":["tf.get_logger().setLevel('ERROR')\n","tf.config.run_functions_eagerly(True)"],"metadata":{"id":"uKEqRlKowOQS","executionInfo":{"status":"ok","timestamp":1672993838568,"user_tz":-60,"elapsed":23,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Parametri BERT"],"metadata":{"id":"BehZY4rETECN"}},{"cell_type":"code","source":["bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'  \n","tfhub_handle_encoder =  'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n","\n","print('BERT model selected                : ', tfhub_handle_encoder)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fodDcY6sm392","executionInfo":{"status":"ok","timestamp":1672993838569,"user_tz":-60,"elapsed":18,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"2f3f0323-ccd1-43e9-f1e3-c159d0943224"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT model selected                :  https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n"]}]},{"cell_type":"markdown","source":["### Variabili Globali"],"metadata":{"id":"HRe16D-rUBLA"}},{"cell_type":"code","source":["# PARAMETRI GLOBALI\n","root_folder = 'drive/MyDrive/BERT/'\n","\n","# DATI\n","data_folder_name = 'data'\n","data_filename = 'dataset_dantesco.csv'\n","train_filename = 'train_dataset_dantesco.csv'\n","\n","DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n","data_filenamepath = os.path.abspath(os.path.join(DATA_PATH, data_filename))\n","train_data_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n","\n","# PATH LOG Tensorboard\n","PATH_LOG = 'logs/fit/transformer_bert_dante'\n","PATH_LOG = os.path.abspath(os.path.join(root_folder, PATH_LOG))\n","log_dir =  os.path.abspath(os.path.join(PATH_LOG, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))) \n","log_history = os.path.abspath(os.path.join(PATH_LOG, 'histrory.json'))\n","\n","# PATH WEIGHTS Tensorboard\n","PATH_WEIGHTS = 'weights/transformer_bert_dante'\n","PATH_WEIGHTS = os.path.abspath(os.path.join(root_folder, PATH_WEIGHTS))\n","checkpoint_path = os.path.abspath(os.path.join(PATH_WEIGHTS, 'cp.ckpt'))\n","\n","# VOCABOLARIO\n","vocab_folder = 'vocab'\n","ita_vocab_finalname = 'ita_vocab_dante.txt'\n","dan_vocab_finalname = 'dan_vocab_dante.txt'\n","\n","VOCAB_PATH = os.path.abspath(os.path.join(root_folder, vocab_folder))\n","ita_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, ita_vocab_finalname))\n","dan_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, dan_vocab_finalname))"],"metadata":{"id":"ewLgCIuEpczO","executionInfo":{"status":"ok","timestamp":1672993838570,"user_tz":-60,"elapsed":15,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# parametri per il modello\n","ORIGINAL_COLUMN = 'Original'\n","TRANSLATE_COLUMN = 'Translate'\n","\n","# parametri per il modello\n","NUM_SAMPLES = 68248 \n","TRAIN = 16000 \n","VALIDATION = 16000\n","N_VALIDATION = 5\n","TEST = 100\n","\n","MAX_VOCAB_SIZE = 20000 \n","EMBEDDING_DIM = 64\n","HIDDEN_DIM = 1024 # numero di celle nei layer ricorrenti nascosti\n","\n","BATCH_SIZE = 32\n","BUFFER_SIZE = 2000\n","MAX_SEQ_LENGTH = 64\n","\n","NUM_LAYERS = 1 # Numero di layer di Decoder del Transformer\n","NUM_HEADS = 8 # Numero di meccanismi di multi-head attention\n","FF_DIM = 16 # Numero di celle dei Layer Feed Forward\n","DROPUOT = 0.5\n","\n","# Ottimizzatore Adam\n","LEARNING_RATE_ADAM = 1e-4\n","BETA_1 = 0.66\n","BETA_2 = 0.999\n","EPOCHS_ADAM = 5\n","\n","# IMPOSTO IL DEBUG A TRUE \n","debug = True\n","training = True"],"metadata":{"id":"8CN-4Uzoqbjl","executionInfo":{"status":"ok","timestamp":1672993838571,"user_tz":-60,"elapsed":15,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## DATASET"],"metadata":{"id":"5DPeN9Vanbvv"}},{"cell_type":"markdown","source":["### Caricamento Dati"],"metadata":{"id":"LU7AorKXT8K7"}},{"cell_type":"code","source":["exist_data_file = Path(train_data_filenamepath)\n","\n","if not exist_data_file.exists():\n","  # Caricamento dataset: frasi in inglese, frasi in italiano\n","  df = pd.read_csv(\n","    data_filenamepath,\n","    usecols=[ORIGINAL_COLUMN, TRANSLATE_COLUMN],\n","    names=[ORIGINAL_COLUMN, TRANSLATE_COLUMN],\n","    dtype={ORIGINAL_COLUMN: str, TRANSLATE_COLUMN: str}\n","  )\n","\n","  # df = df[-(TRAIN+VALIDATION+TEST):].reset_index(drop=True)\n","\n","  # Mischio il dataset in modo che sia più uniforme tra train e test\n","  df = df.iloc[np.random.permutation(df.index)].reset_index(drop=True)\n","\n","  print(df.iloc[-4:], '\\n')\n","\n","  df.to_csv(train_data_filenamepath, header=False, index=False, sep='|', columns=[ORIGINAL_COLUMN, TRANSLATE_COLUMN])"],"metadata":{"id":"vU7qvEPQ581U","executionInfo":{"status":"ok","timestamp":1672993839544,"user_tz":-60,"elapsed":987,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def unicode_to_ascii(s):\n","  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n","\n","def preprocess_sentence(w):\n","  '''\n","  Preprocessing dei testi di input, impostando tutti i caratteri\n","  minuscoli, aggiungendo uno spazio prima di ogni punto e sostituendo\n","  qualsiasi carattere con uno spazio se non è compreso nel seguente elenco:\n","  (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","  '''\n","  w = unicode_to_ascii(w.lower().strip())\n","\n","  # inserimento di uno spazio tra ogni parola e il successivo punto,\n","  # punto esclamativo, punto interrogativo e virgola\n","  # esempio: \"ciao, come và?\" => \"ciao , come và ?\"\n","  w = re.sub(r\"([?.!,])\", r\" \\1 \", w) # inserimento di uno spazio\n","\n","  # sostituzione dei caratteri non desiderati con uno spazio\n","  w = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", w)\n","\n","  w = re.sub(r'[\" \"]+', \" \", w) # rimozione di più spazi consecutivi\n","  return w"],"metadata":{"id":"Jm_Up6gyOTgW","executionInfo":{"status":"ok","timestamp":1672993839546,"user_tz":-60,"elapsed":19,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\n","  train_data_filenamepath,\n","  usecols=[ORIGINAL_COLUMN, TRANSLATE_COLUMN],\n","  names=[ORIGINAL_COLUMN, TRANSLATE_COLUMN],\n","  sep = '|'\n",")\n","\n","# Preprocessing dei dati di Input\n","input_data = df[TRANSLATE_COLUMN].apply(lambda x : preprocess_sentence(x)).tolist()\n","\n","# Preprocessing dei dati Target con aggiunta del token di fine frase\n","target_data = df[ORIGINAL_COLUMN].apply(lambda x : preprocess_sentence(x)).tolist()\n","\n","train_input_data = input_data[:TRAIN]\n","train_target_data = target_data[:TRAIN]\n","\n","validation_input_data = input_data[TRAIN:TRAIN+VALIDATION]\n","validation_target_data = target_data[TRAIN:TRAIN+VALIDATION]\n","\n","test_input_data = input_data[TRAIN+VALIDATION:TRAIN+VALIDATION+TEST]\n","test_target_data = target_data[TRAIN+VALIDATION:TRAIN+VALIDATION+TEST]\n","\n","print(f'Dati totali presenti nel Dataset               : {len(df)}')\n","print(f'Dati totali presenti nel Dataset di Train      : {len(train_input_data)}')\n","print(f'Dati totali presenti nel Dataset di Validation : {len(validation_input_data)}')\n","print(f'Dati totali presenti nel Dataset di Test       : {len(test_input_data)}\\n')\n","\n","\n","print('-----------TRAIN SET--------------')\n","print(train_input_data[-4:])\n","print(train_target_data[-4:])\n","print('-----------VALIDATION SET---------------')\n","print(validation_input_data[-4:])\n","print(validation_target_data[-4:])\n","print('-----------TEST SET---------------')\n","print(test_input_data[-4:])\n","print(test_target_data[-4:])"],"metadata":{"id":"NcEcrx2L2m5z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672993846557,"user_tz":-60,"elapsed":7024,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"3da36e83-f258-4f80-9913-725b12fcfedb"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Dati totali presenti nel Dataset               : 68249\n","Dati totali presenti nel Dataset di Train      : 16000\n","Dati totali presenti nel Dataset di Validation : 16000\n","Dati totali presenti nel Dataset di Test       : 100\n","\n","-----------TRAIN SET--------------\n","['tra esso e la base del terrapieno', 'peter ha iniziato la sua comunita senza oro . ', 'e io a lui io imparerei di piu da te ', 'con tutte le bellezze del suo spettacolo ']\n","['e tra l pie de la ripa ed essa , in traccia', 'pier comincio sanz oro e sanz argento , ', 'e io a lui ancor vo che mi nsegni', 'con le bellezze d ogne sua paroffia ']\n","-----------VALIDATION SET---------------\n","['era meglio che foste qui pecore o capre ! ', 'non per uscire dove non sarebbero stati bruciati . ', 'per il servizio di dio sono diventato cosi saldo , ', 'in piedi ad ascoltare con i loro occhi per terra , ']\n","['mei foste state qui pecore o zebe ! ', 'di non uscir dove non fosser arsi . ', 'al servigio di dio mi fe si fermo , ', 'con li occhi a terra stannosi , ascoltando']\n","-----------TEST SET---------------\n","['chi ruba questo albero e gioioso', 'lasciava che il cavaliere si concedesse da lui , ', 'se fossero torri , volevi chiedermelo ? ', 'supplicati per grazia per tanto potere']\n","['qualunque ruba quella o quella schianta , ', 'da esso ebbe milizia e privilegio ', 'sappi che non son torri , ma giganti , ', 'supplica a te , per grazia , di virtute']\n"]}]},{"cell_type":"markdown","source":["### Analisi Dati"],"metadata":{"id":"q1u_rcHxUaqV"}},{"cell_type":"code","source":["print(f'Esempi nel Dataset di Train                            : {len(train_input_data)}')\n","print(f'Frase più corta in Italiano nel Dataset di Train       : {min(train_input_data, key = len)}')\n","print(f'Frase più corta in Dantesco nel Dataset di Train       : {min(train_target_data, key = len)}')\n","print(f'Frase più lunga in Italiano nel Dataset di Train       : {max(train_input_data, key = len)}')\n","print(f'Frase più lunga in Dantesco nel Dataset di Train       : {max(train_target_data, key = len)}')\n","print('---------------------------------------------------------------------------------------')\n","print(f'Esempi nel Dataset di Validation                       : {len(validation_input_data)}')\n","print(f'Frase più corta in Italiano nel Dataset di Validation  : {min(validation_input_data, key = len)}')\n","print(f'Frase più corta in Dantesco nel Dataset di Validation  : {min(validation_target_data, key = len)}')\n","print(f'Frase più lunga in Italiano nel Dataset di Validation  : {max(validation_input_data, key = len)}')\n","print(f'Frase più lunga in Dantesco nel Dataset di Validation  : {max(validation_target_data, key = len)}')\n","print('---------------------------------------------------------------------------------------')\n","print(f'Esempi nel Dataset di Test                             : {len(test_input_data)}')\n","print(f'Frase più corta in Italiano nel Dataset di Test        : {min(test_input_data, key = len)}')\n","print(f'Frase più corta in Dantesco nel Dataset di Test        : {min(test_target_data, key = len)}')\n","print(f'Frase più lunga in Italiano nel Dataset di Test        : {max(test_input_data, key = len)}')\n","print(f'Frase più lunga in Dantesco nel Dataset di Test        : {max(test_target_data, key = len)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rssHK6CUcRL","executionInfo":{"status":"ok","timestamp":1672993846558,"user_tz":-60,"elapsed":46,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"d88d5e2a-7e6b-48c8-8d1f-37bacd57f216"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Esempi nel Dataset di Train                            : 16000\n","Frase più corta in Italiano nel Dataset di Train       : e lei , dov e ? \n","Frase più corta in Dantesco nel Dataset di Train       : a vera vita non e\n","Frase più lunga in Italiano nel Dataset di Train       : l impatto sull ambiente e sull ambiente di lavoro e di gran lunga superiore a quello degli altri paesi . \n","Frase più lunga in Dantesco nel Dataset di Train       : dal quinto il quarto , e poi dal sesto il quinto . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Validation                       : 16000\n","Frase più corta in Italiano nel Dataset di Validation  : e poi ho detto \n","Frase più corta in Dantesco nel Dataset di Validation  : a vera vita non e\n","Frase più lunga in Italiano nel Dataset di Validation  : presidente . l ordine del giorno reca , in discussione congiunta , le seguenti proposte di risoluzione \n","Frase più lunga in Dantesco nel Dataset di Validation  : dal quinto il quarto , e poi dal sesto il quinto . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Test                             : 100\n","Frase più corta in Italiano nel Dataset di Test        : mostro l inferno a chi vive . \n","Frase più corta in Dantesco nel Dataset di Test        : e io udi ne la luce piu dia\n","Frase più lunga in Italiano nel Dataset di Test        : il pendio sale piu in alto di quanto i miei occhi possano seguire . \n","Frase più lunga in Dantesco nel Dataset di Test        :  fuor di quel mar che la terra inghirlanda , \n"]}]},{"cell_type":"markdown","source":["## Tokenizer\n","\n","Creo due differenti tokenizer che mi servizranno per la predisposizione dei dati di input:\n","\n","\n","*   EncTokenizer classe custom per la tokenizzazione dei dati di input al Layer di Encoder di Bert\n","*   DecTokenizer classe custom per la tokenizzazione dei dati di input al Layer di Decoder\n","\n"],"metadata":{"id":"njyY9RWlFMWu"}},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices((input_data, target_data))\n","dataset = dataset.shuffle(len(input_data)).batch(BATCH_SIZE, drop_remainder=True)\n","\n","train_ita = dataset.map(lambda ita, dan: ita)\n","train_dan = dataset.map(lambda ita, dan: dan)"],"metadata":{"id":"fUG1fTAYekOy","executionInfo":{"status":"ok","timestamp":1672993849951,"user_tz":-60,"elapsed":3428,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a15ca8e2-a998-4613-987c-284f9ad691df"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def write_vocab_file(filepath, vocab):\n","  with open(filepath, 'w') as f:\n","    for token in vocab:\n","      print(token, file=f)"],"metadata":{"id":"xWO-LrXJe0cF","executionInfo":{"status":"ok","timestamp":1672993849952,"user_tz":-60,"elapsed":34,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def cleanup_text(reserved_tokens, token_txt):\n","\n","  # Drop the reserved tokens, except for \"[UNK]\".\n","  bad_tokens = [re.escape(tok) for tok in reserved_tokens if tok != \"[UNK]\"]\n","  bad_token_re = \"|\".join(bad_tokens)\n","\n","  bad_cells = tf.strings.regex_full_match(token_txt, bad_token_re)\n","  result = tf.ragged.boolean_mask(token_txt, ~bad_cells)\n","\n","  # Join them into strings.\n","  result = tf.strings.reduce_join(result, separator=' ', axis=-1)\n","\n","  return result"],"metadata":{"id":"yGdsrOoKiYUK","executionInfo":{"status":"ok","timestamp":1672993849953,"user_tz":-60,"elapsed":34,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["tokenizers = tf.Module()"],"metadata":{"id":"qbKNS_uQhHLz","executionInfo":{"status":"ok","timestamp":1672993850296,"user_tz":-60,"elapsed":376,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["### Classe EncTokenizer\n","\n","Classe custom per la tokenizzazione dei dati di Dante e che crea i tre vettori necessari al layer di Encoder \n","Bert:\n","\n","\n","*   input_word_ids\n","*   input_type_ids\n","*   input_mask\n","\n","\n","\n"],"metadata":{"id":"0KUcCnjXVjt3"}},{"cell_type":"code","source":["bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens = {\n","    'start_of_sequence_id': 101,\n","    'end_of_segment_id': 102,\n","    'padding_id': 0,\n","    'mask_id': 103\n","}\n","\n","bert_vocab_args = dict(\n","    # The target vocabulary size\n","    vocab_size = MAX_VOCAB_SIZE,\n","    # Reserved tokens that must be included in the vocabulary\n","    reserved_tokens=reserved_tokens,\n","    # Arguments for `text.BertTokenizer`\n","    bert_tokenizer_params=bert_tokenizer_params,\n","    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","    learn_params={},\n",")"],"metadata":{"id":"Yr0izOZLembx","executionInfo":{"status":"ok","timestamp":1672993850297,"user_tz":-60,"elapsed":10,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(ita_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  ita_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_ita.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(ita_vocab_filenamepath, ita_vocab)"],"metadata":{"id":"BwSKtlLSe7bH","executionInfo":{"status":"ok","timestamp":1672993850298,"user_tz":-60,"elapsed":10,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class EncTokenizer(tf.Module):\n","  def __init__(self, reserved_tokens, vocab_path, max_len):\n","    self.tokenizer = text.BertTokenizer(vocab_path, lower_case=True, token_out_type=tf.int32)\n","    self._reserved_tokens_vocab = reserved_tokens\n","    self._vocab_path = tf.saved_model.Asset(vocab_path)\n","    self.packer_input = tfm.nlp.layers.BertPackInputs(seq_length=max_len,\n","                                                      special_tokens_dict=reserved_tokens)\n","    \n","    vocab = pathlib.Path(vocab_path).read_text().splitlines()\n","    self.vocab = tf.Variable(vocab)\n","\n","    ## Create the signatures for export:   \n","\n","    # Include a tokenize signature for a batch of strings. \n","    self.tokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None], dtype=tf.string))\n","    \n","    # Include `detokenize` and `lookup` signatures for:\n","    #   * `Tensors` with shapes [tokens] and [batch, tokens]\n","    #   * `RaggedTensors` with shape [batch, tokens]\n","    self.detokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.detokenize.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    self.lookup.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.lookup.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    # These `get_*` methods take no arguments\n","    self.get_vocab_size.get_concrete_function()\n","    self.get_vocab_path.get_concrete_function()\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    enc = self.tokenizer.tokenize(strings, )\n","    # Merge the `word` and `word-piece` axes.\n","    enc = enc.merge_dims(-2,-1)\n","    enc = self.packer_input([enc])\n","    return enc\n","\n","  @tf.function\n","  def detokenize(self, tokenized):\n","    words = self.tokenizer.detokenize(tokenized)\n","    return cleanup_text(self._reserved_tokens_vocab, words)\n","\n","  @tf.function\n","  def lookup(self, token_ids):\n","    return tf.gather(self.vocab, token_ids)\n","\n","  @tf.function\n","  def get_vocab_size(self):\n","    return tf.shape(self.vocab)[0]\n","\n","  @tf.function\n","  def get_vocab_path(self):\n","    return self._vocab_path"],"metadata":{"id":"WmsNdDLNf6vr","executionInfo":{"status":"ok","timestamp":1672993850298,"user_tz":-60,"elapsed":10,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["tokenizers.ita = EncTokenizer(reserved_tokens, ita_vocab_filenamepath, MAX_SEQ_LENGTH*2)"],"metadata":{"id":"-4B-HWWcmsmz","executionInfo":{"status":"ok","timestamp":1672993859570,"user_tz":-60,"elapsed":9281,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["### Classe DecTokenizer\n","\n","Classe custom per la tokenizzazione dei dati in lingua italiana per il layer di Decoder\n"],"metadata":{"id":"mICEGEzJVnvx"}},{"cell_type":"code","source":["bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens_vocab=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","bert_vocab_args = dict(\n","    # The target vocabulary size\n","    vocab_size = MAX_VOCAB_SIZE,\n","    # Reserved tokens that must be included in the vocabulary\n","    reserved_tokens=reserved_tokens_vocab,\n","    # Arguments for `text.BertTokenizer`\n","    bert_tokenizer_params=bert_tokenizer_params,\n","    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","    learn_params={},\n",")"],"metadata":{"id":"abBEnJJGV0AD","executionInfo":{"status":"ok","timestamp":1672993859571,"user_tz":-60,"elapsed":48,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(dan_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  dan_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_dan.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(dan_vocab_filenamepath, dan_vocab)"],"metadata":{"id":"dGsP1V4nVz6S","executionInfo":{"status":"ok","timestamp":1672993859572,"user_tz":-60,"elapsed":46,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["START = tf.argmax(tf.constant(reserved_tokens_vocab) == \"[START]\")\n","END = tf.argmax(tf.constant(reserved_tokens_vocab) == \"[END]\")\n","\n","def add_start_end(ragged):\n","  count = ragged.bounding_shape(out_type=tf.int32)[0]\n","\n","  starts = tf.fill([count,1], START)\n","  starts = tf.cast(starts, tf.int32)\n","\n","  ends = tf.fill([count,1], END)\n","  ends = tf.cast(ends, tf.int32)\n","\n","  x = tf.concat([starts, ragged, ends], axis=1)\n","  return x"],"metadata":{"id":"BeaD2-uLWT50","executionInfo":{"status":"ok","timestamp":1672993859572,"user_tz":-60,"elapsed":44,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["class DecTokenizer(tf.Module):\n","  def __init__(self, reserved_tokens_vocab, vocab_path):\n","    self.tokenizer = text.BertTokenizer(vocab_path, lower_case=True, token_out_type=tf.int32)\n","    self._reserved_tokens_vocab = reserved_tokens_vocab\n","    self._vocab_path = tf.saved_model.Asset(vocab_path)\n","\n","    vocab = pathlib.Path(vocab_path).read_text().splitlines()\n","    self.vocab = tf.Variable(vocab)\n","\n","    ## Create the signatures for export:   \n","\n","    # Include a tokenize signature for a batch of strings. \n","    self.tokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None], dtype=tf.string))\n","    \n","    # Include `detokenize` and `lookup` signatures for:\n","    #   * `Tensors` with shapes [tokens] and [batch, tokens]\n","    #   * `RaggedTensors` with shape [batch, tokens]\n","    self.detokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.detokenize.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    self.lookup.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.lookup.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    # These `get_*` methods take no arguments\n","    self.get_vocab_size.get_concrete_function()\n","    self.get_vocab_path.get_concrete_function()\n","    self.get_reserved_tokens.get_concrete_function()\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    enc = self.tokenizer.tokenize(strings)\n","    # Merge the `word` and `word-piece` axes.\n","    enc = enc.merge_dims(-2,-1)\n","    enc = add_start_end(enc)\n","    return enc\n","\n","  @tf.function\n","  def detokenize(self, tokenized):\n","    words = self.tokenizer.detokenize(tokenized)\n","    return cleanup_text(self._reserved_tokens_vocab, words)\n","\n","  @tf.function\n","  def lookup(self, token_ids):\n","    return tf.gather(self.vocab, token_ids)\n","\n","  @tf.function\n","  def get_vocab_size(self):\n","    return tf.shape(self.vocab)[0]\n","\n","  @tf.function\n","  def get_vocab_path(self):\n","    return self._vocab_path\n","\n","  @tf.function\n","  def get_reserved_tokens(self):\n","    return tf.constant(self._reserved_tokens_vocab)"],"metadata":{"id":"iaAW-xm5WT1_","executionInfo":{"status":"ok","timestamp":1672993859573,"user_tz":-60,"elapsed":42,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["tokenizers.dan = DecTokenizer(reserved_tokens_vocab, dan_vocab_filenamepath)"],"metadata":{"id":"svlLobM4WTzC","executionInfo":{"status":"ok","timestamp":1672993861905,"user_tz":-60,"elapsed":2372,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["### Analisi Dati Tokenizzati"],"metadata":{"id":"pKZxiQ5_Whmw"}},{"cell_type":"code","source":["print(f'Vocabolario Italiano : {tokenizers.ita.get_vocab_size()}')\n","print(f'Vocabolario Dantesco : {tokenizers.dan.get_vocab_size()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jrg6TwQzW5LN","executionInfo":{"status":"ok","timestamp":1672993861907,"user_tz":-60,"elapsed":18,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"9581ee6d-d598-4834-ecdc-0b1ca3dddf70"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabolario Italiano : 5139\n","Vocabolario Dantesco : 6309\n"]}]},{"cell_type":"code","source":["print(input_data[-2:])\n","print(tokenizers.ita.tokenize(input_data[-2:])['input_word_ids'][:, :32])\n","print('------------------------------------------------------------------')\n","print(target_data[-2:])\n","print(tokenizers.dan.tokenize(target_data[-2:]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKEFeDdGFIGS","executionInfo":{"status":"ok","timestamp":1672993862383,"user_tz":-60,"elapsed":488,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"f345929b-025f-40d0-aa81-bee9e069d3a1"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["['in piedi sul bordo del ponte , ho visto questo', 'quindi penso di fare bene , non chiedendo nulla ']\n","tf.Tensor(\n","[[ 101   39  172  187  537   53  754    5   52   90   58  102    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0]\n"," [ 101  339 1071   37  251  151    5   38 3189  439  102    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0]], shape=(2, 32), dtype=int32)\n","------------------------------------------------------------------\n","['io stava sovra l ponte a veder surto , ', 'contra l disio , fo ben ch io non dimando . ']\n","<tf.RaggedTensor [[2, 37, 569, 206, 17, 814, 8, 152, 6086, 5, 3],\n"," [2, 356, 17, 268, 5, 2543, 79, 39, 37, 35, 1006, 6, 3]]>\n"]}]},{"cell_type":"code","source":["print([min(train_input_data, key = len)])\n","print(tokenizers.ita.tokenize([min(train_input_data, key = len)])['input_word_ids'][:, :32])\n","print('------------------------------------------------------------------')\n","print([min(train_target_data, key = len)])\n","print(tokenizers.dan.tokenize([min(train_target_data, key = len)]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O85BUq2INK5j","executionInfo":{"status":"ok","timestamp":1672993862384,"user_tz":-60,"elapsed":21,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"d6dfcf96-9d13-4ade-8f65-823ce3ce9095"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["['e lei , dov e ? ']\n","tf.Tensor(\n","[[101  12 162   5 906  12   7 102   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(1, 32), dtype=int32)\n","------------------------------------------------------------------\n","['a vera vita non e']\n","<tf.RaggedTensor [[2, 8, 535, 182, 35, 12, 3]]>\n"]}]},{"cell_type":"code","source":["print([max(train_input_data, key = len)])\n","print(tokenizers.ita.tokenize([max(train_input_data, key = len)])['input_word_ids'])\n","print('------------------------------------------------------------------')\n","print([max(train_target_data, key = len)])\n","print(tokenizers.dan.tokenize([max(train_target_data, key = len)]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JzJl4YGBPR3Z","executionInfo":{"status":"ok","timestamp":1672993862731,"user_tz":-60,"elapsed":360,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"eff21aa8-5b8f-4678-b8a5-5f7fbf9eec7d"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["['l impatto sull ambiente e sull ambiente di lavoro e di gran lunga superiore a quello degli altri paesi . ']\n","tf.Tensor(\n","[[ 101   19   16  890 1258  442  408    8  890 1266 1389   12  408    8\n","   890 1266 1389   37 1240   12   37 1403  588 1895    8   92  298  159\n","    23  205 2389  199    6  102    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]], shape=(1, 128), dtype=int32)\n","------------------------------------------------------------------\n","['dal quinto il quarto , e poi dal sesto il quinto . ']\n","<tf.RaggedTensor [[2, 93, 1263, 45, 1420, 5, 12, 60, 93, 1148, 45, 1263, 6, 3]]>\n"]}]},{"cell_type":"markdown","source":["## Creazione dataset\n","Utilizzo della libreria tf.data per la gestione del dataset da utilizzare.\n","Verranno creati batch di esempi che verranno utilizzati durante l'addestramento."],"metadata":{"id":"5QIDajkEsVU1"}},{"cell_type":"code","source":["def prepare_batch(dan, ita):\n","  zero = tf.zeros([BATCH_SIZE, MAX_SEQ_LENGTH], tf.int32)\n","\n","  # Tokenizzo l'input per l'Encoder\n","  encoder = tokenizers.ita.tokenize(ita)          \n","\n","  # Tokenizzo l'input per il Decder e creo la variabile Target\n","  dan = tokenizers.dan.tokenize(dan)\n","  decoder = dan[:, :-1].to_tensor()  # Drop the [END] tokens\n","  target = dan[:, 1:].to_tensor()   # Drop the [START] tokens\n","  \n","  decoder = tf.concat([decoder, zero], 1)\n","  decoder = decoder[:, :(MAX_SEQ_LENGTH)]\n","\n","  target = tf.concat([target, zero], 1)\n","  target = target[:, :(MAX_SEQ_LENGTH)]\n","\n","  return (encoder, decoder), target"],"metadata":{"id":"ccH3jHoABPzV","executionInfo":{"status":"ok","timestamp":1672993862732,"user_tz":-60,"elapsed":12,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def make_batches(ds):\n","  return (\n","      ds\n","      .shuffle(BUFFER_SIZE)\n","      .batch(BATCH_SIZE)\n","      .map(prepare_batch, tf.data.AUTOTUNE)\n","      .prefetch(buffer_size=tf.data.AUTOTUNE))"],"metadata":{"id":"l_dswlCiBTdR","executionInfo":{"status":"ok","timestamp":1672993862733,"user_tz":-60,"elapsed":12,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Suddivido il dataset di validation in n parti per effettuare una validation incrociata\n","num_record_validation = len(validation_input_data) / N_VALIDATION\n","val_input_data = []\n","val_target_data = []\n","\n","for i in range(N_VALIDATION):\n","  df_input = validation_input_data[int((i*num_record_validation)):int(((i+1)*num_record_validation))]\n","  df_target = validation_target_data[int((i*num_record_validation)):int(((i+1)*num_record_validation))]\n","\n","  val_input_data.append(df_input)\n","  val_target_data.append(df_target)"],"metadata":{"id":"ess3ZrYA3H0h","executionInfo":{"status":"ok","timestamp":1672993862733,"user_tz":-60,"elapsed":11,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Definizione del dataset\n","# [from_tensor_slices] permette di recuperare batch\n","# di esempi dai dataset di riferimento\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_input_data, train_target_data))\n","validation_dataset = [tf.data.Dataset.from_tensor_slices((val_input, val_target)) \n","                            for val_input, val_target in zip(val_input_data, val_target_data)]\n","\n","# impostazione del recupero di esempi presi in maniera\n","# casuale in gruppi di [BATCH_SIZE] tra quelli disponibili\n","train_dataset = make_batches(train_dataset)\n","validation_dataset = [make_batches(val_dataset) for val_dataset in validation_dataset]"],"metadata":{"id":"tktJ5YuIsYe3","executionInfo":{"status":"ok","timestamp":1672993872138,"user_tz":-60,"elapsed":9415,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Recupero un batch di esempi per la verifica delle classi custom che andrò a creare\n","for (enc_input, dec_input), target in train_dataset.take(1):\n","  print('----------------------- ENCODER  -------------------------------')\n","  print(f'Shape                    : {enc_input[\"input_word_ids\"].shape}')\n","  print(f'Word Ids                 : {enc_input[\"input_word_ids\"][0, :MAX_SEQ_LENGTH]}')\n","  print(f'Input Mask               : {enc_input[\"input_mask\"][0, :MAX_SEQ_LENGTH]}')\n","  print(f'Type Ids                 : {enc_input[\"input_type_ids\"][0, :MAX_SEQ_LENGTH]}')  \n","  print('--------------------- DECODER ----------------------------------')\n","  print(f'Shape it input           : {dec_input.shape}')\n","  print(f'Example it input         : {dec_input[0]}')  \n","  print('--------------------- TARGET -----------------------------------')\n","  print(f'Shape it input           : {target.shape}')\n","  print(f'Example it target        : {target[0]}')  "],"metadata":{"id":"VH_aKPlV_AWA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672993873432,"user_tz":-60,"elapsed":1310,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"f85f10a0-adda-4035-c88f-b07aa627b003"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------- ENCODER  -------------------------------\n","Shape                    : (32, 128)\n","Word Ids                 : [ 101  243   69    8   84   75  259 2200   12   75  259 2357   99  102\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n","Input Mask               : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","Type Ids                 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","--------------------- DECODER ----------------------------------\n","Shape it input           : (32, 64)\n","Example it input         : [   2 1736  107   36   73  573  651   12  573   52  111 4490    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n","--------------------- TARGET -----------------------------------\n","Shape it input           : (32, 64)\n","Example it target        : [1736  107   36   73  573  651   12  573   52  111 4490    3    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n"]}]},{"cell_type":"markdown","source":["## Encoder BERT\n","\n","Predispondo la classe necessaria per la costruzione di BERT\n"],"metadata":{"id":"8dtVuZGJpvXl"}},{"cell_type":"code","source":["class EncoderBert(layers.Layer):\n","  def __init__(self, bert_encoder, embedding_dim, max_len):\n","    super(EncoderBert, self).__init__()\n","\n","    self.encoder = hub.KerasLayer(bert_encoder, name='BERT_encoder', trainable=False)\n","\n","    self.conv_1 = tf.keras.layers.Conv1D(embedding_dim * 4, 1, activation='relu') \n","    self.conv_2 = tf.keras.layers.Conv1D(embedding_dim, 1, activation='relu') \n","    self.lambda_layer = tf.keras.layers.Lambda(lambda x: x[:,:max_len])\n","    self.max_len = max_len\n","\n","  def call(self, x, debug=False):\n","\n","    if debug:\n","      print(f'****************** DEBUG ENCODER BERT ******************')\n","      print(f\"First example\")\n","      print(f'Keys                         : {list(x.keys())}')\n","      print(f'Shape                        : {x[\"input_word_ids\"].shape}')\n","      print(f'Word Ids                     : {x[\"input_word_ids\"][0, :16]}')\n","      print(f'Input Mask                   : {x[\"input_mask\"][0, :16]}')\n","      print(f'Type Ids                     : {x[\"input_type_ids\"][0, :16]}')\n","      \n","    # x = self.encoder(x)['sequence_output'] \n","    # encoder_outputs stato intermedio di BERT prima che esegua la traduzione recuperare la metà della lunghezza\n","    x = self.encoder(x)['encoder_outputs'] \n","    x = x[int(len(x) / 2) - 1]\n","\n","    if debug:\n","      print()\n","      print(f'Encoder Outputs BERT Shape   : {x.shape}')\n","      print(f'Encoder Outputs BERT Values  : {x[0, :1, :16]}')\n","\n","    x = self.conv_1(x)\n","    if debug:\n","      print()\n","      print(f'Sequence Conv1 Shape         : {x.shape}')\n","\n","    x = self.conv_2(x)\n","    if debug:\n","      print(f'Sequence Conv2 Shape         : {x.shape}')\n","\n","    x = self.lambda_layer(x)\n","    if debug:\n","      print(f'Sequence Lambda Layer        : {x.shape}')\n","      print()\n","      print(f'Sequence Outputs Values      : {x[0, 0, :16]}')      \n","      print('*********************************************************') \n","\n","    return x"],"metadata":{"id":"m7v9Y-Lep4CD","executionInfo":{"status":"ok","timestamp":1672993873433,"user_tz":-60,"elapsed":11,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["encoder_bert = EncoderBert(tfhub_handle_encoder, \n","                           EMBEDDING_DIM, \n","                           MAX_SEQ_LENGTH)\n","\n","bert_outputs = encoder_bert(enc_input, debug) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q08luTkusEfn","executionInfo":{"status":"ok","timestamp":1672993916007,"user_tz":-60,"elapsed":42582,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"231ba81d-03f0-4f88-c7af-fd12c765553a"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_word_ids', 'input_mask', 'input_type_ids']\n","Shape                        : (32, 128)\n","Word Ids                     : [ 101  243   69    8   84   75  259 2200   12   75  259 2357   99  102\n","    0    0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n","Type Ids                     : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[-0.2855804  -1.0893128   0.18167168 -0.51378155 -0.0605888   0.56065214\n","  -0.5365202   0.01175864 -0.01334048 -0.88153327 -0.1537769   0.9340685\n","  -0.17861578  0.3018391  -0.34964022  0.3313697 ]]\n","\n","Sequence Conv1 Shape         : (32, 128, 256)\n","Sequence Conv2 Shape         : (32, 128, 64)\n","Sequence Lambda Layer        : (32, 64, 64)\n","\n","Sequence Outputs Values      : [0.5213613  1.7226831  0.9686215  0.         0.         0.\n"," 0.03983971 0.33337787 0.         0.         0.         0.\n"," 0.         0.         0.69320685 1.9042478 ]\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["## Decoder\n","\n","Predispondo la classe necessaria per la costruzione di un Layer di Decoder"],"metadata":{"id":"ReEQ5rX7aGtl"}},{"cell_type":"markdown","source":["### TOKEN AND POSITION EMBEDDING\n","\n","Implementazione del blocco Embedding per l'utilizzo di vettori posizionali insieme ai vettori di token di parole tramite estensione della classe Layer di Keras. "],"metadata":{"id":"gAu1IXlRZzlq"}},{"cell_type":"code","source":["class TokenAndPositionEmbedding(layers.Layer):\n","  def __init__(self, maxlen, vocab_size, embed_dim):\n","    super(TokenAndPositionEmbedding, self).__init__()\n","    self.maxlen = maxlen\n","    self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n","    self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","  def call(self, x, debug=False):\n","    x = keras.preprocessing.sequence.pad_sequences(x, maxlen=self.maxlen, padding='post')\n","    maxlen = tf.shape(x)[-1]\n","\n","    if debug:\n","      print('********** DEBUG TOKEN AND POSITION EMBEDDING ***********')\n","      print(f'Sequence Max len                          : {maxlen}')\n","      print(f'Sequence Shape                            : {tf.shape(x)}')\n","\n","    positions = tf.range(start=0, limit=maxlen, delta=1)\n","    positions = self.pos_emb(positions)\n","    x = self.token_emb(x)\n","    output = x + positions\n","\n","    if debug:\n","      print(f'Shape TokenAndPositionEmbedding           : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"o9-RSKTqsmUC","executionInfo":{"status":"ok","timestamp":1672993916008,"user_tz":-60,"elapsed":23,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["token_position_it = TokenAndPositionEmbedding(MAX_SEQ_LENGTH, tokenizers.dan.get_vocab_size(), EMBEDDING_DIM)\n","\n","inputs_decoder = token_position_it(dec_input, debug)"],"metadata":{"id":"rr_EWQUX8EWP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672993916009,"user_tz":-60,"elapsed":22,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"619bb4ba-7855-4fca-c166-462ff6ccfe3e"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 64\n","Sequence Shape                            : [32 64]\n","Shape TokenAndPositionEmbedding           : (32, 64, 64)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["### LAYER DECODER\n","\n","Implementazione di un blocco di DecoderTransformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"XdLv-6nidKGK"}},{"cell_type":"markdown","source":["#### DecodeBert\n","\n","Implmentazione di un blocco di  decodifica custom per decodificare l'output dal layer EncoderBert prima di passarlo al Decoder del Transformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"_iq7Y-d4eRd8"}},{"cell_type":"code","source":["class DecodeBert(layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DecodeBert'):\n","    super(DecodeBert, self).__init__()\n","    self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = keras.Sequential(\n","      [layers.Dense(ff_dim, activation='relu'), layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = layers.LayerNormalization()\n","    self.layernorm2 = layers.LayerNormalization()\n","    self.dropout1 = layers.Dropout(rate)\n","    self.dropout2 = layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, bert_outputs, training=False, debug=False):\n","    attn_output = self.att(query=bert_outputs,\n","                           value=bert_outputs, \n","                           key=bert_outputs)\n","    \n","    attn_output = self.dropout1(attn_output)\n","    out1 = self.layernorm1(bert_outputs + attn_output)\n","\n","    ffn_output = self.ffn(out1)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","\n","    output = self.layernorm2(out1 + ffn_output)\n","\n","    if debug:\n","      print('********************* DEBUG DECODE-BERT *********************')\n","      print(f'Shape Input Layer Decode-Bert       : {bert_outputs.shape}')\n","      print(f'Shape Output Layer Decode-Bert      : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"joTBTlWF8ETD","executionInfo":{"status":"ok","timestamp":1672993916010,"user_tz":-60,"elapsed":14,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["encoder = DecodeBert(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_encoder = encoder(bert_outputs=bert_outputs,\n","                          training=training, \n","                          debug=debug)"],"metadata":{"id":"JaIzBxFCfKe9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672993918344,"user_tz":-60,"elapsed":2346,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"c4f64b1b-3e8d-43b8-8739-8ee94999cc94"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 64, 64)\n","Shape Output Layer Decode-Bert      : (32, 64, 64)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["#### Layer Decoder"],"metadata":{"id":"dMTKLwd3dRw5"}},{"cell_type":"code","source":["class Decoder(layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DEC'):\n","    super(Decoder, self).__init__()\n","    self.decode_bert = DecodeBert(max_len=max_len, embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, rate=rate)\n","    self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.att2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = keras.Sequential(\n","      [layers.Dense(ff_dim, activation='relu'), layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = layers.LayerNormalization()\n","    self.layernorm2 = layers.LayerNormalization()\n","    self.layernorm3 = layers.LayerNormalization()\n","    self.dropout1 = layers.Dropout(rate)\n","    self.dropout2 = layers.Dropout(rate)\n","    self.dropout3 = layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, inputs, bert_outputs, training=False, debug=False):\n","    attn_output1 = self.att1(query=inputs,\n","                             value=inputs, \n","                             key=inputs, \n","                             use_causal_mask=True)\n","    \n","    attn_output1 = self.dropout1(attn_output1)\n","    out1 = self.layernorm1(inputs + attn_output1)\n","\n","    dec_bert = self.decode_bert(bert_outputs=bert_outputs, training=training, debug=debug)\n","\n","    attn_output2 = self.att2(key=dec_bert, \n","                             value=dec_bert, \n","                             query=out1)\n","    \n","    attn_output2 = self.dropout2(attn_output2, training=training)\n","    out2 = self.layernorm2(out1 + attn_output2)\n","\n","    ffn_output = self.ffn(out2)\n","    ffn_output = self.dropout3(ffn_output, training=training)\n","\n","    output = self.layernorm3(out2 + ffn_output)\n","\n","    if debug:\n","      print('******************* DEBUG DECODER ***********************')\n","      print(f'Input Shape                       : {inputs.shape}')\n","      print(f'Shape Outputs Decoder             : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"SO5rYsFpfFS_","executionInfo":{"status":"ok","timestamp":1672993918345,"user_tz":-60,"elapsed":47,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_decoder = decoder(inputs=inputs_decoder, \n","                          bert_outputs=bert_outputs,  \n","                          training=training,\n","                          debug=debug)"],"metadata":{"id":"yysVdkHH8EPH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672993918347,"user_tz":-60,"elapsed":43,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"1ba77093-93f9-4c45-b138-a44c05f51596"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 64, 64)\n","Shape Output Layer Decode-Bert      : (32, 64, 64)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 64, 64)\n","Shape Outputs Decoder             : (32, 64, 64)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["## TRANSFORMER\n","\n","Implementazione del blocco Transformer tramite estensione della classe Layer di Keras."],"metadata":{"id":"ne4zTOG_NKfV"}},{"cell_type":"code","execution_count":43,"metadata":{"pycharm":{"name":"#%%\n"},"id":"lw2xMCAMC_4M","executionInfo":{"status":"ok","timestamp":1672993918350,"user_tz":-60,"elapsed":36,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"outputs":[],"source":["class TransformerBlock(keras.Model):\n","  def __init__(self, \n","               num_layers, \n","               embed_dim, \n","               num_heads, \n","               ff_dim, \n","               max_len,\n","               vocab_size,\n","               tfhub_handle_encoder,\n","               rate=0.5):\n","    \n","    super(TransformerBlock, self).__init__()\n","\n","    self.num_layers = num_layers\n","\n","    self.token_pos_dec = TokenAndPositionEmbedding(max_len, vocab_size, embed_dim)\n","\n","    self.encoder = EncoderBert(tfhub_handle_encoder, embed_dim, max_len)\n","    self.decoder = [Decoder(max_len, embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n","\n","    self.dropout = layers.Dropout(rate)\n","    self.final_layer = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, training=False, debug=False):\n","    inputs_encoder, inputs_decoder  = inputs\n","\n","    encoder_output = self.encoder(inputs_encoder, debug) \n","\n","    inputs_decoder = self.token_pos_dec(inputs_decoder, debug)\n","\n","    if debug:\n","      print(f'---------------- DEBUG TRANSFORMER BLOCK ----------------')\n","      print(f'inputs_encoder       : {inputs_encoder[\"input_word_ids\"].shape}')\n","      print(f'inputs_decoder       : {inputs_decoder.shape}')      \n","\n","    transformer_output = inputs_decoder\n","      \n","    for i in range(self.num_layers):\n","      transformer_output = self.decoder[i](inputs=transformer_output, \n","                                           bert_outputs=encoder_output, \n","                                           training=training,\n","                                           debug=debug)\n","\n","    transformer_output = self.dropout(transformer_output)\n","    logits = self.final_layer(transformer_output)\n","\n","    if debug:\n","      print(f'Output Shape       : {logits.shape}')\n","      print(f'Output Transformer : {logits[0, :1, :12]}')    \n","      print(f'---------------------------------------------------------')\n","\n","    return logits"]},{"cell_type":"code","source":["transformer = TransformerBlock(NUM_LAYERS, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.dan.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               DROPUOT)\n","\n","transformer_output = transformer((enc_input, dec_input), \n","                                 training=training,\n","                                 debug=debug)"],"metadata":{"id":"pr--G0ZZVAMi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672993932661,"user_tz":-60,"elapsed":14344,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"7eb23e01-c1d7-4345-e655-d1c8e1f6250e"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_word_ids', 'input_mask', 'input_type_ids']\n","Shape                        : (32, 128)\n","Word Ids                     : [ 101  243   69    8   84   75  259 2200   12   75  259 2357   99  102\n","    0    0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n","Type Ids                     : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[-0.2855804  -1.0893128   0.18167168 -0.51378155 -0.0605888   0.56065214\n","  -0.5365202   0.01175864 -0.01334048 -0.88153327 -0.1537769   0.9340685\n","  -0.17861578  0.3018391  -0.34964022  0.3313697 ]]\n","\n","Sequence Conv1 Shape         : (32, 128, 256)\n","Sequence Conv2 Shape         : (32, 128, 64)\n","Sequence Lambda Layer        : (32, 64, 64)\n","\n","Sequence Outputs Values      : [0.         0.86564535 0.7597855  0.         0.06458384 0.30239856\n"," 0.0753853  0.65765846 0.92639214 0.         0.9354932  0.\n"," 0.63321054 0.6367638  0.         1.5942163 ]\n","*********************************************************\n","********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 64\n","Sequence Shape                            : [32 64]\n","Shape TokenAndPositionEmbedding           : (32, 64, 64)\n","*********************************************************\n","---------------- DEBUG TRANSFORMER BLOCK ----------------\n","inputs_encoder       : (32, 128)\n","inputs_decoder       : (32, 64, 64)\n","********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 64, 64)\n","Shape Output Layer Decode-Bert      : (32, 64, 64)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 64, 64)\n","Shape Outputs Decoder             : (32, 64, 64)\n","*********************************************************\n","Output Shape       : (32, 64, 6309)\n","Output Transformer : [[-0.0040943   0.00786257  0.11510307 -0.04641666  0.07868677 -0.14802764\n","  -0.14050658 -0.06221797 -0.10964838 -0.04561514  0.13991113  0.18548468]]\n","---------------------------------------------------------\n"]}]},{"cell_type":"code","source":["transformer.summary()"],"metadata":{"id":"_kwqvJSu8liP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672993933083,"user_tz":-60,"elapsed":526,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"429edb1c-d052-43cc-8935-6fcb242097e4"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer_block\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," token_and_position_embeddin  multiple                 407872    \n"," g_1 (TokenAndPositionEmbedd                                     \n"," ing)                                                            \n","                                                                 \n"," encoder_bert_1 (EncoderBert  multiple                 109695553 \n"," )                                                               \n","                                                                 \n"," DEC (Decoder)               multiple                  402912    \n","                                                                 \n"," dropout_16 (Dropout)        multiple                  0         \n","                                                                 \n"," dense_10 (Dense)            multiple                  410085    \n","                                                                 \n","=================================================================\n","Total params: 110,916,422\n","Trainable params: 1,434,181\n","Non-trainable params: 109,482,241\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## Addestramento modello con ottimizzatore ADAM"],"metadata":{"id":"IFmcHTSDTvYk"}},{"cell_type":"markdown","source":["### Compilazione"],"metadata":{"id":"tiuqPlHo0Z0n"}},{"cell_type":"code","source":["transformer.compile(\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_ADAM, \n","                                       beta_1=BETA_1, \n","                                       beta_2=BETA_2),\n","    metrics=[keras.metrics.SparseCategoricalAccuracy()])"],"metadata":{"id":"bOyqCyjIr-L2","executionInfo":{"status":"ok","timestamp":1672993933084,"user_tz":-60,"elapsed":22,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 save_best_only=True)\n","\n","# Create a callback Tensorboard\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n","\n","# Create a callback save the log history\n","json_logging_callback = tf.keras.callbacks.LambdaCallback(\n","    on_epoch_end=lambda epoch, logs: json_log.write(\n","        json.dumps({'epoch': epoch, \n","                    'loss': logs['loss'],\n","                    'sparse_categorical_accuracy': logs['sparse_categorical_accuracy'],\n","                    'val_loss': logs['val_loss'],\n","                    'val_sparse_categorical_accuracy': logs['val_sparse_categorical_accuracy']}) + '\\n'),\n","    on_train_end=lambda logs: json_log.close()\n",")"],"metadata":{"id":"3hurmpSjJ_dT","executionInfo":{"status":"ok","timestamp":1672993933085,"user_tz":-60,"elapsed":22,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["### Addestramento 1"],"metadata":{"id":"Day7C7Qh0b4G"}},{"cell_type":"code","source":["start = datetime.datetime.now()\n","initial_epoch = 0\n","epochs = EPOCHS_ADAM\n","\n","for val_dataset in validation_dataset:\n","  json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","  transformer.fit(train_dataset,\n","                  initial_epoch=initial_epoch,\n","                  epochs=epochs,\n","                  shuffle=True,\n","                  validation_data=val_dataset,\n","                  callbacks=[tensorboard_callback,\n","                             json_logging_callback, \n","                             cp_callback])\n","  \n","  initial_epoch = epochs\n","  epochs = epochs + EPOCHS_ADAM\n","\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"etOGtBcer9yi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c7745d6c-d184-4da7-a887-9585ec68d85c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","500/500 [==============================] - 523s 1s/step - loss: 5.4267 - sparse_categorical_accuracy: 0.7575 - val_loss: 2.4375 - val_sparse_categorical_accuracy: 0.7958\n","Epoch 2/5\n","500/500 [==============================] - 525s 1s/step - loss: 1.7939 - sparse_categorical_accuracy: 0.7964 - val_loss: 1.3655 - val_sparse_categorical_accuracy: 0.8024\n","Epoch 3/5\n","500/500 [==============================] - 527s 1s/step - loss: 1.3541 - sparse_categorical_accuracy: 0.8082 - val_loss: 1.2219 - val_sparse_categorical_accuracy: 0.8143\n","Epoch 4/5\n","500/500 [==============================] - 519s 1s/step - loss: 1.2365 - sparse_categorical_accuracy: 0.8166 - val_loss: 1.1563 - val_sparse_categorical_accuracy: 0.8226\n","Epoch 5/5\n","500/500 [==============================] - 526s 1s/step - loss: 1.1717 - sparse_categorical_accuracy: 0.8213 - val_loss: 1.1121 - val_sparse_categorical_accuracy: 0.8262\n","Epoch 6/10\n","500/500 [==============================] - 514s 1s/step - loss: 1.1255 - sparse_categorical_accuracy: 0.8248 - val_loss: 1.0835 - val_sparse_categorical_accuracy: 0.8283\n","Epoch 7/10\n","500/500 [==============================] - 520s 1s/step - loss: 1.0897 - sparse_categorical_accuracy: 0.8278 - val_loss: 1.0553 - val_sparse_categorical_accuracy: 0.8305\n","Epoch 8/10\n","500/500 [==============================] - 525s 1s/step - loss: 1.0613 - sparse_categorical_accuracy: 0.8301 - val_loss: 1.0324 - val_sparse_categorical_accuracy: 0.8317\n","Epoch 9/10\n","500/500 [==============================] - 525s 1s/step - loss: 1.0385 - sparse_categorical_accuracy: 0.8315 - val_loss: 1.0145 - val_sparse_categorical_accuracy: 0.8325\n","Epoch 10/10\n","500/500 [==============================] - 523s 1s/step - loss: 1.0198 - sparse_categorical_accuracy: 0.8327 - val_loss: 0.9981 - val_sparse_categorical_accuracy: 0.8336\n","Epoch 11/15\n","500/500 [==============================] - 522s 1s/step - loss: 1.0038 - sparse_categorical_accuracy: 0.8336 - val_loss: 0.9813 - val_sparse_categorical_accuracy: 0.8349\n","Epoch 12/15\n","500/500 [==============================] - 523s 1s/step - loss: 0.9902 - sparse_categorical_accuracy: 0.8344 - val_loss: 0.9703 - val_sparse_categorical_accuracy: 0.8355\n","Epoch 13/15\n","500/500 [==============================] - 516s 1s/step - loss: 0.9787 - sparse_categorical_accuracy: 0.8349 - val_loss: 0.9607 - val_sparse_categorical_accuracy: 0.8355\n","Epoch 14/15\n","500/500 [==============================] - 523s 1s/step - loss: 0.9685 - sparse_categorical_accuracy: 0.8354 - val_loss: 0.9521 - val_sparse_categorical_accuracy: 0.8358\n","Epoch 15/15\n","500/500 [==============================] - 519s 1s/step - loss: 0.9595 - sparse_categorical_accuracy: 0.8360 - val_loss: 0.9440 - val_sparse_categorical_accuracy: 0.8363\n","Epoch 16/20\n","500/500 [==============================] - 518s 1s/step - loss: 0.9518 - sparse_categorical_accuracy: 0.8363 - val_loss: 0.9351 - val_sparse_categorical_accuracy: 0.8368\n","Epoch 17/20\n","500/500 [==============================] - 520s 1s/step - loss: 0.9445 - sparse_categorical_accuracy: 0.8366 - val_loss: 0.9300 - val_sparse_categorical_accuracy: 0.8368\n","Epoch 18/20\n","500/500 [==============================] - 527s 1s/step - loss: 0.9381 - sparse_categorical_accuracy: 0.8371 - val_loss: 0.9255 - val_sparse_categorical_accuracy: 0.8372\n","Epoch 19/20\n","500/500 [==============================] - 531s 1s/step - loss: 0.9323 - sparse_categorical_accuracy: 0.8372 - val_loss: 0.9202 - val_sparse_categorical_accuracy: 0.8376\n","Epoch 20/20\n","500/500 [==============================] - 518s 1s/step - loss: 0.9277 - sparse_categorical_accuracy: 0.8374 - val_loss: 0.9164 - val_sparse_categorical_accuracy: 0.8376\n","Epoch 21/25\n","500/500 [==============================] - 528s 1s/step - loss: 0.9231 - sparse_categorical_accuracy: 0.8378 - val_loss: 0.9097 - val_sparse_categorical_accuracy: 0.8387\n","Epoch 22/25\n","500/500 [==============================] - 520s 1s/step - loss: 0.9177 - sparse_categorical_accuracy: 0.8381 - val_loss: 0.9060 - val_sparse_categorical_accuracy: 0.8387\n","Epoch 23/25\n","500/500 [==============================] - 519s 1s/step - loss: 0.9139 - sparse_categorical_accuracy: 0.8383 - val_loss: 0.9039 - val_sparse_categorical_accuracy: 0.8389\n","Epoch 24/25\n","500/500 [==============================] - 519s 1s/step - loss: 0.9104 - sparse_categorical_accuracy: 0.8385 - val_loss: 0.9020 - val_sparse_categorical_accuracy: 0.8390\n","Epoch 25/25\n","448/500 [=========================>....] - ETA: 49s - loss: 0.9071 - sparse_categorical_accuracy: 0.8388"]}]},{"cell_type":"markdown","source":["### Addestramento 2"],"metadata":{"id":"qDYaeyzJ4AZP"}},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"dQjPtbe34D-Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672944258431,"user_tz":-60,"elapsed":13418,"user":{"displayName":"Dan Bad","userId":"09439284819205921448"}},"outputId":"7861255d-8b24-4461-89bd-84f5f2e48ec8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f8595e45160>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","initial_epoch = 24\n","epochs = initial_epoch + EPOCHS_ADAM\n","\n","for val_dataset in validation_dataset:\n","  json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","  transformer.fit(train_dataset,\n","                  initial_epoch=initial_epoch,\n","                  epochs=epochs,\n","                  shuffle=True,\n","                  validation_data=val_dataset,\n","                  callbacks=[tensorboard_callback,\n","                             json_logging_callback, \n","                             cp_callback])\n","\n","  initial_epoch = epochs\n","  epochs = epochs + EPOCHS_ADAM\n","\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"k67wpRqA4HGC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672957799814,"user_tz":-60,"elapsed":13539229,"user":{"displayName":"Dan Bad","userId":"09439284819205921448"}},"outputId":"324065b3-629a-4e15-d2bc-fc875ff06688"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 25/29\n","500/500 [==============================] - 524s 1s/step - loss: 0.9069 - sparse_categorical_accuracy: 0.8387 - val_loss: 0.9038 - val_sparse_categorical_accuracy: 0.8383\n","Epoch 26/29\n","500/500 [==============================] - 526s 1s/step - loss: 0.9039 - sparse_categorical_accuracy: 0.8389 - val_loss: 0.9019 - val_sparse_categorical_accuracy: 0.8387\n","Epoch 27/29\n","500/500 [==============================] - 520s 1s/step - loss: 0.9000 - sparse_categorical_accuracy: 0.8393 - val_loss: 0.9000 - val_sparse_categorical_accuracy: 0.8385\n","Epoch 28/29\n","500/500 [==============================] - 520s 1s/step - loss: 0.8974 - sparse_categorical_accuracy: 0.8396 - val_loss: 0.8986 - val_sparse_categorical_accuracy: 0.8385\n","Epoch 29/29\n","500/500 [==============================] - 515s 1s/step - loss: 0.8943 - sparse_categorical_accuracy: 0.8397 - val_loss: 0.8971 - val_sparse_categorical_accuracy: 0.8388\n","Epoch 30/34\n","500/500 [==============================] - 521s 1s/step - loss: 0.8923 - sparse_categorical_accuracy: 0.8400 - val_loss: 0.9040 - val_sparse_categorical_accuracy: 0.8375\n","Epoch 31/34\n","500/500 [==============================] - 514s 1s/step - loss: 0.8894 - sparse_categorical_accuracy: 0.8402 - val_loss: 0.9045 - val_sparse_categorical_accuracy: 0.8376\n","Epoch 32/34\n","500/500 [==============================] - 516s 1s/step - loss: 0.8872 - sparse_categorical_accuracy: 0.8403 - val_loss: 0.9028 - val_sparse_categorical_accuracy: 0.8375\n","Epoch 33/34\n","500/500 [==============================] - 514s 1s/step - loss: 0.8848 - sparse_categorical_accuracy: 0.8405 - val_loss: 0.9019 - val_sparse_categorical_accuracy: 0.8379\n","Epoch 34/34\n","500/500 [==============================] - 523s 1s/step - loss: 0.8825 - sparse_categorical_accuracy: 0.8408 - val_loss: 0.9019 - val_sparse_categorical_accuracy: 0.8382\n","Epoch 35/39\n","500/500 [==============================] - 524s 1s/step - loss: 0.8805 - sparse_categorical_accuracy: 0.8411 - val_loss: 0.8939 - val_sparse_categorical_accuracy: 0.8386\n","Epoch 36/39\n","500/500 [==============================] - 520s 1s/step - loss: 0.8785 - sparse_categorical_accuracy: 0.8413 - val_loss: 0.8929 - val_sparse_categorical_accuracy: 0.8384\n","Epoch 37/39\n","500/500 [==============================] - 520s 1s/step - loss: 0.8762 - sparse_categorical_accuracy: 0.8414 - val_loss: 0.8910 - val_sparse_categorical_accuracy: 0.8388\n","Epoch 38/39\n","500/500 [==============================] - 511s 1s/step - loss: 0.8742 - sparse_categorical_accuracy: 0.8416 - val_loss: 0.8914 - val_sparse_categorical_accuracy: 0.8390\n","Epoch 39/39\n","500/500 [==============================] - 521s 1s/step - loss: 0.8725 - sparse_categorical_accuracy: 0.8417 - val_loss: 0.8905 - val_sparse_categorical_accuracy: 0.8388\n","Epoch 40/44\n","500/500 [==============================] - 513s 1s/step - loss: 0.8709 - sparse_categorical_accuracy: 0.8420 - val_loss: 0.8895 - val_sparse_categorical_accuracy: 0.8395\n","Epoch 41/44\n","500/500 [==============================] - 515s 1s/step - loss: 0.8690 - sparse_categorical_accuracy: 0.8421 - val_loss: 0.8898 - val_sparse_categorical_accuracy: 0.8394\n","Epoch 42/44\n","500/500 [==============================] - 513s 1s/step - loss: 0.8671 - sparse_categorical_accuracy: 0.8423 - val_loss: 0.8880 - val_sparse_categorical_accuracy: 0.8397\n","Epoch 43/44\n","500/500 [==============================] - 518s 1s/step - loss: 0.8654 - sparse_categorical_accuracy: 0.8425 - val_loss: 0.8890 - val_sparse_categorical_accuracy: 0.8396\n","Epoch 44/44\n","500/500 [==============================] - 512s 1s/step - loss: 0.8651 - sparse_categorical_accuracy: 0.8425 - val_loss: 0.8885 - val_sparse_categorical_accuracy: 0.8397\n","Epoch 45/49\n","500/500 [==============================] - 515s 1s/step - loss: 0.8630 - sparse_categorical_accuracy: 0.8427 - val_loss: 0.8833 - val_sparse_categorical_accuracy: 0.8407\n","Epoch 46/49\n","500/500 [==============================] - 517s 1s/step - loss: 0.8610 - sparse_categorical_accuracy: 0.8428 - val_loss: 0.8827 - val_sparse_categorical_accuracy: 0.8406\n","Epoch 47/49\n","500/500 [==============================] - 521s 1s/step - loss: 0.8604 - sparse_categorical_accuracy: 0.8429 - val_loss: 0.8820 - val_sparse_categorical_accuracy: 0.8405\n","Epoch 48/49\n","500/500 [==============================] - 518s 1s/step - loss: 0.8585 - sparse_categorical_accuracy: 0.8432 - val_loss: 0.8817 - val_sparse_categorical_accuracy: 0.8409\n","Epoch 49/49\n","500/500 [==============================] - 511s 1s/step - loss: 0.8573 - sparse_categorical_accuracy: 0.8434 - val_loss: 0.8818 - val_sparse_categorical_accuracy: 0.8410\n","Tempo necessario per l'addestramento: 3:45:38.837154\n"]}]},{"cell_type":"markdown","source":["### Addestramento 3"],"metadata":{"id":"b4ibAQRvrJDt"}},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zl0eD38DrODN","executionInfo":{"status":"ok","timestamp":1672993953057,"user_tz":-60,"elapsed":12546,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"09b323bd-f461-463e-d204-864e9ad33d18"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f3a4f693b50>"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","initial_epoch = 49\n","epochs = initial_epoch + EPOCHS_ADAM\n","\n","for val_dataset in validation_dataset:\n","  json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","  transformer.fit(train_dataset,\n","                  initial_epoch=initial_epoch,\n","                  epochs=epochs,\n","                  shuffle=True,\n","                  validation_data=val_dataset,\n","                  callbacks=[tensorboard_callback,\n","                             json_logging_callback, \n","                             cp_callback])\n","\n","  initial_epoch = epochs\n","  epochs = epochs + EPOCHS_ADAM\n","\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"AnPHFdCXrN3Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673007676871,"user_tz":-60,"elapsed":13723881,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"0141b7ea-e8a5-424a-893e-6b82ece74c38"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 50/54\n","500/500 [==============================] - 545s 1s/step - loss: 0.8568 - sparse_categorical_accuracy: 0.8431 - val_loss: 0.8830 - val_sparse_categorical_accuracy: 0.8400\n","Epoch 51/54\n","500/500 [==============================] - 524s 1s/step - loss: 0.8557 - sparse_categorical_accuracy: 0.8433 - val_loss: 0.8827 - val_sparse_categorical_accuracy: 0.8399\n","Epoch 52/54\n","500/500 [==============================] - 526s 1s/step - loss: 0.8542 - sparse_categorical_accuracy: 0.8434 - val_loss: 0.8831 - val_sparse_categorical_accuracy: 0.8398\n","Epoch 53/54\n","500/500 [==============================] - 524s 1s/step - loss: 0.8539 - sparse_categorical_accuracy: 0.8435 - val_loss: 0.8833 - val_sparse_categorical_accuracy: 0.8402\n","Epoch 54/54\n","500/500 [==============================] - 527s 1s/step - loss: 0.8519 - sparse_categorical_accuracy: 0.8436 - val_loss: 0.8825 - val_sparse_categorical_accuracy: 0.8399\n","Epoch 55/59\n","500/500 [==============================] - 523s 1s/step - loss: 0.8501 - sparse_categorical_accuracy: 0.8440 - val_loss: 0.8922 - val_sparse_categorical_accuracy: 0.8387\n","Epoch 56/59\n","500/500 [==============================] - 517s 1s/step - loss: 0.8491 - sparse_categorical_accuracy: 0.8439 - val_loss: 0.8921 - val_sparse_categorical_accuracy: 0.8388\n","Epoch 57/59\n","500/500 [==============================] - 524s 1s/step - loss: 0.8484 - sparse_categorical_accuracy: 0.8441 - val_loss: 0.8914 - val_sparse_categorical_accuracy: 0.8387\n","Epoch 58/59\n","500/500 [==============================] - 525s 1s/step - loss: 0.8461 - sparse_categorical_accuracy: 0.8441 - val_loss: 0.8917 - val_sparse_categorical_accuracy: 0.8389\n","Epoch 59/59\n","500/500 [==============================] - 522s 1s/step - loss: 0.8466 - sparse_categorical_accuracy: 0.8442 - val_loss: 0.8915 - val_sparse_categorical_accuracy: 0.8390\n","Epoch 60/64\n","500/500 [==============================] - 522s 1s/step - loss: 0.8447 - sparse_categorical_accuracy: 0.8443 - val_loss: 0.8847 - val_sparse_categorical_accuracy: 0.8396\n","Epoch 61/64\n","500/500 [==============================] - 522s 1s/step - loss: 0.8442 - sparse_categorical_accuracy: 0.8443 - val_loss: 0.8842 - val_sparse_categorical_accuracy: 0.8397\n","Epoch 62/64\n","500/500 [==============================] - 523s 1s/step - loss: 0.8436 - sparse_categorical_accuracy: 0.8446 - val_loss: 0.8842 - val_sparse_categorical_accuracy: 0.8399\n","Epoch 63/64\n","500/500 [==============================] - 522s 1s/step - loss: 0.8414 - sparse_categorical_accuracy: 0.8445 - val_loss: 0.8828 - val_sparse_categorical_accuracy: 0.8398\n","Epoch 64/64\n","500/500 [==============================] - 515s 1s/step - loss: 0.8409 - sparse_categorical_accuracy: 0.8445 - val_loss: 0.8827 - val_sparse_categorical_accuracy: 0.8398\n","Epoch 65/69\n","500/500 [==============================] - 519s 1s/step - loss: 0.8397 - sparse_categorical_accuracy: 0.8447 - val_loss: 0.8845 - val_sparse_categorical_accuracy: 0.8399\n","Epoch 66/69\n","500/500 [==============================] - 523s 1s/step - loss: 0.8382 - sparse_categorical_accuracy: 0.8449 - val_loss: 0.8842 - val_sparse_categorical_accuracy: 0.8399\n","Epoch 67/69\n","500/500 [==============================] - 523s 1s/step - loss: 0.8376 - sparse_categorical_accuracy: 0.8450 - val_loss: 0.8833 - val_sparse_categorical_accuracy: 0.8399\n","Epoch 68/69\n","500/500 [==============================] - 523s 1s/step - loss: 0.8375 - sparse_categorical_accuracy: 0.8452 - val_loss: 0.8832 - val_sparse_categorical_accuracy: 0.8399\n","Epoch 69/69\n","500/500 [==============================] - 519s 1s/step - loss: 0.8361 - sparse_categorical_accuracy: 0.8449 - val_loss: 0.8837 - val_sparse_categorical_accuracy: 0.8401\n","Epoch 70/74\n","500/500 [==============================] - 522s 1s/step - loss: 0.8352 - sparse_categorical_accuracy: 0.8454 - val_loss: 0.8780 - val_sparse_categorical_accuracy: 0.8411\n","Epoch 71/74\n","500/500 [==============================] - 523s 1s/step - loss: 0.8341 - sparse_categorical_accuracy: 0.8454 - val_loss: 0.8779 - val_sparse_categorical_accuracy: 0.8411\n","Epoch 72/74\n","500/500 [==============================] - 520s 1s/step - loss: 0.8336 - sparse_categorical_accuracy: 0.8453 - val_loss: 0.8785 - val_sparse_categorical_accuracy: 0.8413\n","Epoch 73/74\n","500/500 [==============================] - 516s 1s/step - loss: 0.8331 - sparse_categorical_accuracy: 0.8453 - val_loss: 0.8780 - val_sparse_categorical_accuracy: 0.8411\n","Epoch 74/74\n","500/500 [==============================] - 515s 1s/step - loss: 0.8318 - sparse_categorical_accuracy: 0.8456 - val_loss: 0.8784 - val_sparse_categorical_accuracy: 0.8411\n","Tempo necessario per l'addestramento: 3:48:45.412562\n"]}]},{"cell_type":"markdown","source":["### Addestramento 4"],"metadata":{"id":"WEXGcXMlB8mx"}},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"WWenzzXbCA58","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671632501334,"user_tz":-60,"elapsed":16358,"user":{"displayName":"Dan Bad","userId":"09439284819205921448"}},"outputId":"c3081fc8-bd78-41a0-9999-ce53ad28982a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f466097ce50>"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","initial_epoch = 75\n","epochs = initial_epoch + EPOCHS_ADAM\n","\n","for val_dataset in validation_dataset:\n","  json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","  transformer.fit(train_dataset,\n","                  initial_epoch=initial_epoch,\n","                  epochs=epochs,\n","                  shuffle=True,\n","                  validation_data=val_dataset,\n","                  callbacks=[tensorboard_callback,\n","                             json_logging_callback, \n","                             cp_callback])\n","\n","  initial_epoch = epochs\n","  epochs = epochs + EPOCHS_ADAM\n","\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"-c_uBg4nCD1X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Valutazione dell'addestramento\n","Avendo in output il log ed i risultati dell'addestramento, possiamo visualizzare\n","queste informazioni relativamente alle metriche di interesse."],"metadata":{"id":"L0w4wF79UhAp"}},{"cell_type":"code","source":["# Recupero il log di addestramento\n","df_history = pd.read_json(log_history, lines=True)\n","\n","# visualizzazione andamento addestramento\n","# su un grafico composto da due sub-plot\n","# uno per il loss, l'altro per l'accuracy\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n","\n","# Errore durante l'addestramento\n","ax1.plot(df_history['loss'], label='Loss')\n","ax1.plot(df_history['val_loss'], label='Validation Loss')\n","ax1.set_title('Training Loss')\n","ax1.legend()\n","\n","# Accuratezza durante l'addestramento\n","ax2.plot(df_history['sparse_categorical_accuracy'], label='Accuracy')\n","ax2.plot(df_history['val_sparse_categorical_accuracy'], label='Validation Accuracy')\n","ax2.set_title('Training Accuracy')\n","ax2.legend()\n","\n","plt.show()"],"metadata":{"id":"RpXR2p5VAdoG","colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"status":"ok","timestamp":1673007677903,"user_tz":-60,"elapsed":19,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"94b041f1-28b2-4bea-e596-4655cb455914"},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x360 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## Test del modello\n","La seguente cella permette di caricare l'ultimo checkpoint dell'addestramento\n","precedentemente salvato."],"metadata":{"id":"ReOkcBp2WHWW"}},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"5PIf_6-RSBb1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673007679368,"user_tz":-60,"elapsed":1477,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"8d0fcb97-8c05-400e-cb30-f26c69294fbb"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f39d07e1c40>"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["class Translate:\n","  def __init__(self, transformer_block, tokenizers):\n","    self.transformer = transformer_block\n","    self.tokenizers = tokenizers\n","\n","  def predict(self, input_text, max_length):\n","    if input_text is None:\n","      input_text = input_data[np.random.choice(len(input_data))]\n","      print(input_text)\n","\n","    inputs_bert = self.tokenizers.ita.tokenize(input_text)\n","\n","    start_end = self.tokenizers.dan.tokenize([''])[0]\n","    start = (start_end[0][tf.newaxis]).numpy()[0]\n","    end = (start_end[1][tf.newaxis]).numpy()[0]\n","\n","    output_array = tf.TensorArray(dtype=tf.int32, size=max_length, dynamic_size=True)\n","    output_array = output_array.write(0, tf.constant([start]))     \n","\n","    out_words = []\n","\n","    for i in tf.range(max_length):\n","      # decodifica e recupero probabilità di output\n","      output = tf.transpose(output_array.stack())\n","\n","      transformer_output = transformer((inputs_bert, output), \n","                                        training=False,\n","                                        debug=False)\n","\n","      predictions = transformer_output[:, -1:, :]\n","\n","      # selezione della parola più probabile\n","      predict = tf.argmax(predictions, -1)\n","      pred_values = (K.argmax(transformer_output, axis=-1)).numpy()\n","    \n","      # inserimento della parola nella sequenza di output\n","      output_array = output_array.write(i+1, [pred_values[0][i]])\n","\n","      if pred_values[0][i] == end:\n","        break\n","\n","    output = tf.transpose(output_array.stack())\n","    text = tokenizers.dan.detokenize(output)[0]  \n","    tokens = tokenizers.dan.lookup(output)[0]\n","\n","    return text, tokens"],"metadata":{"id":"L2PEoJVb1V8x","executionInfo":{"status":"ok","timestamp":1673007679369,"user_tz":-60,"elapsed":17,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["test_sequences = [test_input_data[2], test_input_data[26], test_input_data[19], \n","                  test_input_data[34], test_input_data[45], test_input_data[58], \n","                  test_input_data[62], test_input_data[71], test_input_data[84],\n","                  test_input_data[90], test_input_data[99], test_input_data[0]]\n","\n","target_sequences = [test_target_data[2], test_target_data[26], test_target_data[19], \n","                    test_target_data[34], test_target_data[45], test_target_data[58], \n","                    test_target_data[62], test_target_data[71], test_target_data[84],\n","                    test_target_data[90], test_target_data[99], test_target_data[0]]\n","\n","\n","translate = Translate(transformer_block=transformer,\n","                      tokenizers=tokenizers)\n","\n","for test_sequence, target in zip(test_sequences, target_sequences):\n","  text, token = translate.predict(tf.constant([test_sequence]), MAX_SEQ_LENGTH)\n","\n","  print(f'{\"Input\":15s}: {test_sequence}')\n","  print(f'{\"Target\":15s}: {target}')\n","  print(f'{\"Prediction\":15s}: {text.numpy().decode(\"utf-8\")}')  \n","  print('---------------------------------------------')\n"],"metadata":{"id":"udIjI2jZWR6g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673007690657,"user_tz":-60,"elapsed":11302,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"069b8901-ae04-48c7-9adf-6c9b78c45609"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Input          : ha rivisto la sua fonte , antandros e\n","Target         : antandro e simeonta , onde si mosse , \n","Prediction     : egli altri , che signora ,\n","---------------------------------------------\n","Input          : le creature che amano il piacere di guardare , \n","Target         : queste sustanze , poi che fur gioconde\n","Prediction     : egli altri , egli altri ,\n","---------------------------------------------\n","Input          : quindi , tra queste tonalita , vado nella tristezza . \n","Target         : per ch io vo tra costor con bassa fronte . \n","Prediction     : egli spiriti che signora ,\n","---------------------------------------------\n","Input          : era un miserabile fantasma nascosto nel ghiaccio , \n","Target         : mettendo i denti in nota di cicogna . \n","Prediction     : egli altri , egli altri ,\n","---------------------------------------------\n","Input          : tu sei stato finche io mi sono abbassato . \n","Target         : di la fosti cotanto quant io scesi \n","Prediction     : e il mio capo , e la sua strada ,\n","---------------------------------------------\n","Input          : ma a me ha rivolto mente e volto , \n","Target         : ma drizzo verso me l animo e l volto , \n","Prediction     : e il mio capo mi ha fatto ,\n","---------------------------------------------\n","Input          : potevano far pensare che , pur essendo di bronzo , \n","Target         : si che , con tutto che fosse di rame , \n","Prediction     : e io , che non e stato fatto ,\n","---------------------------------------------\n","Input          : cosi forte che io , nella paura , mi avvicinai al poeta . \n","Target         : ch i mi strinsi al poeta per sospetto . \n","Prediction     : e il mio capo mi ha fatto il suo nome .\n","---------------------------------------------\n","Input          : laggiu ci siamo imbattuti in un popolo laccato\n","Target         : la giu trovammo una gente dipinta\n","Prediction     : egli altri , che signore ,\n","---------------------------------------------\n","Input          : perche le stesse cose sono sepolte qui a somiglianza , \n","Target         : simile qui con simile e sepolto , \n","Prediction     : e la sua volonta , e la sua strada ,\n","---------------------------------------------\n","Input          : supplicati per grazia per tanto potere\n","Target         : supplica a te , per grazia , di virtute\n","Prediction     : e io , che non signora ,\n","---------------------------------------------\n","Input          : ai piedi della riva alta che sorge mai , \n","Target         : al pie de l alta ripa che pur sale , \n","Prediction     : e io , che non signora ,\n","---------------------------------------------\n"]}]},{"cell_type":"markdown","source":["## Tensorboard"],"metadata":{"id":"YJf4hjv4PMAJ"}},{"cell_type":"code","source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"metadata":{"id":"vcwHe7VJWt-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_dir"],"metadata":{"id":"7AB28JmGPQgi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir drive/MyDrive/BERT/logs/fit/20221026-134720"],"metadata":{"id":"2ZkkDKVwPT2O"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":["b4ibAQRvrJDt","WEXGcXMlB8mx","YJf4hjv4PMAJ"]},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}